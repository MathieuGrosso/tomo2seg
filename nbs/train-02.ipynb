{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks as keras_callbacks\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    MetaCrop3DGenerator, VolumeCropSequence,\n",
    "    UniformGridPosition, SequentialGridPosition,\n",
    "    ET3DUniformCuboidAlmostEverywhere, ET3DConstantEverywhere, \n",
    "    GTUniformEverywhere, GTConstantEverywhere, \n",
    "    VSConstantEverywhere, VSUniformEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg import callbacks as tomo2seg_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-4-0983157db95a>:<module>:005}::[2020-11-24::11:24:43.261]\n",
      "runid=1606208020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time())\n",
    "# runid = 1606208020\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:001}::[2020-11-24::11:24:48.798]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:002}::[2020-11-24::11:24:48.855]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:003}::[2020-11-24::11:24:49.283]\n",
      "Both here should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-6-f863a788f16a>:<module>:010}::[2020-11-24::11:24:49.390]\n",
      "volume_name='PA66GF30' volume_version='v1' labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:237}::[2020-11-24::11:24:50.589]\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "ERROR::tomo2seg::{data.py:with_check:255}::[2020-11-24::11:24:50.591]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels.raw\n",
      "\n",
      "WARNING::tomo2seg::{data.py:with_check:259}::[2020-11-24::11:24:50.593]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.weights.raw\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:194}::[2020-11-24::11:24:50.594]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-7-3d9af8b98d34>:<module>:007}::[2020-11-24::11:24:50.602]\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [0, 1300], 'alias': 'train'}, 'val': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1600, 1900], 'alias': 'val'}, 'test': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1300, 1600], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-7-3d9af8b98d34>:<module>:022}::[2020-11-24::11:24:50.603]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-7-3d9af8b98d34>:<module>:026}::[2020-11-24::11:25:00.641]\n",
      "voldata.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-3d9af8b98d34>:<module>:030}::[2020-11-24::11:25:00.645]\n",
      "voldata_train.shape=(1300, 1040, 1300) voldata_val.shape=(1300, 1040, 300)\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-7-3d9af8b98d34>:<module>:036}::[2020-11-24::11:25:08.355]\n",
      "vollabels.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-3d9af8b98d34>:<module>:040}::[2020-11-24::11:25:08.357]\n",
      "vollabels_train.shape=(1300, 1040, 1300) vollabels_val.shape=(1300, 1040, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "logger.debug(f\"{voldata_train.shape=} {voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "logger.debug(f\"{vollabels_train.shape=} {vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "# Data crop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-8-630e2409ee30>:<module>:010}::[2020-11-24::11:25:09.247]\n",
      "batch_size_per_replica=10\n",
      "n_replicas=2\n",
      "batch_size=20\n",
      "common_random_state=143\n",
      "crop_shape=(320, 320, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size_per_replica = 10  \n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "\n",
    "common_random_state = 143\n",
    "\n",
    "# crop_shape = (256, 256, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "# bigger crops will have less border effects (?)\n",
    "crop_shape = (320, 320, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\\n{common_random_state=}\\n{crop_shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:145}::[2020-11-24::11:26:16.658]\n",
      "Built UniformGridPosition from volume_shape=(1300, 1040, 1300) and crop_shape=(320, 320, 1) ==> {'x_range': (0, 981), 'y_range': (0, 721), 'z_range': (0, 1300)}\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:229}::[2020-11-24::11:26:16.661]\n",
      "Initializing ET3DUniformCuboidAlmostEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:460}::[2020-11-24::11:26:16.662]\n",
      "Initializing ET3DUniformCuboidAlmostEverywhere with a crop_source_volume_shape=(1300, 1040, 1300).\n",
      "The crop_{x, y, z}lim values will be overwritten with (0, crop_source_volume_shape[{0, 1, 2}]).\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:229}::[2020-11-24::11:26:16.664]\n",
      "Initializing GTUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1bb1610de7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgrid_position_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_pos_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         ),\n\u001b[0;32m---> 31\u001b[0;31m         vs_field=VSUniformEverywhere.build_plus_or_mines(\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# half a value to both sides +/-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mgrid_position_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_pos_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/tomo2seg/volume_sequence.py\u001b[0m in \u001b[0;36mbuild_plus_or_mines\u001b[0;34m(cls, shift, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_plus_or_mines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'random_state'"
     ]
    }
   ],
   "source": [
    "data = voldata_train\n",
    "labels = vollabels_train\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := UniformGridPosition.build_from_volume_crop_shapes(\n",
    "                volume_shape=volume_shape, \n",
    "                crop_shape=crop_shape,\n",
    "                random_state=RandomState(common_random_state),\n",
    "            )\n",
    "        ),\n",
    "        et_field=ET3DUniformCuboidAlmostEverywhere.build_half_voxel_cuboid(\n",
    "            crop_shape=crop_shape,\n",
    "            crop_source_volume_shape=volume_shape,\n",
    "            spline_order=1,  # linear interpolation\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "            random_state=RandomState(common_random_state),\n",
    "        ),\n",
    "        gt_field=GTUniformEverywhere.build_2d(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "        ),\n",
    "        vs_field=VSUniformEverywhere.build_plus_or_mines(\n",
    "            shift=1. / 255 / 2,  # half a value to both sides +/-\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "            random_state\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "    epoch_size=1,\n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val volume\n",
    "\n",
    "data = voldata_val\n",
    "labels = vollabels_val\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    # data source\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    \n",
    "    # data augmentation\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "#             grid_pos_gen := SequentialGridPosition.build_min_overlap(\n",
    "#                 volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "#             )\n",
    "            grid_pos_gen := SequentialGridPosition.build_from_volume_crop_shapes(\n",
    "                volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "                n_steps_x=2, n_steps_y=2, n_steps_z=200,\n",
    "            )\n",
    "        ),\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator_=grid_pos_gen),\n",
    "        gt_field=GTConstantEverywhere.build_gt2d_identity(grid_position_generator_=grid_pos_gen),\n",
    "        vs_field=VSConstantEverywhere.build_no_shift(grid_position_generator_=grid_pos_gen),\n",
    "    ),\n",
    "    \n",
    "    # others\n",
    "    batch_size=batch_size,\n",
    "    epoch_size=len(grid_pos_gen),  # go through all the crops in validation    \n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "except NameError:\n",
    "    print(\"already deleted (:\")\n",
    "else:\n",
    "    del tomo2seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_segm import keras_custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_master_name = \"unet-2d-small\"\n",
    "model_version = \"vanilla00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "model_factory_function = modular_unet.u_net\n",
    "model_factory_kwargs = dict(\n",
    "    input_shape = crop_shape,\n",
    "    nb_filters_0 = 16,\n",
    ")\n",
    "\n",
    "try:\n",
    "    tomo2seg_model\n",
    "    \n",
    "except NameError:\n",
    "    \n",
    "    tomo2seg_model = Tomo2SegModel(\n",
    "        model_master_name, \n",
    "        model_version, \n",
    "        runid=runid,\n",
    "        factory_function=model_factory_function,\n",
    "        factory_kwargs=model_factory_kwargs,\n",
    "    )\n",
    "                \n",
    "else:\n",
    "    logger.warning(\"The model is already defined. To create a new one: `del tomo2seg_model`\")\n",
    "\n",
    "finally:\n",
    "    \n",
    "    logger.info(f\"{tomo2seg_model=}\")\n",
    "    \n",
    "    logger.info(\"Compiling model.\")\n",
    "    \n",
    "    with strategy.scope():\n",
    "        if not tomo2seg_model.autosaved_model_path.exists():\n",
    "#             assert not tomo2seg_model.model_path.exists(), f\"Please delete '{tomo2seg_model.model_path}' to resave it if you wish to regenerate it.\"\n",
    "            model = model_factory_function(\n",
    "                output_channels=len(volume.metadata.labels), \n",
    "                name=tomo2seg_model.name,\n",
    "                **model_factory_kwargs\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\"An autosaved model already exists, loading it instead of creating a new one!\")\n",
    "            model = keras.models.load_model(tomo2seg_model.autosaved_model_path_str, compile=False)\n",
    "       \n",
    "        model.compile(\n",
    "            loss=keras_custom_loss.jaccard2_loss, \n",
    "            optimizer=optimizers.Adam(lr=.003)\n",
    "        )\n",
    "        model.save(tomo2seg_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8175,
     "status": "ok",
     "timestamp": 1602255988215,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "L2U_tsMojKCD"
   },
   "outputs": [],
   "source": [
    "# write the model summary in a file\n",
    "with tomo2seg_model.summary_path.open(\"w\") as f:\n",
    "    def print_to_txt(line):\n",
    "        f.writelines([line + \"\\n\"])\n",
    "    model.summary(print_fn=print_to_txt, line_length=140)\n",
    "    \n",
    "# same for the architecture\n",
    "utils.plot_model(model, show_shapes=True, to_file=tomo2seg_model.architecture_plot_path);\n",
    "\n",
    "logger.info(f\"Check the summary and the figure of the model in the following locations:\\n{tomo2seg_model.summary_path}\\n{tomo2seg_model.architecture_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "todo check how to get the history call back so i merge it automatically\n",
    "todo add metrics to the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [],
   "source": [
    "autosave_cb = keras_callbacks.ModelCheckpoint(\n",
    "    tomo2seg_model.autosaved_model_path_str, \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=2, \n",
    "    save_best_only=True, \n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "# todo load if it already exists\n",
    "try:\n",
    "    history_cb\n",
    "    \n",
    "except NameError:\n",
    "    history_cb = tomo2seg_callbacks.History(\n",
    "        optimizer=model.optimizer,\n",
    "        backup=5,\n",
    "        csv_path=tomo2seg_model.history_path,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    history_df = history_cb.dataframe\n",
    "\n",
    "    try:\n",
    "        history_df_temp = pd.read_csv(tomo2seg_model.history_path)\n",
    "        # keep the longest one\n",
    "        history_df = history_df if history_df.shape[0] >= history_df_temp.shape[0] else history_df_temp\n",
    "        del history_df_temp\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "    \n",
    "    finally:\n",
    "        history_df.to_csv(history_cb.csv_path, index=True)\n",
    "    \n",
    "finally:\n",
    "    # make sure the correct objects are linked \n",
    "    history_cb.model = model\n",
    "    # todo do the same with other objs in history_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training\n",
    "\n",
    "stuff that i use after the training but i want it to appear in the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Volume slices\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Generator samples\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "# Learning rate range test\n",
    "\n",
    "todo put this back to work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(str(model_paths.autosaved_model_path) + \".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# lr = 0.001\n",
    "# K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "lr_schedule_cb = keras_callbacks.LearningRateScheduler(\n",
    "#     schedule=log_schedule_factory(-6, -2, 9, 9),\n",
    "    schedule=log_schedule_factory(-2, -1, 13, 0, offset_epoch=61),\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "crop_seq_train.epoch_size = 10\n",
    "\n",
    "callbacks = [\n",
    "    autosave_cb,\n",
    "    history_cb,\n",
    "    keras_callbacks.TerminateOnNaN(),\n",
    "    lr_schedule_cb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "model.fit(\n",
    "    # data sequences\n",
    "    x=crop_seq_train,\n",
    "    validation_data=crop_seq_val,\n",
    "    \n",
    "    # epochs\n",
    "#     initial_epoch=0,\n",
    "#     epochs=n_epochs,\n",
    "    initial_epoch=history_cb.last_epoch + 1,  # for some reason it is 0-starting and others 1-starting...\n",
    "    epochs=history_cb.last_epoch + 1 + n_epochs,  \n",
    "    \n",
    "    # others\n",
    "    callbacks=callbacks,  \n",
    "    verbose=2,\n",
    "    use_multiprocessing=False,   \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decreasing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "lr_schedule_cb = keras_callbacks.LearningRateScheduler(\n",
    "#     schedule=log_schedule_factory(-2, -4, 11, 0, offset_epoch=76),\n",
    "    schedule=log_schedule_factory(-4, -5, 31, 0, offset_epoch=101),\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "crop_seq_train.epoch_size = 10\n",
    "\n",
    "history_cb.optimizer = model.optimizer\n",
    "\n",
    "callbacks = [\n",
    "    autosave_cb,\n",
    "    history_cb,\n",
    "    keras_callbacks.TerminateOnNaN(),\n",
    "    lr_schedule_cb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 33\n",
    "\n",
    "model.fit(\n",
    "    # data sequences\n",
    "    x=crop_seq_train,\n",
    "    validation_data=crop_seq_val,\n",
    "    \n",
    "    # epochs\n",
    "#     initial_epoch=0,\n",
    "#     epochs=n_epochs,\n",
    "    initial_epoch=history_cb.last_epoch + 1,  # for some reason it is 0-starting and others 1-starting...\n",
    "    epochs=history_cb.last_epoch + 1 + n_epochs,  \n",
    "    \n",
    "    # others\n",
    "    callbacks=callbacks,  \n",
    "    verbose=2,\n",
    "    use_multiprocessing=False,   \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows := 2, 1, figsize=(2*(sz := 5), nrows * sz), dpi=100)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "hist_display = viz.TrainingHistoryDisplay(\n",
    "    history_cb.history, \n",
    "    model_name=tomo2seg_model.name,\n",
    "    loss_name=model.loss.__name__,\n",
    ").plot(axs, with_lr=True)\n",
    "\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[-1].set_yscale(\"log\")\n",
    "\n",
    "viz.mark_min_values(hist_display.ax_loss_, hist_display.plots_[\"loss\"][0])\n",
    "viz.mark_min_values(hist_display.ax_loss_, hist_display.plots_[\"val_loss\"][0], txt_kwargs=dict(rotation=0))\n",
    "\n",
    "hist_display.fig_.savefig(\n",
    "    tomo2seg_model.model_path / (hist_display.title + \".png\"),\n",
    "    format='png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "outputs": [],
   "source": [
    "history_cb.dataframe.to_csv(history_cb.csv_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [],
   "source": [
    "model.save(tomo2seg_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8787,
     "status": "aborted",
     "timestamp": 1602255923921,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "RRq6qKodQz0n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

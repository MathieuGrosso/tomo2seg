{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "import copy\n",
    "import functools\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "from progressbar import progressbar as pbar\n",
    "from enum import Enum\n",
    "import re\n",
    "from enum import Enum\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from cnn_segm import keras_custom_loss\n",
    "\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    VolumeCropSequence, MetaCrop3DGenerator, VSConstantEverywhere, \n",
    "    GTConstantEverywhere, SequentialGridPosition, ET3DConstantEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg.data import EstimationVolume\n",
    "from tomo2seg import AggregationStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-4-cf972d05bc84>:<module>:004}::[2020-11-22::15:47:53.304]\n",
      "runid=1606056473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time())\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-5-9df7dd5953d5>:<module>:001}::[2020-11-22::15:47:53.353]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-5-9df7dd5953d5>:<module>:002}::[2020-11-22::15:47:53.355]\n",
      "Num GPUs Available: 0\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-5-9df7dd5953d5>:<module>:003}::[2020-11-22::15:47:53.384]\n",
      "Both here should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[]\n",
      "tf.config.list_logical_devices('GPU')=[]\n",
      "\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "DEBUG::tomo2seg::{<ipython-input-5-9df7dd5953d5>:<module>:011}::[2020-11-22::15:47:53.389]\n",
      "strategy=<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f21ae84cee0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "logger.debug(f\"{strategy=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will later be useful when i transform this in python script\n",
    "save_probas_by_class = True\n",
    "\n",
    "debug__save_figs = True\n",
    "debug__materialize_crops = False\n",
    "probabilities_dtype = np.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet-2d-small.vanilla00.000.1605-971-456.autosaved.hdf5\n",
      "\u001b[01;34munet-2d-small.vanilla00.000.1605-972-712\u001b[0m/\n",
      "unet-2d-small.vanilla00.000.1605-972-712.autosaved.hdf5\n",
      "\u001b[01;34munet-2d-small.vanilla00.000.1605-982-196\u001b[0m/\n",
      "unet-2d-small.vanilla00.000.1605-982-196.autosaved.hdf5\n"
     ]
    }
   ],
   "source": [
    "ls ../data/models | grep unet-2d-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-7-d7942cfb89c4>:<module>:004}::[2020-11-22::15:47:53.658]\n",
      "tomo2seg_model=Model(master_name='unet-2d-small', version='vanilla00', fold=0, runid=1605982196, factory_function=None, factory_kwargs=None)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-d7942cfb89c4>:<module>:016}::[2020-11-22::15:47:55.357]\n",
      "input_n_channels=(1,)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-d7942cfb89c4>:<module>:024}::[2020-11-22::15:47:55.360]\n",
      "anysize_input=<tf.Tensor 'input_any_image_size:0' shape=(None, None, None, None, 1) dtype=float32>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tomo2seg_model = Tomo2SegModel.build_from_model_name(\n",
    "    \"unet-2d-small.vanilla00.000.1605-982-196\"\n",
    ")\n",
    "logger.info(f\"{tomo2seg_model=}\")\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model(\n",
    "        tomo2seg_model.autosaved_model_path_str,\n",
    "        compile=False\n",
    "    )\n",
    "    \n",
    "    in_ = model.layers[0]\n",
    "    in_shape = in_.input_shape[0]\n",
    "    input_n_channels = in_shape[-1:]\n",
    "\n",
    "    logger.debug(f\"{input_n_channels=}\")\n",
    "    \n",
    "    # make it capable of getting any dimension in the input\n",
    "    anysize_input = layers.Input(\n",
    "        shape=[None, None, None] + list(input_n_channels),\n",
    "        name=\"input_any_image_size\"\n",
    "    )\n",
    "    \n",
    "    logger.debug(f\"{anysize_input=}\")\n",
    "    \n",
    "    model.layers[0] = anysize_input\n",
    "    \n",
    "    # todo keep this somewhere instead of copying and pasting\n",
    "    optimizer = optimizers.Adam()\n",
    "    loss_func = keras_custom_loss.jaccard2_loss\n",
    "\n",
    "    model.compile(loss=loss_func, optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-8-cdb1781c8ebd>:<module>:010}::[2020-11-22::15:47:55.422]\n",
      "volume_name='PA66GF30' volume_version='v1-reduced' labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "#     VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:227}::[2020-11-22::15:47:55.491]\n",
      "vol=Volume(name='PA66GF30', version='v1-reduced', _metadata=None)\n",
      "\n",
      "ERROR::tomo2seg::{data.py:with_check:245}::[2020-11-22::15:47:55.492]\n",
      "Missing file: /home/joaopcbertoldo/projects/tomo2seg/data/PA66GF30.v1-reduced/PA66GF30.v1-reduced.labels.raw\n",
      "\n",
      "WARNING::tomo2seg::{data.py:with_check:249}::[2020-11-22::15:47:55.494]\n",
      "Missing file: /home/joaopcbertoldo/projects/tomo2seg/data/PA66GF30.v1-reduced/PA66GF30.v1-reduced.weights.raw\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:184}::[2020-11-22::15:47:55.495]\n",
      "Loading metadata from `/home/joaopcbertoldo/projects/tomo2seg/data/PA66GF30.v1-reduced/PA66GF30.v1-reduced.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-127f893db5f4>:<module>:007}::[2020-11-22::15:47:55.503]\n",
      "volume=Volume(name='PA66GF30', version='v1-reduced', _metadata=Volume.Metadata(dimensions=[256, 256, 256], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 256], 'y_range': [0, 256], 'z_range': [0, 128], 'alias': 'train'}, 'val': {'x_range': [0, 256], 'y_range': [0, 256], 'z_range': [128, 192], 'alias': 'val'}, 'test': {'x_range': [0, 256], 'y_range': [0, 256], 'z_range': [192, 256], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-127f893db5f4>:<module>:022}::[2020-11-22::15:47:55.504]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 256 x 256 x 256\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-9-127f893db5f4>:<module>:026}::[2020-11-22::15:47:55.614]\n",
      "voldata.shape=(256, 256, 256)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-9-127f893db5f4>:<module>:033}::[2020-11-22::15:47:55.616]\n",
      "voldata_train.shape=(256, 256, 128) voldata_val.shape=(256, 256, 64) voldata_test.shape=(256, 256, 64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "voldata_test = volume.test_partition.get_volume_partition(voldata)\n",
    "\n",
    "del voldata\n",
    "logger.debug(f\"{voldata_train.shape=} {voldata_val.shape=} {voldata_test.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop generator (not yet integrated)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_sequential_2d_no_augmentation(\n",
    "    volume_: Volume, \n",
    "    volume_data_: ndarray,\n",
    "    volume_labels_: ndarray,\n",
    "    batch_size_: int,\n",
    "    crop_shape_: Optional[Tuple[int, int, int]] = None,\n",
    "    flat_axis: int = 2,  # where the image is flat\n",
    ") -> VolumeCropSequence:\n",
    "    \n",
    "    volume_shape = volume_data_.shape\n",
    "    \n",
    "    if crop_shape_ is None:\n",
    "        # multiple of 16 (requirement of a 4-level u-net)\n",
    "        crop_shape_ = tuple(\n",
    "            16 * (size // 16) if axis_idx != flat_axis else 1\n",
    "            for axis_idx, size in enumerate(volume_shape)\n",
    "        )\n",
    "        logger.info(f\"Crop shape was not give. Maximum multiple sizes found: {crop_shape_=}\")\n",
    "    \n",
    "    crop_xyz_ranges = {\n",
    "        \"x_range\": (0, volume_shape[0] - crop_shape_[0] + 1),\n",
    "        \"y_range\": (0, volume_shape[1] - crop_shape_[1] + 1),\n",
    "        \"z_range\": (0, volume_shape[2] - crop_shape_[2] + 1),\n",
    "    }\n",
    "    crop_xyz_steps = {\n",
    "        \"x_step\": max(1, volume_shape[0] % crop_shape_[0]),\n",
    "        \"y_step\": max(1, volume_shape[1] % crop_shape_[1]),\n",
    "        \"z_step\": max(1, volume_shape[2] % crop_shape_[2]),\n",
    "    }\n",
    "    logger.debug(f\"{crop_xyz_ranges=} {crop_xyz_steps=}\")\n",
    "    \n",
    "    return VolumeCropSequence(\n",
    "        # data / labels\n",
    "        data_volume=volume_data_,\n",
    "        labels_volume=volume_labels_,\n",
    "        \n",
    "        # metadata\n",
    "        labels=volume.metadata.labels,\n",
    "        \n",
    "        # meta crops\n",
    "        meta_crop_generator = MetaCrop3DGenerator(\n",
    "            volume_shape=volume_shape,\n",
    "            crop_shape=crop_shape_,\n",
    "            \n",
    "            x0y0z0_generator = (\n",
    "                sequential_grid_position_generator := SequentialGridPosition(\n",
    "                    **crop_xyz_ranges, **crop_xyz_steps\n",
    "                )\n",
    "            ),\n",
    "            et_field=ET3DConstantEverywhere.build_no_displacement(**crop_xyz_ranges),\n",
    "            gt_field=GTConstantEverywhere.build_gt2d_identity(**crop_xyz_ranges,),\n",
    "            vs_field=VSConstantEverywhere.build_no_shift(**crop_xyz_ranges),\n",
    "        ),\n",
    "        \n",
    "        # others\n",
    "        batch_size=batch_size_,\n",
    "        epoch_size=len(sequential_grid_position_generator),\n",
    "        meta_crops_hist_path=None,\n",
    "        debug__no_data_check=True,  # remove me!\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_size_per_replica = 1  \n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\")\n",
    "\n",
    "seq_train = get_sequential_2d_no_augmentation(\n",
    "    volume_=volume,\n",
    "    volume_data_=voldata_train,\n",
    "    volume_labels_=vollabels_train,\n",
    "    batch_size_=batch_size,\n",
    ")\n",
    "\n",
    "seq_val = get_sequential_2d_no_augmentation(\n",
    "    volume_=volume,\n",
    "    volume_data_=voldata_val,\n",
    "    volume_labels_=vollabels_val,\n",
    "    batch_size_=batch_size,\n",
    ")\n",
    "\n",
    "seq_test = get_sequential_2d_no_augmentation(\n",
    "    volume_=volume,\n",
    "    volume_data_=voldata_test,\n",
    "    volume_labels_=vollabels_test,\n",
    "    batch_size_=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-10-a4286ac1c483>:<module>:012}::[2020-11-22::15:47:55.677]\n",
      "data_volume.shape=(256, 256, 64) partition=SetPartition(x_range=(0, 256), y_range=(0, 256), z_range=(192, 256), alias='test') agg_strategy=<AggregationStrategy.average_probabilities: 0> runid=1606056473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_volume = voldata_train\n",
    "# partition = volume.train_partition\n",
    "\n",
    "# data_volume = voldata_val\n",
    "# partition = volume.val_partition\n",
    "\n",
    "data_volume = voldata_test\n",
    "partition = volume.test_partition\n",
    "\n",
    "agg_strategy = AggregationStrategy.average_probabilities\n",
    "\n",
    "logger.debug(f\"{data_volume.shape=} {partition=} {agg_strategy=} {runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:metadata_path:290}::[2020-11-22::15:47:55.723]\n",
      "Creating metadata file /home/joaopcbertoldo/projects/tomo2seg/data/vol=PA66GF30.v1-reduced.set=test.model=unet-2d-small.vanilla00.000.1605-982-196.runid=1606-056-473/vol=PA66GF30.v1-reduced.set=test.model=unet-2d-small.vanilla00.000.1605-982-196.runid=1606-056-473.metadata.yml.\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:__setitem__:298}::[2020-11-22::15:47:55.724]\n",
      "Writing to file self.metadata_path=PosixPath('/home/joaopcbertoldo/projects/tomo2seg/data/vol=PA66GF30.v1-reduced.set=test.model=unet-2d-small.vanilla00.000.1605-982-196.runid=1606-056-473/vol=PA66GF30.v1-reduced.set=test.model=unet-2d-small.vanilla00.000.1605-982-196.runid=1606-056-473.metadata.yml').\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-11-ccaae396c38c>:<module>:009}::[2020-11-22::15:47:55.727]\n",
      "estimation_volume=EstimationVolume(volume_fullname='PA66GF30.v1-reduced', model_name='unet-2d-small.vanilla00.000.1605-982-196', runid=1606056473, partition=SetPartition(x_range=(0, 256), y_range=(0, 256), z_range=(192, 256), alias='test'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimation_volume = EstimationVolume.from_objects(\n",
    "    volume=volume, \n",
    "    model=tomo2seg_model, \n",
    "    set_partition=partition,\n",
    "    runid=runid,\n",
    ")\n",
    "estimation_volume[\"aggregation_strategy\"] = agg_strategy.name\n",
    "\n",
    "logger.info(f\"{estimation_volume=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-14-18204e9a3117>:<module>:003}::[2020-11-22::15:51:43.999]\n",
      "figs_dir=PosixPath('/home/joaopcbertoldo/projects/tomo2seg/data/vol=PA66GF30.v1-reduced.set=test.model=unet-2d-small.vanilla00.000.1605-982-196.runid=1606-056-473')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if debug__save_figs:\n",
    "    figs_dir = estimation_volume.dir\n",
    "    logger.debug(f\"{figs_dir=}\")\n",
    "    figs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def crop_coord2data(coordinates: ndarray, data: ndarray) -> ndarray:\n",
    "    \"\"\"\n",
    "    coordinates: 3x2\n",
    "    data: W x H x D\n",
    "    \"\"\"\n",
    "    (x0, x1), (y0, y1), (z0, z1) = coordinates\n",
    "    return data[x0:x1, y0:y1, z0:z1]\n",
    "\n",
    "\n",
    "crop_coord2data__data_loaded = functools.partial(crop_coord2data, data=data_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapes and steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-16-0d701cd4dcc5>:<module>:003}::[2020-11-22::15:54:23.530]\n",
      "xy_dims_multiple_16=[256, 256]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-16-0d701cd4dcc5>:<module>:008}::[2020-11-22::15:54:23.532]\n",
      "crop_shape=(256, 256, 1)   volume_shape=(256, 256, 64)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-16-0d701cd4dcc5>:<module>:014}::[2020-11-22::15:54:23.533]\n",
      "n_steps=(1, 1, 64)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-16-0d701cd4dcc5>:<module>:036}::[2020-11-22::15:54:23.535]\n",
      "min(x0s)=0, max(x0s)=0, len(x0s)=1\n",
      "min(y0s)=0, max(y0s)=0, len(y0s)=1\n",
      "min(z0s)=0, max(z0s)=63, len(z0s)=64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# it has to be multiple of 16 because of the 4 cascaded 2x2-strided 2x2-downsamplings in u-net\n",
    "xy_dims_multiple_16 = [int(16 * np.floor(dim / 16)) for dim in volume.metadata.dimensions[:2]]\n",
    "logger.debug(f\"{xy_dims_multiple_16=}\")\n",
    "\n",
    "crop_shape = tuple(xy_dims_multiple_16 + [1])  # x-axis, y-axis, z-axis\n",
    "volume_shape = data_volume.shape\n",
    "\n",
    "logger.debug(f\"{crop_shape=}   {volume_shape=}\")\n",
    "\n",
    "n_steps = tuple(\n",
    "    int(np.ceil(vol_dim / crop_dim))\n",
    "    for vol_dim, crop_dim in zip(volume_shape, crop_shape)\n",
    ")\n",
    "logger.debug(f\"{n_steps=}\")\n",
    "\n",
    "def get_coordinates_iterator(n_steps_):\n",
    "    assert len(n_steps_) == 3\n",
    "    return itertools.product(*(range(n_steps_[dim]) for dim in range(3)))\n",
    "\n",
    "get_ijk_iterator = functools.partial(\n",
    "    get_coordinates_iterator, copy.copy(n_steps)\n",
    ")\n",
    "\n",
    "get_kji_iterator = functools.partial(\n",
    "    get_coordinates_iterator, tuple(reversed(n_steps))\n",
    ")\n",
    "\n",
    "# coordinates (xs, ys, and zs) of the front upper left corners of the crops\n",
    "x0s, y0s, z0s = tuple(\n",
    "    tuple(map(\n",
    "        int, \n",
    "        np.linspace(0, vol_dim - crop_dim, n)\n",
    "    ))\n",
    "    for vol_dim, crop_dim, n in zip(volume_shape, crop_shape, n_steps)\n",
    ")\n",
    "logger.debug(f\"\"\"{min(x0s)=}, {max(x0s)=}, {len(x0s)=}\n",
    "{min(y0s)=}, {max(y0s)=}, {len(y0s)=}\n",
    "{min(z0s)=}, {max(z0s)=}, {len(z0s)=}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal slices figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_common_kwargs = dict(bbox_inches=\"tight\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug__save_figs:\n",
    "    \n",
    "    logger.debug(f\"Saving figure {(fig_name := 'whole-volume.orthogonal-slices.png')=}\")\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(sz := 20, sz))\n",
    "    viz.plot_orthogonal_slices(axs, data_volume, normalized_voxels=True);\n",
    "    \n",
    "    figpath = figs_dir / fig_name\n",
    "    logger.info(f\"{figpath=}\")\n",
    "    fig.savefig(\n",
    "        fname=figpath,\n",
    "        dpi=200,\n",
    "        **figs_common_kwargs,\n",
    "        metadata={\n",
    "            \"Title\": f\"vol={volume.fullname}::debug-fig::{fig_name}\",\n",
    "            **figs_common_kwargs\n",
    "        }\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "if debug__save_figs:\n",
    "    logger.debug(f\"Saving figure {(fig_name := 'whole-volume.orthogonal-slices-with-(x0s, y0s, z0s).png')=}\")\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(sz := 20, sz))\n",
    "    viz.plot_orthogonal_slices(axs, data_volume, normalized_voxels=True)\n",
    "\n",
    "    ax_xy, ax_yz, ax_xz = axs[0, 0], axs[0, 1], axs[1, 0]\n",
    "    \n",
    "    for x_ in x0s:\n",
    "        ax_xy.vlines(x_, 0, volume_shape[0] - 1, color='g', linewidth=1)\n",
    "        ax_xz.vlines(x_, 0, volume_shape[2] - 1, color='g', linewidth=1)\n",
    "\n",
    "    for y_ in y0s:\n",
    "        ax_xy.hlines(y_, 0, volume_shape[1] - 1, color='r', linewidth=1)\n",
    "        ax_yz.hlines(y_, 0, volume_shape[2] - 1, color='r', linewidth=1)\n",
    "\n",
    "    for z_ in z0s:\n",
    "        ax_yz.vlines(z_, 0, volume_shape[0] - 1, color='b', linewidth=0.2)    \n",
    "        ax_xz.hlines(z_, 0, volume_shape[1] - 1, color='b', linewidth=0.2)\n",
    "    \n",
    "    figpath = figs_dir / fig_name\n",
    "    logger.info(f\"{figpath=}\")\n",
    "    fig.savefig(\n",
    "        fname=figpath,\n",
    "        dpi=200,\n",
    "        **figs_common_kwargs,\n",
    "        metadata={\n",
    "            \"Title\": f\"vol={volume.fullname}::debug-fig::{fig_name}\",\n",
    "            **figs_common_metadata\n",
    "        }\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crops coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Generating the crop coordinates.\")\n",
    "\n",
    "crops_coordinates = np.array(\n",
    "    [\n",
    "        (\n",
    "            (x0, x0 + crop_shape[0]), \n",
    "            (y0, y0 + crop_shape[1]),\n",
    "            (z0, z0 + crop_shape[2]),\n",
    "        )\n",
    "        for x0, y0, z0 in itertools.product(x0s, y0s, z0s)\n",
    "    ], \n",
    "    dtype=tuple\n",
    ").reshape(len(x0s), len(y0s), len(z0s), 3, 2).astype(int)  # 3 = nb of dimenstions, 2 = (start, end)\n",
    "\n",
    "logger.debug(f\"{crops_coordinates.shape=}\\n{crops_coordinates[0, 0, 0]=} \")\n",
    "\n",
    "if debug__save_crops_coordinates:\n",
    "    logger.debug(f\"Saving crops coordinates at {(coords_fname := volume.dir / f'process-volume.execution={execid}.crops-coordinates.npy')=}\")\n",
    "    np.save(coords_fname, crops_coordinates)\n",
    "\n",
    "crops_coordinates_sequential = crops_coordinates.reshape(-1, 3, 2, order='F')  # 'F' reshapes with x varying fastest and z slowest\n",
    "\n",
    "logger.debug(f\"{crops_coordinates_sequential.shape=}\\n{crops_coordinates_sequential[0]=} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-z-slice-crops-locations.png\n",
    "\n",
    "not kept, search fro `one-z-slice-crops-locations.png` in `process-3d-crops-entire-2d-slice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug__materialize_crops\n",
    "\n",
    "same for\n",
    "`debug__materialize_crops`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of 3d crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug__save_figs:\n",
    "\n",
    "    logger.debug(f\"Plotinng {(n_crop_plots := 3)=} examples of 3d crops.\")\n",
    "    \n",
    "    for n, (k, j, i) in enumerate(get_kji_iterator()):\n",
    "                \n",
    "        if n >= n_crop_plots:\n",
    "            break\n",
    "            \n",
    "        logger.debug(f\"{(ijk := (i, j, k))=}\")\n",
    "        \n",
    "        one_crop = crop_coord2data__data_loaded(crops_coordinates[i, j, k])\n",
    "        logger.debug(f\"{one_crop.shape=}\")\n",
    "        \n",
    "        logger.debug(f\"Saving figure {(fig_name := f'crop-{ijk}.orthogonal-slices.png')=}\")    \n",
    "\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=2, ncols=2,\n",
    "            figsize=(sz := 20, sz), \n",
    "            gridspec_kw={\"wspace\": (gridspace := .01), \"hspace\": .5 * gridspace}\n",
    "        )\n",
    "        for ax in axs.ravel():\n",
    "            ax.axis(\"off\")\n",
    "            \n",
    "        viz.plot_orthogonal_slices(axs, one_crop, normalized_voxels=True)\n",
    "        \n",
    "        figpath = figs_dir / fig_name\n",
    "        logger.info(f\"{figpath=}\")\n",
    "        fig.savefig(\n",
    "            fname=figpath,\n",
    "            dpi=200,\n",
    "            **figs_common_kwargs,\n",
    "            metadata={\n",
    "                \"Title\": f\"vol={volume.fullname}::debug-fig::{fig_name}\",\n",
    "                **figs_common_kwargs\n",
    "            }\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Segmenting one crop for debug {(crop_ijk := (0, 0, 0))=}\")\n",
    "\n",
    "crop_coordinates = crops_coordinates[crop_ijk[0], crop_ijk[1], crop_ijk[2]]\n",
    "crop_data = crop_coord2data__data_loaded(crop_coordinates)\n",
    "    \n",
    "logger.debug(f\"{crop_data.shape=}\")\n",
    "\n",
    "# [model] - i call it with a first crop bc if something goes wrong then the error\n",
    "# will appear here instead of in a loop\n",
    "\n",
    "# modelin\n",
    "modelin = crop_data.reshape(1, crop_shape[0], crop_shape[1], 1) \n",
    "logger.debug(f\"{modelin.shape=}\")\n",
    "\n",
    "# modelout\n",
    "modelout = model.predict(modelin, batch_size=1)\n",
    "logger.debug(f\"{modelout.shape=}\")\n",
    "\n",
    "logger.debug(f\"{(n_classes := modelout.shape[-1])=}\")\n",
    "\n",
    "# probas\n",
    "logger.debug(f\"{(crop_probas_target_shape := list(crop_shape) + [n_classes])=}\")\n",
    "crop_probas = modelout.reshape(crop_probas_target_shape).astype(probabilities_dtype)\n",
    "\n",
    "# preds\n",
    "crop_preds = crop_probas.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug__save_figs:\n",
    "    logger.debug(f\"Saving figure {(fig_name := f'crop-{crop_ijk}.prediction.png')=}\")    \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(sz := 20, 2 * sz))\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    axs[0].imshow(crop_data, vmin=0, vmax=1, cmap=cm.gray)\n",
    "    axs[0].set_title(\"data\")\n",
    "    \n",
    "    axs[1].imshow(crop_preds, vmin=0, vmax=n_classes-1, cmap=cm.gray)\n",
    "    axs[1].set_title(\"prediction (classes)\")\n",
    "\n",
    "    figpath = figs_dir / fig_name\n",
    "    logger.info(f\"{figpath=}\")\n",
    "    fig.savefig(\n",
    "        fname=figpath,\n",
    "        dpi=200,\n",
    "        **figs_common_kwargs,\n",
    "        metadata={\n",
    "            \"Title\": f\"vol={volume.fullname}::debug-fig::{fig_name}\",\n",
    "            **figs_common_kwargs\n",
    "        }\n",
    "    )\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

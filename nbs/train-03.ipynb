{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks as keras_callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics as keras_metrics\n",
    "\n",
    "from tomo2seg import slack\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    MetaCrop3DGenerator, VolumeCropSequence,\n",
    "    UniformGridPosition, SequentialGridPosition,\n",
    "    ET3DUniformCuboidAlmostEverywhere, ET3DConstantEverywhere, \n",
    "    GTUniformEverywhere, GTConstantEverywhere, \n",
    "    VSConstantEverywhere, VSUniformEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg import callbacks as tomo2seg_callbacks\n",
    "from tomo2seg import losses as tomo2seg_losses\n",
    "from tomo2seg.schedule import ComposedSchedule, LogSpaceSchedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-9-a53a2ef95cd6>:<module>:005}::[2020-12-09::17:37:01.903]\n",
      "runid=1607466349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time())\n",
    "# runid = 1607466349\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:001}::[2020-12-09::17:35:47.759]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:002}::[2020-12-09::17:35:47.853]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:003}::[2020-12-09::17:35:48.235]\n",
      "Both here should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-6-f863a788f16a>:<module>:010}::[2020-12-09::17:35:56.490]\n",
      "volume_name='PA66GF30' volume_version='v1' labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:258}::[2020-12-09::17:35:57.178]\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:195}::[2020-12-09::17:35:57.181]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:007}::[2020-12-09::17:35:57.196]\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [0, 1300], 'alias': 'train'}, 'val': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1600, 1900], 'alias': 'val'}, 'test': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1300, 1600], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:024}::[2020-12-09::17:35:57.198]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:028}::[2020-12-09::17:36:10.742]\n",
      "voldata.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:033}::[2020-12-09::17:36:10.747]\n",
      "voldata_train.shape=(1300, 1040, 1300)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:034}::[2020-12-09::17:36:10.748]\n",
      "voldata_val.shape=(1300, 1040, 300)\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:040}::[2020-12-09::17:36:13.957]\n",
      "vollabels.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:045}::[2020-12-09::17:36:13.959]\n",
      "vollabels_train.shape=(1300, 1040, 1300)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:046}::[2020-12-09::17:36:13.960]\n",
      "vollabels_val.shape=(1300, 1040, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "n_classes = len(volume.metadata.labels)\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "\n",
    "logger.debug(f\"{voldata_train.shape=}\")\n",
    "logger.debug(f\"{voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "\n",
    "logger.debug(f\"{vollabels_train.shape=}\")\n",
    "logger.debug(f\"{vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already deleted (:\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "except NameError:\n",
    "    print(\"already deleted (:\")\n",
    "else:\n",
    "    del tomo2seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "# crop_shape = (256, 256, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "# bigger crops will have less border effects (?)\n",
    "crop_shape = (112, 112, 112, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "model_master_name = \"unet3d\"\n",
    "model_version = \"crop112-f12\"\n",
    "model_factory_function = modular_unet.u_net\n",
    "model_factory_kwargs = {\n",
    "    **modular_unet.kwargs_vanilla03,\n",
    "    **dict(\n",
    "        convlayer=modular_unet.ConvLayer.conv3d,\n",
    "        input_shape = crop_shape,\n",
    "        output_channels=n_classes,\n",
    "#         nb_filters_0 = 2,\n",
    "#         nb_filters_0 = 4,\n",
    "#         nb_filters_0 = 8,\n",
    "        nb_filters_0 = 12,\n",
    "#         nb_filters_0 = 16,\n",
    "#         nb_filters_0 = 32,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-12-2291d74903ed>:<module>:005}::[2020-12-09::17:37:31.845]\n",
      "Creating a Tomo2SegModel.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-12-2291d74903ed>:<module>:020}::[2020-12-09::17:37:31.846]\n",
      "tomo2seg_model=Model(master_name='unet3d', version='crop112-f12', fold=0, runid=1607466349, factory_function='tomo2seg.modular_unet.u_net', factory_kwargs={'depth': 4, 'sigma_noise': 0, 'updown_conv_sampling': True, 'unet_block_kwargs': {'kernel_size': 3, 'res': True, 'batch_norm': True, 'dropout': 0}, 'unet_down_kwargs': {'batchnorm': True}, 'unet_up_kwargs': {'batchnorm': True}, 'convlayer': <ConvLayer.conv3d: 10>, 'input_shape': (112, 112, 112, 1), 'output_channels': 3, 'nb_filters_0': 12})\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-12-2291d74903ed>:<module>:022}::[2020-12-09::17:37:31.847]\n",
      "Creating the Keras model.\n",
      "\n",
      "WARNING::tomo2seg::{<ipython-input-12-2291d74903ed>:<module>:033}::[2020-12-09::17:37:31.851]\n",
      "An autosaved model already exists, loading it instead of creating a new one!\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO::tomo2seg::{<ipython-input-12-2291d74903ed>:<module>:036}::[2020-12-09::17:37:37.694]\n",
      "Compiling the model.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jcasagrande/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/assets\n",
      "INFO::tomo2seg::{<ipython-input-12-2291d74903ed>:<module>:067}::[2020-12-09::17:37:59.834]\n",
      "Check the summary and the figure of the model in the following locations:\n",
      "/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/summary.txt\n",
      "/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/architecture.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "    \n",
    "except NameError:\n",
    "    logger.info(\"Creating a Tomo2SegModel.\")\n",
    "    \n",
    "    tomo2seg_model = Tomo2SegModel(\n",
    "        model_master_name, \n",
    "        model_version, \n",
    "        runid=runid,\n",
    "        factory_function=model_factory_function,\n",
    "        factory_kwargs=model_factory_kwargs,\n",
    "    )\n",
    "                \n",
    "else:\n",
    "    logger.warning(\"The model is already defined. To create a new one: `del tomo2seg_model`\")\n",
    "\n",
    "finally:\n",
    "    \n",
    "    logger.info(f\"{tomo2seg_model=}\")\n",
    "    \n",
    "logger.info(\"Creating the Keras model.\")\n",
    "\n",
    "with strategy.scope():\n",
    "    if not tomo2seg_model.autosaved_model_path.exists():\n",
    "        logger.info(f\"Instantiating a new model with model_factory_function={model_factory_function.__name__}\")\n",
    "      \n",
    "        model = model_factory_function(\n",
    "            name=tomo2seg_model.name,\n",
    "            **model_factory_kwargs\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\"An autosaved model already exists, loading it instead of creating a new one!\")\n",
    "        model = keras.models.load_model(tomo2seg_model.autosaved_model_path_str, compile=False)\n",
    "\n",
    "    logger.info(\"Compiling the model.\")\n",
    "\n",
    "    # using the avg jaccard is dangerous if one of the classes is too\n",
    "    # underrepresented because it's jaccard will be unstable\n",
    "    loss = tomo2seg_losses.jaccard2_flat\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=.003)\n",
    "    metrics = [\n",
    "#         tomo2seg_losses.jaccard2_macro_avg,\n",
    "#         keras_metrics.Accuracy(),\n",
    "#     ] + [\n",
    "#         tomo2seg_losses.Jaccard2(class_idx)\n",
    "#         for class_idx in range(n_classes)\n",
    "    ]\n",
    "\n",
    "    model.compile(\n",
    "        loss=loss, \n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    model.save(tomo2seg_model.model_path)\n",
    "\n",
    "    # write the model summary in a file\n",
    "    with tomo2seg_model.summary_path.open(\"w\") as f:\n",
    "        def print_to_txt(line):\n",
    "            f.writelines([line + \"\\n\"])\n",
    "        model.summary(print_fn=print_to_txt, line_length=140)\n",
    "\n",
    "    # same for the architecture\n",
    "    utils.plot_model(model, show_shapes=True, to_file=tomo2seg_model.architecture_plot_path);\n",
    "\n",
    "    logger.info(f\"Check the summary and the figure of the model in the following locations:\\n{tomo2seg_model.summary_path}\\n{tomo2seg_model.architecture_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "# Data crop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-15-b6382cff3437>:<module>:006}::[2020-12-09::17:38:09.638]\n",
      "batch_size_per_replica=1\n",
      "n_replicas=2\n",
      "batch_size=2\n",
      "common_random_state=144\n",
      "crop_shape=(112, 112, 112, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size_per_replica = 1\n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "\n",
    "common_random_state = 144  # i resumed the training so i changed this\n",
    "\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\\n{common_random_state=}\\n{crop_shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:438}::[2020-12-09::17:38:38.486]\n",
      "Built UniformGridPosition from volume_shape=(1300, 1040, 1300) and crop_shape=(112, 112, 112, 1) ==> {'x_range': (0, 1189), 'y_range': (0, 929), 'z_range': (0, 1189)}\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:400}::[2020-12-09::17:38:38.488]\n",
      "UniformGridPosition ==> npositions=1313346809 (1,313,346,809)\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-09::17:38:38.489]\n",
      "Initializing ET3DConstantEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-09::17:38:38.490]\n",
      "Initializing GTUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-09::17:38:38.491]\n",
      "Initializing VSUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:1353}::[2020-12-09::17:38:38.492]\n",
      "Initializing VolumeCropSequence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = voldata_train\n",
    "labels = vollabels_train\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := UniformGridPosition.build_from_volume_crop_shapes(\n",
    "                volume_shape=volume_shape, \n",
    "                crop_shape=crop_shape,\n",
    "                random_state=RandomState(common_random_state),\n",
    "            )\n",
    "        ),\n",
    "        # it is too slow to use this\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator=grid_pos_gen),\n",
    "#         gt_field=GTUniformEverywhere.build_2d(\n",
    "        gt_field=GTUniformEverywhere.build_3d(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "        ),\n",
    "        vs_field=VSUniformEverywhere.build_plus_or_mines(\n",
    "            shift=1. / 255 / 2,  # half a value to both sides +/-\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "            random_state=RandomState(common_random_state),\n",
    "        ),\n",
    "        is_2halfd=True,\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "#     epoch_size=5,\n",
    "    epoch_size=1,\n",
    "    meta_crops_hist_path=tomo2seg_model.train_metacrop_history_path,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    "#     output_as_2d=True,\n",
    "#     output_as_2halfd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{volume_sequence.py:build_min_overlap:506}::[2020-12-09::17:38:46.312]\n",
      "Building SequentialGridPosition with minimal overlap (smallest n_steps in each directions) n_steps={'n_steps_x': 12, 'n_steps_y': 10, 'n_steps_z': 3}.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:build_min_overlap:509}::[2020-12-09::17:38:46.313]\n",
      "n_steps_kwargs={'n_steps_z': 8} was given --> effective n_steps={'n_steps_x': 12, 'n_steps_y': 10, 'n_steps_z': 8}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:438}::[2020-12-09::17:38:46.314]\n",
      "Built SequentialGridPosition from volume_shape=(1300, 1040, 300) and crop_shape=(112, 112, 112, 1) ==> {'x_range': (0, 1189), 'y_range': (0, 929), 'z_range': (0, 189)}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:__post_init__:486}::[2020-12-09::17:38:46.322]\n",
      "The SequentialGridPosition has len(self.positions)=960 different positions (therefore crops).\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-09::17:38:46.323]\n",
      "Initializing ET3DConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-09::17:38:46.323]\n",
      "Initializing GTConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-09::17:38:46.324]\n",
      "Initializing VSConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:1353}::[2020-12-09::17:38:46.325]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:1385}::[2020-12-09::17:38:46.326]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# val volume\n",
    "\n",
    "data = voldata_val\n",
    "labels = vollabels_val\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    # data source\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    \n",
    "    # data augmentation\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := SequentialGridPosition.build_min_overlap(\n",
    "                volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "                # reduce the total number of crops\n",
    "#                 n_steps_x=15,\n",
    "#                 n_steps_y=15,\n",
    "                # increase the total number of crops\n",
    "                n_steps_z=8,\n",
    "            )\n",
    "#             grid_pos_gen := SequentialGridPosition.build_from_volume_crop_shapes(\n",
    "#                 volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "#                 n_steps_x=2, n_steps_y=2, n_steps_z=200,\n",
    "#             )\n",
    "        ),\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator=grid_pos_gen),\n",
    "#         gt_field=GTConstantEverywhere.build_gt2d_identity(grid_position_generator=grid_pos_gen),\n",
    "        gt_field=GTConstantEverywhere.build_gt3d_identity(grid_position_generator=grid_pos_gen),\n",
    "        vs_field=VSConstantEverywhere.build_no_shift(grid_position_generator=grid_pos_gen),\n",
    "        is_2halfd=True,\n",
    "    ),\n",
    "    \n",
    "    # others\n",
    "    batch_size=batch_size,\n",
    "    epoch_size=len(grid_pos_gen),  # go through all the crops in validation    \n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    "    \n",
    "#     output_as_2d=True,\n",
    "#     output_as_2halfd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{callbacks.py:__init__:051}::[2020-12-09::17:56:47.561]\n",
      "Loading history from csv self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv').\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autosave_cb = keras_callbacks.ModelCheckpoint(\n",
    "    tomo2seg_model.autosaved_model_path_str, \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=2, \n",
    "    save_best_only=True, \n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "# todo load if it already exists\n",
    "try:\n",
    "    history_cb\n",
    "    \n",
    "except NameError:\n",
    "    history_cb = tomo2seg_callbacks.History(\n",
    "        optimizer=model.optimizer,\n",
    "        crop_seq_train=crop_seq_train,\n",
    "        crop_seq_val=crop_seq_val,\n",
    "        backup=1,\n",
    "        csv_path=tomo2seg_model.history_path,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    logger.warning(\"The history callback already exists!\")\n",
    "    \n",
    "    history_df = history_cb.dataframe\n",
    "\n",
    "    try:\n",
    "        history_df_temp = pd.read_csv(history_cb.csv_path)\n",
    "        \n",
    "        # keep the longest one\n",
    "        history_df = history_df if (\n",
    "            history_df.shape[0] >= history_df_temp.shape[0] and\n",
    "            history_df[\"epoch\"][-1] > history_df_temp[\"epoch\"][-1]\n",
    "        ) else history_df_temp\n",
    "        \n",
    "        del history_df_temp\n",
    "        \n",
    "        history_cb.history = history_df.to_dict(orient=\"list\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "finally:\n",
    "    # make sure the correct objects are linked \n",
    "    history_cb.optimizer = model.optimizer\n",
    "    history_cb.crop_seq_train = crop_seq_train\n",
    "    history_cb.crop_seq_val = crop_seq_val\n",
    "    # todo do the same with other objs in history_cb\n",
    "    \n",
    "history_plot_cb = tomo2seg_callbacks.HistoryPlot(\n",
    "    history_callback=history_cb,\n",
    "    save_path=tomo2seg_model.train_history_plot_wip_path\n",
    ")\n",
    "\n",
    "early_stop_cb = keras_callbacks.EarlyStopping(  # todo modify the early stopping to take more conditions (don't stop too early before it doesnt break the jaccard2=.32)\n",
    "    monitor='val_loss', \n",
    "    min_delta=.1 / 100, \n",
    "    patience=50,\n",
    "    verbose=2, \n",
    "    mode='auto',\n",
    "    baseline=.71,  # 0th-order classifier\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training\n",
    "\n",
    "stuff that i use after the training but i want it to appear in the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Volume slices\n",
    "\n",
    "todo do this in a notebook\n",
    "\n",
    "## Generator samples\n",
    "\n",
    "todo do this in a notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangular log lr schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-09::18:27:07.780]\n",
      "LogSpaceSchedule ==> self.n=10\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-09::18:27:07.782]\n",
      "LogSpaceSchedule ==> self.n=30\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-09::18:27:07.783]\n",
      "LogSpaceSchedule ==> self.n=20\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-09::18:27:07.784]\n",
      "LogSpaceSchedule ==> self.n=40\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-09::18:27:07.785]\n",
      "LogSpaceSchedule ==> self.n=20\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-09::18:27:07.785]\n",
      "LogSpaceSchedule ==> self.n=40\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:107}::[2020-12-09::18:27:07.786]\n",
      "ComposedSchedule ==> self.n=160\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-57-95099433ae50>:<module>:021}::[2020-12-09::18:27:07.787]\n",
      "(0, 160)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### from tensorflow.keras import backend as K\n",
    "# lr = 0.001\n",
    "# K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "lr_schedule_cb = keras_callbacks.LearningRateScheduler(\n",
    "    schedule= (schedule := ComposedSchedule(\n",
    "        offset_epoch=0,\n",
    "        sub_schedules=[\n",
    "            LogSpaceSchedule(0, wait=0, start=-4, stop=-3, n_between_scales=8), \n",
    "            LogSpaceSchedule(10, wait=20, start=-3, stop=-4, n_between_scales=8),\n",
    "            LogSpaceSchedule(40, wait=0, start=-4, stop=-3, n_between_scales=18),\n",
    "            LogSpaceSchedule(60, wait=20, start=-3, stop=-4, n_between_scales=18),\n",
    "            LogSpaceSchedule(100, wait=0, start=-4, stop=-3, n_between_scales=18),\n",
    "            LogSpaceSchedule(120, wait=20, start=-3, stop=-4, n_between_scales=18),\n",
    "#             LogSpaceSchedule(160, wait=50, start=-4, stop=-5, n_between_scales=48),\n",
    "        ]\n",
    "    )),\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.info(f\"{schedule.range}\")\n",
    "\n",
    "crop_seq_train.epoch_size = 10\n",
    "\n",
    "callbacks = [\n",
    "    keras_callbacks.TerminateOnNaN(),\n",
    "    autosave_cb,\n",
    "    history_cb,\n",
    "    history_plot_cb,\n",
    "    lr_schedule_cb,\n",
    "#     early_stop_cb,\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "history_cb.history[\"train.crop_shape\"] = [\n",
    "    literal_eval(x) if isinstance(x, str) else x\n",
    "    for x in history_cb.history[\"train.crop_shape\"]\n",
    "]\n",
    "\n",
    "history_cb.history[\"val.crop_shape\"] = [\n",
    "    literal_eval(x) if isinstance(x, str) else x\n",
    "    for x in history_cb.history[\"val.crop_shape\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to 0.000379269019073225.\n",
      "Epoch 149/400\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.01978 to 0.01943, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::18:34:38.629]\n",
      "Saving backup of the training history epoch=148 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::18:34:38.729]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:34:38.776]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:34:38.779]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 433s - loss: 0.0172 - val_loss: 0.0194 - lr: 3.7927e-04\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to 0.0003359818286283781.\n",
      "Epoch 150/400\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01943\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::18:41:48.851]\n",
      "Saving backup of the training history epoch=149 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::18:41:48.946]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:41:48.990]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:41:48.993]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0182 - val_loss: 0.0198 - lr: 3.3598e-04\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to 0.00029763514416313193.\n",
      "Epoch 151/400\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.01943 to 0.01896, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::18:49:05.444]\n",
      "Saving backup of the training history epoch=150 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::18:49:05.532]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:49:05.575]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:49:05.578]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 435s - loss: 0.0191 - val_loss: 0.0190 - lr: 2.9764e-04\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to 0.00026366508987303583.\n",
      "Epoch 152/400\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01896 to 0.01890, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::18:56:21.659]\n",
      "Saving backup of the training history epoch=151 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::18:56:21.746]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:56:21.787]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::18:56:21.790]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 434s - loss: 0.0177 - val_loss: 0.0189 - lr: 2.6367e-04\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to 0.00023357214690901214.\n",
      "Epoch 153/400\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01890\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:03:31.446]\n",
      "Saving backup of the training history epoch=152 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:03:31.511]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:03:31.543]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:03:31.546]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0171 - val_loss: 0.0191 - lr: 2.3357e-04\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to 0.00020691380811147902.\n",
      "Epoch 154/400\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01890\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:10:40.904]\n",
      "Saving backup of the training history epoch=153 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:10:41.011]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:10:41.055]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:10:41.058]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0177 - val_loss: 0.0190 - lr: 2.0691e-04\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to 0.00018329807108324357.\n",
      "Epoch 155/400\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01890\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:17:51.050]\n",
      "Saving backup of the training history epoch=154 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:17:51.137]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:17:51.176]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:17:51.179]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0205 - val_loss: 0.0191 - lr: 1.8330e-04\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to 0.0001623776739188721.\n",
      "Epoch 156/400\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01890\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:25:00.803]\n",
      "Saving backup of the training history epoch=155 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:25:00.890]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:25:00.929]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:25:00.932]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0165 - val_loss: 0.0190 - lr: 1.6238e-04\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to 0.0001438449888287663.\n",
      "Epoch 157/400\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01890\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:32:10.589]\n",
      "Saving backup of the training history epoch=156 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:32:10.681]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:32:10.723]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:32:10.726]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0165 - val_loss: 0.0189 - lr: 1.4384e-04\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to 0.00012742749857031348.\n",
      "Epoch 158/400\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.01890 to 0.01889, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:39:27.130]\n",
      "Saving backup of the training history epoch=157 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:39:27.396]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:39:27.446]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:39:27.451]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 435s - loss: 0.0168 - val_loss: 0.0189 - lr: 1.2743e-04\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to 0.00011288378916846895.\n",
      "Epoch 159/400\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.01889 to 0.01888, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:46:43.581]\n",
      "Saving backup of the training history epoch=158 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:46:43.669]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:46:44.317]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:46:44.320]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 435s - loss: 0.0191 - val_loss: 0.0189 - lr: 1.1288e-04\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 160/400\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01888\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::19:53:54.009]\n",
      "Saving backup of the training history epoch=159 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::19:53:54.103]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:53:54.145]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::19:53:54.148]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0177 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 161/400\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.01888 to 0.01887, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:01:11.206]\n",
      "Saving backup of the training history epoch=160 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:01:11.295]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:01:11.337]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:01:11.340]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 435s - loss: 0.0191 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 162/400\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01887\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:08:20.899]\n",
      "Saving backup of the training history epoch=161 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:08:21.136]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:08:21.183]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:08:21.187]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0171 - val_loss: 0.0192 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 163/400\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01887\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:15:31.222]\n",
      "Saving backup of the training history epoch=162 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:15:31.333]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:15:31.379]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:15:31.382]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0167 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 164/400\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01887\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:22:41.142]\n",
      "Saving backup of the training history epoch=163 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:22:41.206]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:22:41.237]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:22:41.239]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0161 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 165/400\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.01887\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:29:50.853]\n",
      "Saving backup of the training history epoch=164 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:29:50.909]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:29:50.939]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:29:50.942]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0170 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 166/400\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01887\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:37:00.491]\n",
      "Saving backup of the training history epoch=165 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:37:00.558]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:37:00.589]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:37:00.592]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0190 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 167/400\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01887\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:44:10.611]\n",
      "Saving backup of the training history epoch=166 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:44:10.718]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:44:10.762]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:44:10.765]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0166 - val_loss: 0.0192 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 168/400\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.01887 to 0.01883, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:51:26.731]\n",
      "Saving backup of the training history epoch=167 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:51:26.820]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:51:26.863]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:51:26.866]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 435s - loss: 0.0175 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 169/400\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::20:58:37.261]\n",
      "Saving backup of the training history epoch=168 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::20:58:37.365]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:58:37.410]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::20:58:37.413]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 428s - loss: 0.0175 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 170/400\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:05:48.769]\n",
      "Saving backup of the training history epoch=169 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:05:48.835]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:05:48.865]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:05:48.868]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0160 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 171/400\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:12:59.472]\n",
      "Saving backup of the training history epoch=170 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:12:59.580]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:12:59.626]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:12:59.629]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 172/400\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:20:10.224]\n",
      "Saving backup of the training history epoch=171 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:20:10.326]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:20:10.371]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:20:10.374]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0187 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 173/400\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:27:20.904]\n",
      "Saving backup of the training history epoch=172 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:27:21.002]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:27:21.044]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:27:21.047]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0185 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 174/400\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:34:31.413]\n",
      "Saving backup of the training history epoch=173 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:34:32.982]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:34:33.029]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:34:33.033]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 430s - loss: 0.0182 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 175/400\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:41:43.611]\n",
      "Saving backup of the training history epoch=174 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:41:43.715]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:41:43.759]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:41:43.762]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0185 - val_loss: 0.0192 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 176/400\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:48:54.304]\n",
      "Saving backup of the training history epoch=175 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:48:54.404]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:48:54.447]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:48:54.450]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0164 - val_loss: 0.0193 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 177/400\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::21:56:04.700]\n",
      "Saving backup of the training history epoch=176 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::21:56:04.797]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:56:04.840]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::21:56:04.842]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0174 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 178/400\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:03:15.358]\n",
      "Saving backup of the training history epoch=177 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:03:15.448]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:03:15.489]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:03:15.492]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 179/400\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:10:26.054]\n",
      "Saving backup of the training history epoch=178 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:10:26.156]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:10:26.200]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:10:26.203]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0194 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 180/400\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:17:36.595]\n",
      "Saving backup of the training history epoch=179 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:17:36.691]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:17:36.732]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:17:36.735]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0192 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 181/400\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.01883\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:24:48.038]\n",
      "Saving backup of the training history epoch=180 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:24:48.154]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:24:48.203]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:24:48.207]\n",
      "val: argmin=101 --> min=0.0188\n",
      "\n",
      "10/10 - 430s - loss: 0.0175 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 182/400\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.01883 to 0.01875, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:32:05.551]\n",
      "Saving backup of the training history epoch=181 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:32:05.647]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:32:05.686]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:32:05.689]\n",
      "val: argmin=181 --> min=0.0187\n",
      "\n",
      "10/10 - 436s - loss: 0.0173 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 183/400\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.01875\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:39:15.976]\n",
      "Saving backup of the training history epoch=182 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:39:16.076]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:39:16.119]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:39:16.121]\n",
      "val: argmin=181 --> min=0.0187\n",
      "\n",
      "10/10 - 428s - loss: 0.0174 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 184/400\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.01875\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:46:26.084]\n",
      "Saving backup of the training history epoch=183 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:46:26.179]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:46:26.225]\n",
      "train: argmin=97 --> min=0.0156\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:46:26.228]\n",
      "val: argmin=181 --> min=0.0187\n",
      "\n",
      "10/10 - 428s - loss: 0.0161 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 185/400\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.01875\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::22:53:36.128]\n",
      "Saving backup of the training history epoch=184 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::22:53:36.188]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:53:36.222]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::22:53:36.225]\n",
      "val: argmin=181 --> min=0.0187\n",
      "\n",
      "10/10 - 428s - loss: 0.0151 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 186/400\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.01875 to 0.01874, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:00:51.033]\n",
      "Saving backup of the training history epoch=185 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:00:51.119]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:00:51.162]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:00:51.165]\n",
      "val: argmin=185 --> min=0.0187\n",
      "\n",
      "10/10 - 433s - loss: 0.0171 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 187/400\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.01874 to 0.01864, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:08:07.853]\n",
      "Saving backup of the training history epoch=186 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:08:07.941]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:08:07.983]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:08:07.985]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 435s - loss: 0.0173 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 188/400\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:15:17.983]\n",
      "Saving backup of the training history epoch=187 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:15:18.049]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:15:18.080]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:15:18.082]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 428s - loss: 0.0175 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 189/400\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:22:28.354]\n",
      "Saving backup of the training history epoch=188 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:22:28.462]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:22:28.509]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:22:28.513]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 428s - loss: 0.0171 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 190/400\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:29:38.456]\n",
      "Saving backup of the training history epoch=189 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:29:38.562]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:29:38.607]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:29:38.610]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 428s - loss: 0.0175 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 191/400\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:36:48.634]\n",
      "Saving backup of the training history epoch=190 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:36:48.708]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:36:48.741]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:36:48.743]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0159 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 192/400\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:43:59.911]\n",
      "Saving backup of the training history epoch=191 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:44:00.012]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:44:00.057]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:44:00.060]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0170 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 193/400\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:51:09.983]\n",
      "Saving backup of the training history epoch=192 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:51:10.099]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:51:10.147]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:51:10.150]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 428s - loss: 0.0192 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 194/400\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-09::23:58:21.224]\n",
      "Saving backup of the training history epoch=193 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-09::23:58:21.333]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:58:21.379]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-09::23:58:21.382]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0183 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 195/400\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:05:31.674]\n",
      "Saving backup of the training history epoch=194 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:05:31.767]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:05:31.807]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:05:31.810]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0175 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 196/400\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:12:42.191]\n",
      "Saving backup of the training history epoch=195 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:12:42.261]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:12:42.297]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:12:42.299]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0171 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 197/400\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:19:52.787]\n",
      "Saving backup of the training history epoch=196 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:19:52.905]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:19:52.952]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:19:52.955]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0172 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 198/400\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:27:03.427]\n",
      "Saving backup of the training history epoch=197 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:27:03.546]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:27:03.593]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:27:03.596]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0168 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 199/400\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01864\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:34:14.181]\n",
      "Saving backup of the training history epoch=198 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:34:14.275]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:34:14.317]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:34:14.319]\n",
      "val: argmin=186 --> min=0.0186\n",
      "\n",
      "10/10 - 429s - loss: 0.0166 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 200/400\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.01864 to 0.01846, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:41:29.429]\n",
      "Saving backup of the training history epoch=199 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:41:29.518]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:41:29.558]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:41:29.561]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 433s - loss: 0.0161 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 201/400\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:48:39.943]\n",
      "Saving backup of the training history epoch=200 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:48:40.059]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:48:40.107]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:48:40.110]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0180 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 202/400\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::00:55:50.339]\n",
      "Saving backup of the training history epoch=201 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::00:55:50.428]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:55:50.469]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::00:55:50.472]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0180 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 203/400\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:03:00.804]\n",
      "Saving backup of the training history epoch=202 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:03:00.895]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:03:00.934]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:03:00.937]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0172 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 204/400\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:10:11.410]\n",
      "Saving backup of the training history epoch=203 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:10:11.505]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:10:11.547]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:10:11.550]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0177 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 205/400\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:17:22.835]\n",
      "Saving backup of the training history epoch=204 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:17:22.938]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:17:22.983]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:17:22.986]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0173 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 206/400\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:24:33.565]\n",
      "Saving backup of the training history epoch=205 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:24:33.631]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:24:33.662]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:24:33.664]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0181 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 207/400\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:31:44.330]\n",
      "Saving backup of the training history epoch=206 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:31:44.426]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:31:44.471]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:31:44.474]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0175 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 208/400\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:38:55.634]\n",
      "Saving backup of the training history epoch=207 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:38:55.731]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:38:55.773]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:38:55.775]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0173 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 209/400\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:46:06.579]\n",
      "Saving backup of the training history epoch=208 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:46:06.681]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:46:06.726]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:46:06.729]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0174 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 210/400\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::01:53:17.330]\n",
      "Saving backup of the training history epoch=209 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::01:53:17.433]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:53:17.475]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::01:53:17.478]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0163 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 211/400\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:00:27.864]\n",
      "Saving backup of the training history epoch=210 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:00:27.935]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:00:27.966]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:00:27.968]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0176 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 212/400\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:07:38.381]\n",
      "Saving backup of the training history epoch=211 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:07:38.451]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:07:38.483]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:07:38.485]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0181 - val_loss: 0.0188 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 213/400\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:14:48.746]\n",
      "Saving backup of the training history epoch=212 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:14:48.870]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:14:48.916]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:14:48.919]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0160 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 214/400\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:21:59.147]\n",
      "Saving backup of the training history epoch=213 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:21:59.230]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:21:59.268]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:21:59.271]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 428s - loss: 0.0163 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 215/400\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:29:09.446]\n",
      "Saving backup of the training history epoch=214 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:29:09.550]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:29:09.594]\n",
      "train: argmin=184 --> min=0.0151\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:29:09.597]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 428s - loss: 0.0173 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 216/400\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:36:19.841]\n",
      "Saving backup of the training history epoch=215 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:36:19.917]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:36:19.951]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:36:19.953]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 430s - loss: 0.0147 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 217/400\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:43:31.987]\n",
      "Saving backup of the training history epoch=216 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:43:32.093]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:43:32.137]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:43:32.140]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 428s - loss: 0.0188 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 218/400\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:50:42.652]\n",
      "Saving backup of the training history epoch=217 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:50:42.773]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:50:42.820]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:50:42.823]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0176 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 219/400\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::02:57:52.947]\n",
      "Saving backup of the training history epoch=218 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::02:57:53.012]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:57:53.047]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::02:57:53.050]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 428s - loss: 0.0175 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 220/400\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:05:03.504]\n",
      "Saving backup of the training history epoch=219 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:05:03.569]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:05:03.599]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:05:03.601]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0182 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 221/400\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:12:13.828]\n",
      "Saving backup of the training history epoch=220 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:12:13.934]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:12:13.976]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:12:13.979]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 428s - loss: 0.0176 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 222/400\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:19:24.421]\n",
      "Saving backup of the training history epoch=221 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:19:24.538]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:19:24.583]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:19:24.586]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0171 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 223/400\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:26:35.305]\n",
      "Saving backup of the training history epoch=222 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:26:35.373]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:26:35.405]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:26:35.407]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0160 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 224/400\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:33:46.870]\n",
      "Saving backup of the training history epoch=223 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:33:46.982]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:33:47.028]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:33:47.031]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 430s - loss: 0.0162 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 225/400\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:40:57.170]\n",
      "Saving backup of the training history epoch=224 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:40:57.265]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:40:57.306]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:40:57.309]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 428s - loss: 0.0163 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 226/400\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.01846\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:48:07.820]\n",
      "Saving backup of the training history epoch=225 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:48:07.932]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:48:07.978]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:48:07.981]\n",
      "val: argmin=199 --> min=0.0185\n",
      "\n",
      "10/10 - 429s - loss: 0.0166 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 227/400\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.01846 to 0.01828, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::03:55:26.881]\n",
      "Saving backup of the training history epoch=226 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::03:55:26.975]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:55:27.018]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::03:55:27.021]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 437s - loss: 0.0183 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 228/400\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:02:37.533]\n",
      "Saving backup of the training history epoch=227 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:02:37.647]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:02:37.693]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:02:37.696]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0186 - val_loss: 0.0190 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 229/400\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:09:48.194]\n",
      "Saving backup of the training history epoch=228 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:09:48.296]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:09:48.338]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:09:48.341]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0162 - val_loss: 0.0191 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 230/400\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:16:58.578]\n",
      "Saving backup of the training history epoch=229 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:16:58.633]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:16:58.664]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:16:58.667]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 428s - loss: 0.0170 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 231/400\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:24:09.099]\n",
      "Saving backup of the training history epoch=230 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:24:09.209]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:24:09.253]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:24:09.257]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0169 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 232/400\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:31:19.784]\n",
      "Saving backup of the training history epoch=231 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:31:19.888]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:31:19.932]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:31:19.935]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0166 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 233/400\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:38:30.419]\n",
      "Saving backup of the training history epoch=232 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:38:30.485]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:38:30.516]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:38:30.518]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 234/400\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:45:40.891]\n",
      "Saving backup of the training history epoch=233 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:45:40.995]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:45:41.040]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:45:41.042]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0179 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 235/400\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::04:52:51.701]\n",
      "Saving backup of the training history epoch=234 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::04:52:51.797]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:52:51.842]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::04:52:51.845]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0155 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 236/400\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:00:02.403]\n",
      "Saving backup of the training history epoch=235 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:00:02.513]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:00:02.557]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:00:02.560]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0172 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 237/400\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:07:13.263]\n",
      "Saving backup of the training history epoch=236 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:07:13.352]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:07:13.391]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:07:13.394]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0181 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 238/400\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:14:23.705]\n",
      "Saving backup of the training history epoch=237 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:14:23.810]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:14:23.855]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:14:23.858]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0163 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 239/400\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:21:34.204]\n",
      "Saving backup of the training history epoch=238 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:21:34.309]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:21:34.351]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:21:34.354]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0169 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 240/400\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:28:44.920]\n",
      "Saving backup of the training history epoch=239 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:28:45.033]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:28:45.079]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:28:45.081]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0167 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 241/400\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:35:55.475]\n",
      "Saving backup of the training history epoch=240 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:35:55.576]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:35:55.617]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:35:55.620]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 242/400\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:43:07.123]\n",
      "Saving backup of the training history epoch=241 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:43:07.229]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:43:07.273]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:43:07.276]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 430s - loss: 0.0169 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 243/400\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:50:17.880]\n",
      "Saving backup of the training history epoch=242 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:50:17.988]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:50:18.031]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:50:18.034]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0181 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 244/400\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::05:57:28.742]\n",
      "Saving backup of the training history epoch=243 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::05:57:28.845]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:57:28.886]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::05:57:28.888]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 245/400\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:04:39.668]\n",
      "Saving backup of the training history epoch=244 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:04:39.730]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:04:39.759]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:04:39.762]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0169 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 246/400\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:11:50.271]\n",
      "Saving backup of the training history epoch=245 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:11:50.380]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:11:50.425]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:11:50.428]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0180 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 247/400\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:19:00.973]\n",
      "Saving backup of the training history epoch=246 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:19:01.080]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:19:01.124]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:19:01.127]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0163 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 248/400\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:26:11.467]\n",
      "Saving backup of the training history epoch=247 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:26:11.533]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:26:11.563]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:26:11.565]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 249/400\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:33:22.169]\n",
      "Saving backup of the training history epoch=248 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:33:22.269]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:33:22.310]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:33:22.313]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0189 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 250/400\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:40:33.438]\n",
      "Saving backup of the training history epoch=249 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:40:33.565]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:40:33.611]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:40:33.614]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 251/400\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:47:44.089]\n",
      "Saving backup of the training history epoch=250 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:47:44.191]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:47:44.232]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:47:44.235]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0170 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 252/400\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::06:54:54.533]\n",
      "Saving backup of the training history epoch=251 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::06:54:54.594]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:54:54.623]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::06:54:54.625]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0168 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 253/400\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:02:04.921]\n",
      "Saving backup of the training history epoch=252 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:02:04.996]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:02:05.029]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:02:05.031]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0186 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 254/400\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:09:15.516]\n",
      "Saving backup of the training history epoch=253 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:09:15.584]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:09:15.627]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:09:15.629]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0166 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 255/400\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:16:26.064]\n",
      "Saving backup of the training history epoch=254 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:16:26.129]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:16:26.160]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:16:26.163]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0157 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 256/400\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:23:36.368]\n",
      "Saving backup of the training history epoch=255 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:23:36.480]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:23:36.526]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:23:36.529]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 428s - loss: 0.0177 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 257/400\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:30:46.848]\n",
      "Saving backup of the training history epoch=256 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:30:46.961]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:30:47.007]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:30:47.010]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0155 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 258/400\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:37:58.058]\n",
      "Saving backup of the training history epoch=257 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:37:58.157]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:37:58.198]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:37:58.201]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0163 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 259/400\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:45:08.661]\n",
      "Saving backup of the training history epoch=258 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:45:08.764]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:45:08.805]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:45:08.808]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0169 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 260/400\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:52:19.591]\n",
      "Saving backup of the training history epoch=259 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:52:19.657]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:52:19.688]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:52:19.690]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 429s - loss: 0.0151 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 261/400\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.01828\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::07:59:30.342]\n",
      "Saving backup of the training history epoch=260 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::07:59:30.443]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:59:30.483]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::07:59:30.486]\n",
      "val: argmin=226 --> min=0.0183\n",
      "\n",
      "10/10 - 430s - loss: 0.0177 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 262/400\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.01828 to 0.01819, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:06:50.528]\n",
      "Saving backup of the training history epoch=261 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:06:50.620]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:06:50.661]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:06:50.664]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 437s - loss: 0.0171 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 263/400\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:14:01.207]\n",
      "Saving backup of the training history epoch=262 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:14:01.304]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:14:01.346]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:14:01.349]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0167 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 264/400\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:21:11.833]\n",
      "Saving backup of the training history epoch=263 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:21:11.919]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:21:11.954]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:21:11.957]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0155 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 265/400\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:28:22.346]\n",
      "Saving backup of the training history epoch=264 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:28:22.476]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:28:22.527]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:28:22.530]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 266/400\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:35:32.869]\n",
      "Saving backup of the training history epoch=265 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:35:32.965]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:35:33.007]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:35:33.010]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0178 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 267/400\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:42:43.321]\n",
      "Saving backup of the training history epoch=266 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:42:43.435]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:42:43.481]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:42:43.483]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0178 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 268/400\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:49:53.982]\n",
      "Saving backup of the training history epoch=267 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:49:54.088]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:49:54.131]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:49:54.133]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0169 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 269/400\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::08:57:04.839]\n",
      "Saving backup of the training history epoch=268 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::08:57:04.945]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:57:04.986]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::08:57:04.989]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0155 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 270/400\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:04:16.377]\n",
      "Saving backup of the training history epoch=269 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:04:16.481]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:04:16.526]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:04:16.529]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 430s - loss: 0.0179 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 271/400\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:11:26.826]\n",
      "Saving backup of the training history epoch=270 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:11:26.890]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:11:26.921]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:11:26.924]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 428s - loss: 0.0167 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 272/400\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:18:37.423]\n",
      "Saving backup of the training history epoch=271 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:18:37.526]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:18:37.569]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:18:37.572]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0183 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 273/400\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:25:48.027]\n",
      "Saving backup of the training history epoch=272 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:25:48.095]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:25:48.127]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:25:48.133]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0173 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 274/400\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:32:58.652]\n",
      "Saving backup of the training history epoch=273 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:32:58.762]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:32:58.806]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:32:58.809]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0170 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 275/400\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:40:09.173]\n",
      "Saving backup of the training history epoch=274 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:40:09.285]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:40:09.328]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:40:09.331]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0160 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 276/400\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:47:19.772]\n",
      "Saving backup of the training history epoch=275 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:47:19.903]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:47:19.949]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:47:19.952]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0166 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 277/400\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::09:54:30.325]\n",
      "Saving backup of the training history epoch=276 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::09:54:30.422]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:54:30.463]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::09:54:30.466]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 278/400\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:01:40.953]\n",
      "Saving backup of the training history epoch=277 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:01:41.017]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:01:41.048]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:01:41.050]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 279/400\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:08:51.865]\n",
      "Saving backup of the training history epoch=278 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:08:51.960]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:08:52.001]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:08:52.003]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0163 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 280/400\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:16:02.608]\n",
      "Saving backup of the training history epoch=279 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:16:02.719]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:16:02.764]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:16:02.767]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0181 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 281/400\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:23:13.378]\n",
      "Saving backup of the training history epoch=280 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:23:13.481]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:23:13.525]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:23:13.528]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0162 - val_loss: 0.0186 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 282/400\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:30:24.158]\n",
      "Saving backup of the training history epoch=281 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:30:24.258]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:30:24.299]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:30:24.301]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0177 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 283/400\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:37:34.759]\n",
      "Saving backup of the training history epoch=282 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:37:34.859]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:37:34.899]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:37:34.902]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 430s - loss: 0.0159 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 284/400\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:44:46.857]\n",
      "Saving backup of the training history epoch=283 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:44:46.973]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:44:47.019]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:44:47.022]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0166 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 285/400\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:51:57.569]\n",
      "Saving backup of the training history epoch=284 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:51:59.102]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:51:59.149]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:51:59.153]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 430s - loss: 0.0163 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 286/400\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::10:59:09.675]\n",
      "Saving backup of the training history epoch=285 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::10:59:09.791]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:59:09.836]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::10:59:09.839]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0178 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 287/400\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:06:20.651]\n",
      "Saving backup of the training history epoch=286 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:06:20.761]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:06:20.806]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:06:20.809]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 288/400\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.01819\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:13:31.189]\n",
      "Saving backup of the training history epoch=287 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:13:31.264]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:13:31.297]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:13:31.299]\n",
      "val: argmin=261 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0182 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 289/400\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.01819 to 0.01817, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:20:48.766]\n",
      "Saving backup of the training history epoch=288 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:20:48.857]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:20:48.899]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:20:48.902]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 436s - loss: 0.0169 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 290/400\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:27:59.489]\n",
      "Saving backup of the training history epoch=289 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:27:59.611]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:27:59.658]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:27:59.661]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0172 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 291/400\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:35:10.350]\n",
      "Saving backup of the training history epoch=290 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:35:10.457]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:35:10.502]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:35:10.505]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0164 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 292/400\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:42:21.288]\n",
      "Saving backup of the training history epoch=291 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:42:21.403]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:42:21.447]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:42:21.450]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0168 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 293/400\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:49:32.234]\n",
      "Saving backup of the training history epoch=292 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:49:32.302]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:49:32.333]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:49:32.336]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0168 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 294/400\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::11:56:42.842]\n",
      "Saving backup of the training history epoch=293 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::11:56:43.874]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:56:43.921]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::11:56:43.924]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 430s - loss: 0.0163 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 295/400\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:03:54.039]\n",
      "Saving backup of the training history epoch=294 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:03:54.104]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:03:54.137]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:03:54.139]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 428s - loss: 0.0167 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 296/400\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:11:04.528]\n",
      "Saving backup of the training history epoch=295 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:11:04.596]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:11:04.627]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:11:04.630]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0171 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 297/400\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:18:15.525]\n",
      "Saving backup of the training history epoch=296 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:18:15.628]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:18:15.700]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:18:15.703]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0174 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 298/400\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:25:26.578]\n",
      "Saving backup of the training history epoch=297 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:25:26.689]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:25:26.732]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:25:26.735]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0173 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 299/400\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:32:37.532]\n",
      "Saving backup of the training history epoch=298 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:32:37.647]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:32:37.691]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:32:37.694]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0150 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 300/400\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:39:48.053]\n",
      "Saving backup of the training history epoch=299 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:39:48.165]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:39:48.209]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:39:48.212]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0164 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00301: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 301/400\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:46:58.680]\n",
      "Saving backup of the training history epoch=300 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:46:58.773]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:46:58.811]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:46:58.814]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0174 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00302: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 302/400\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::12:54:09.324]\n",
      "Saving backup of the training history epoch=301 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::12:54:09.387]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:54:09.417]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::12:54:09.419]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0178 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00303: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 303/400\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:01:20.085]\n",
      "Saving backup of the training history epoch=302 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:01:20.188]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:01:20.231]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:01:20.233]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0161 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00304: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 304/400\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:08:30.389]\n",
      "Saving backup of the training history epoch=303 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:08:30.454]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:08:30.485]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:08:30.487]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 428s - loss: 0.0173 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00305: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 305/400\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:15:40.903]\n",
      "Saving backup of the training history epoch=304 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:15:41.006]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:15:41.047]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:15:41.050]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00306: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 306/400\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:22:51.685]\n",
      "Saving backup of the training history epoch=305 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:22:51.753]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:22:51.783]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:22:51.786]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00307: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 307/400\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:30:02.422]\n",
      "Saving backup of the training history epoch=306 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:30:02.509]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:30:02.551]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:30:02.553]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 429s - loss: 0.0171 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00308: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 308/400\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.01817\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:37:14.543]\n",
      "Saving backup of the training history epoch=307 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:37:14.638]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:37:14.679]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:37:14.682]\n",
      "val: argmin=288 --> min=0.0182\n",
      "\n",
      "10/10 - 430s - loss: 0.0168 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00309: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 309/400\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.01817 to 0.01815, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:44:32.425]\n",
      "Saving backup of the training history epoch=308 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:44:32.530]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:44:32.571]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:44:32.574]\n",
      "val: argmin=308 --> min=0.0181\n",
      "\n",
      "10/10 - 436s - loss: 0.0172 - val_loss: 0.0181 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00310: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 310/400\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.01815\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:51:43.329]\n",
      "Saving backup of the training history epoch=309 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:51:43.462]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:51:43.512]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:51:43.515]\n",
      "val: argmin=308 --> min=0.0181\n",
      "\n",
      "10/10 - 429s - loss: 0.0156 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00311: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 311/400\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.01815\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::13:58:54.089]\n",
      "Saving backup of the training history epoch=310 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::13:58:54.204]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:58:54.251]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::13:58:54.254]\n",
      "val: argmin=308 --> min=0.0181\n",
      "\n",
      "10/10 - 429s - loss: 0.0165 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00312: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 312/400\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.01815 to 0.01805, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:06:11.328]\n",
      "Saving backup of the training history epoch=311 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:06:11.425]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:06:11.469]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:06:11.472]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 435s - loss: 0.0166 - val_loss: 0.0180 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00313: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 313/400\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:13:21.848]\n",
      "Saving backup of the training history epoch=312 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:13:21.964]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:13:22.008]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:13:22.011]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0183 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00314: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 314/400\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:20:32.767]\n",
      "Saving backup of the training history epoch=313 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:20:32.856]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:20:32.893]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:20:32.896]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0180 - val_loss: 0.0189 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00315: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 315/400\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:27:43.743]\n",
      "Saving backup of the training history epoch=314 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:27:43.847]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:27:43.889]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:27:43.892]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0167 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00316: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 316/400\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:34:54.303]\n",
      "Saving backup of the training history epoch=315 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:34:54.409]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:34:54.452]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:34:54.455]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0155 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00317: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 317/400\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:42:04.943]\n",
      "Saving backup of the training history epoch=316 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:42:05.067]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:42:05.115]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:42:05.118]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0170 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00318: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 318/400\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:49:15.609]\n",
      "Saving backup of the training history epoch=317 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:49:15.703]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:49:15.743]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:49:15.746]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0164 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00319: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 319/400\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::14:56:26.257]\n",
      "Saving backup of the training history epoch=318 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::14:56:26.365]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:56:26.407]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::14:56:26.410]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0186 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00320: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 320/400\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:03:37.388]\n",
      "Saving backup of the training history epoch=319 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:03:37.451]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:03:37.480]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:03:37.482]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0176 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00321: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 321/400\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:10:48.048]\n",
      "Saving backup of the training history epoch=320 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:10:48.123]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:10:48.157]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:10:48.160]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0169 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00322: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 322/400\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:17:58.422]\n",
      "Saving backup of the training history epoch=321 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:17:58.542]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:17:58.590]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:17:58.593]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0170 - val_loss: 0.0183 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00323: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 323/400\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:25:08.965]\n",
      "Saving backup of the training history epoch=322 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:25:09.073]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:25:09.118]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:25:09.121]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0171 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00324: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 324/400\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:32:19.472]\n",
      "Saving backup of the training history epoch=323 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:32:19.579]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:32:19.620]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:32:19.623]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0181 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00325: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 325/400\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:39:30.310]\n",
      "Saving backup of the training history epoch=324 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:39:30.404]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:39:30.445]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:39:30.448]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0153 - val_loss: 0.0185 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00326: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 326/400\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.01805\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-10::15:46:40.837]\n",
      "Saving backup of the training history epoch=325 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-10::15:46:40.930]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:46:40.971]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:46:40.974]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n",
      "10/10 - 429s - loss: 0.0180 - val_loss: 0.0184 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00327: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 327/400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-dd0365f8a347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# data sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_seq_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 400\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        # data sequences\n",
    "        x=crop_seq_train,\n",
    "        validation_data=crop_seq_val,\n",
    "\n",
    "        # epochs\n",
    "#         initial_epoch=0,\n",
    "#         epochs=n_epochs,\n",
    "        initial_epoch=history_cb.last_epoch + 1,  # for some reason it is 0-starting and others 1-starting...\n",
    "#         epochs=history_cb.last_epoch + 1 + n_epochs,  \n",
    "        epochs=n_epochs,  \n",
    "\n",
    "        # others\n",
    "        callbacks=callbacks,  \n",
    "        verbose=2,\n",
    "        use_multiprocessing=False,   \n",
    "    );\n",
    "\n",
    "except Exception as ex:\n",
    "    slack.notify_error()\n",
    "    raise ex\n",
    "    \n",
    "else:\n",
    "    slack.notify_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:51:31.905]\n",
      "train: argmin=215 --> min=0.0147\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-10::15:51:31.910]\n",
      "val: argmin=311 --> min=0.018\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1250x1000 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows := 2, ncols := 1, figsize=(2.5 * (sz := 5), nrows * sz), dpi=100)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "hist_display = viz.TrainingHistoryDisplay(\n",
    "    history_cb.history, \n",
    "    model_name=tomo2seg_model.name,\n",
    "    loss_name=model.loss.__name__,\n",
    "    x_axis_mode=(\n",
    "        \"epoch\", \n",
    "        \"batch\",\n",
    "        \"crop\", \n",
    "        \"voxel\",\n",
    "        \"time\",\n",
    "    ),\n",
    ").plot(\n",
    "    axs, \n",
    "    with_lr=True,\n",
    "    metrics=(\n",
    "        \"loss\", \n",
    "#         \"jaccard2.class_idx=0\",\n",
    "#         \"jaccard2.class_idx=1\",\n",
    "#         \"jaccard2.class_idx=2\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[-1].set_yscale(\"log\")\n",
    "\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"loss\"][0])\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"val_loss\"][0], txt_kwargs=dict(rotation=0))\n",
    "\n",
    "hist_display.fig_.savefig(\n",
    "    tomo2seg_model.model_path / (hist_display.title + \".png\"),\n",
    "    format='png',\n",
    ")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "outputs": [],
   "source": [
    "history_cb.dataframe.to_csv(history_cb.csv_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d/unet3d.crop112-f12.fold000.1607-466-349/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(tomo2seg_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING::tomo2seg::{<ipython-input-62-4fb7892d503b>:<module>:004}::[2020-12-10::15:51:58.787]\n",
      "this_nb_name='train-03.ipynb' this_dir='/home/users/jcasagrande/projects/tomo2seg/nbs'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_nb_name = \"train-03.ipynb\"\n",
    "import os\n",
    "this_dir = os.getcwd()\n",
    "logger.warning(f\"{this_nb_name=} {this_dir=}\")\n",
    "\n",
    "os.system(f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {str(tomo2seg_model.model_path)} --to html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks as keras_callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics as keras_metrics\n",
    "\n",
    "from tomo2seg import slack\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    MetaCrop3DGenerator, VolumeCropSequence,\n",
    "    UniformGridPosition, SequentialGridPosition,\n",
    "    ET3DUniformCuboidAlmostEverywhere, ET3DConstantEverywhere, \n",
    "    GTUniformEverywhere, GTConstantEverywhere, \n",
    "    VSConstantEverywhere, VSUniformEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg import callbacks as tomo2seg_callbacks\n",
    "from tomo2seg import losses as tomo2seg_losses\n",
    "from tomo2seg.schedule import ComposedSchedule, LogSpaceSchedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time())\n",
    "# runid = 1606238421\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "n_classes = len(volume.metadata.labels)\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "\n",
    "logger.debug(f\"{voldata_train.shape=}\")\n",
    "logger.debug(f\"{voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "\n",
    "logger.debug(f\"{vollabels_train.shape=}\")\n",
    "logger.debug(f\"{vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "except NameError:\n",
    "    print(\"already deleted (:\")\n",
    "else:\n",
    "    del tomo2seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "# crop_shape = (256, 256, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "# bigger crops will have less border effects (?)\n",
    "crop_shape = (96, 96, 96, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "model_master_name = \"unet3d\"\n",
    "model_version = \"crop96-f08\"\n",
    "model_factory_function = modular_unet.u_net\n",
    "model_factory_kwargs = {\n",
    "    **modular_unet.kwargs_vanilla03,\n",
    "    **dict(\n",
    "        convlayer=modular_unet.ConvLayer.conv3d,\n",
    "        input_shape = crop_shape,https://docs.google.com/document/d/1V4Xh9xRs_AnXcczH_XvV-Xp5olojox0yWACsH_1WFpc/edit#heading=h.jxfmel7ln5myhttps://docs.google.com/document/d/1V4Xh9xRs_AnXcczH_XvV-Xp5olojox0yWACsH_1WFpc/edit#heading=h.jxfmel7ln5my\n",
    "        output_channels=n_classes,\n",
    "#         nb_filters_0 = 2,\n",
    "#         nb_filters_0 = 4,\n",
    "        nb_filters_0 = 8,\n",
    "#         nb_filters_0 = 16,\n",
    "#         nb_filters_0 = 32,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "    \n",
    "except NameError:\n",
    "    logger.info(\"Creating a Tomo2SegModel.\")\n",
    "    \n",
    "    tomo2seg_model = Tomo2SegModel(\n",
    "        model_master_name, \n",
    "        model_version, \n",
    "        runid=runid,\n",
    "        factory_function=model_factory_function,\n",
    "        factory_kwargs=model_factory_kwargs,\n",
    "    )\n",
    "                \n",
    "else:\n",
    "    logger.warning(\"The model is already defined. To create a new one: `del tomo2seg_model`\")\n",
    "\n",
    "finally:\n",
    "    \n",
    "    logger.info(f\"{tomo2seg_model=}\")\n",
    "    \n",
    "logger.info(\"Creating the Keras model.\")\n",
    "\n",
    "with strategy.scope():\n",
    "    if not tomo2seg_model.autosaved_model_path.exists():\n",
    "        logger.info(f\"Instantiating a new model with model_factory_function={model_factory_function.__name__}\")\n",
    "      \n",
    "        model = model_factory_function(\n",
    "            name=tomo2seg_model.name,\n",
    "            **model_factory_kwargs\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\"An autosaved model already exists, loading it instead of creating a new one!\")\n",
    "        model = keras.models.load_model(tomo2seg_model.autosaved_model_path_str, compile=False)\n",
    "\n",
    "    logger.info(\"Compiling the model.\")\n",
    "\n",
    "    # using the avg jaccard is dangerous if one of the classes is too\n",
    "    # underrepresented because it's jaccard will be unstable\n",
    "    loss = tomo2seg_losses.jaccard2_flat\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=.003)\n",
    "    metrics = [\n",
    "#         tomo2seg_losses.jaccard2_macro_avg,\n",
    "#         keras_metrics.Accuracy(),\n",
    "#     ] + [\n",
    "#         tomo2seg_losses.Jaccard2(class_idx)\n",
    "#         for class_idx in range(n_classes)\n",
    "    ]\n",
    "\n",
    "    model.compile(\n",
    "        loss=loss, \n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    model.save(tomo2seg_model.model_path)\n",
    "\n",
    "    # write the model summary in a file\n",
    "    with tomo2seg_model.summary_path.open(\"w\") as f:\n",
    "        def print_to_txt(line):\n",
    "            f.writelines([line + \"\\n\"])\n",
    "        model.summary(print_fn=print_to_txt, line_length=140)\n",
    "\n",
    "    # same for the architecture\n",
    "    utils.plot_model(model, show_shapes=True, to_file=tomo2seg_model.architecture_plot_path);\n",
    "\n",
    "    logger.info(f\"Check the summary and the figure of the model in the following locations:\\n{tomo2seg_model.summary_path}\\n{tomo2seg_model.architecture_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "# Data crop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_per_replica = 4\n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "\n",
    "common_random_state = 143\n",
    "\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\\n{common_random_state=}\\n{crop_shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = voldata_train\n",
    "labels = vollabels_train\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := UniformGridPosition.build_from_volume_crop_shapes(\n",
    "                volume_shape=volume_shape, \n",
    "                crop_shape=crop_shape,\n",
    "                random_state=RandomState(common_random_state),\n",
    "            )\n",
    "        ),\n",
    "        # it is too slow to use this\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator=grid_pos_gen),\n",
    "#         gt_field=GTUniformEverywhere.build_2d(\n",
    "        gt_field=GTUniformEverywhere.build_3d(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "        ),\n",
    "        vs_field=VSUniformEverywhere.build_plus_or_mines(\n",
    "            shift=1. / 255 / 2,  # half a value to both sides +/-\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "            random_state=RandomState(common_random_state),\n",
    "        ),\n",
    "        is_2halfd=True,\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "#     epoch_size=5,\n",
    "    epoch_size=1,\n",
    "    meta_crops_hist_path=tomo2seg_model.train_metacrop_history_path,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    "#     output_as_2d=True,\n",
    "#     output_as_2halfd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val volume\n",
    "\n",
    "data = voldata_val\n",
    "labels = vollabels_val\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    # data source\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    \n",
    "    # data augmentation\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := SequentialGridPosition.build_min_overlap(\n",
    "                volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "                # reduce the total number of crops\n",
    "#                 n_steps_x=15,\n",
    "#                 n_steps_y=15,\n",
    "                # increase the total number of crops\n",
    "                n_steps_z=8,\n",
    "            )\n",
    "#             grid_pos_gen := SequentialGridPosition.build_from_volume_crop_shapes(\n",
    "#                 volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "#                 n_steps_x=2, n_steps_y=2, n_steps_z=200,\n",
    "#             )\n",
    "        ),\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator=grid_pos_gen),\n",
    "#         gt_field=GTConstantEverywhere.build_gt2d_identity(grid_position_generator=grid_pos_gen),\n",
    "        gt_field=GTConstantEverywhere.build_gt3d_identity(grid_position_generator=grid_pos_gen),\n",
    "        vs_field=VSConstantEverywhere.build_no_shift(grid_position_generator=grid_pos_gen),\n",
    "        is_2halfd=True,\n",
    "    ),\n",
    "    \n",
    "    # others\n",
    "    batch_size=batch_size,\n",
    "    epoch_size=len(grid_pos_gen),  # go through all the crops in validation    \n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    "    \n",
    "#     output_as_2d=True,\n",
    "#     output_as_2halfd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [],
   "source": [
    "autosave_cb = keras_callbacks.ModelCheckpoint(\n",
    "    tomo2seg_model.autosaved_model_path_str, \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=2, \n",
    "    save_best_only=True, \n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "# todo load if it already exists\n",
    "try:\n",
    "    history_cb\n",
    "    \n",
    "except NameError:\n",
    "    history_cb = tomo2seg_callbacks.History(\n",
    "        optimizer=model.optimizer,\n",
    "        crop_seq_train=crop_seq_train,\n",
    "        crop_seq_val=crop_seq_val,\n",
    "        backup=1,\n",
    "        csv_path=tomo2seg_model.history_path,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    logger.warning(\"The history callback already exists!\")\n",
    "    \n",
    "    history_df = history_cb.dataframe\n",
    "\n",
    "    try:\n",
    "        history_df_temp = pd.read_csv(tomo2seg_model.history_path)\n",
    "        # keep the longest one\n",
    "        history_df = history_df if history_df.shape[0] >= history_df_temp.shape[0] else history_df_temp\n",
    "        del history_df_temp\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "finally:\n",
    "    # make sure the correct objects are linked \n",
    "    history_cb.model = model\n",
    "    history_cb.crop_seq_train = crop_seq_train\n",
    "    history_cb.crop_seq_val = crop_seq_val\n",
    "    # todo do the same with other objs in history_cb\n",
    "    \n",
    "history_plot_cb = tomo2seg_callbacks.HistoryPlot(\n",
    "    history_callback=history_cb,\n",
    "    save_path=tomo2seg_model.train_history_plot_wip_path\n",
    ")\n",
    "\n",
    "early_stop_cb = keras_callbacks.EarlyStopping(  # todo modify the early stopping to take more conditions (don't stop too early before it doesnt break the jaccard2=.32)\n",
    "    monitor='val_loss', \n",
    "    min_delta=.1 / 100, \n",
    "    patience=50,\n",
    "    verbose=2, \n",
    "    mode='auto',\n",
    "    baseline=.71,  # 0th-order classifier\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training\n",
    "\n",
    "stuff that i use after the training but i want it to appear in the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Volume slices\n",
    "\n",
    "todo do this in a notebook\n",
    "\n",
    "## Generator samples\n",
    "\n",
    "todo do this in a notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangular log lr schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### from tensorflow.keras import backend as K\n",
    "# lr = 0.001\n",
    "# K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "lr_schedule_cb = keras_callbacks.LearningRateScheduler(\n",
    "    schedule= (schedule := ComposedSchedule(\n",
    "        offset_epoch=0,\n",
    "        sub_schedules=[\n",
    "            LogSpaceSchedule(0, wait=0, start=-4, stop=-3, n_between_scales=8), \n",
    "            LogSpaceSchedule(10, wait=20, start=-3, stop=-4, n_between_scales=8),\n",
    "            LogSpaceSchedule(40, wait=0, start=-4, stop=-3, n_between_scales=18),\n",
    "            LogSpaceSchedule(60, wait=20, start=-3, stop=-4, n_between_scales=18),\n",
    "            LogSpaceSchedule(100, wait=0, start=-4, stop=-3, n_between_scales=18),\n",
    "            LogSpaceSchedule(120, wait=20, start=-3, stop=-4, n_between_scales=18),\n",
    "            LogSpaceSchedule(160, wait=50, start=-4, stop=-5, n_between_scales=48),\n",
    "        ]\n",
    "    )),\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.info(f\"{schedule.range}\")\n",
    "\n",
    "crop_seq_train.epoch_size = 10\n",
    "\n",
    "callbacks = [\n",
    "    keras_callbacks.TerminateOnNaN(),\n",
    "    autosave_cb,\n",
    "    history_cb,\n",
    "    history_plot_cb,\n",
    "    lr_schedule_cb,\n",
    "#     early_stop_cb,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        # data sequences\n",
    "        x=crop_seq_train,\n",
    "        validation_data=crop_seq_val,\n",
    "\n",
    "        # epochs\n",
    "        initial_epoch=0,\n",
    "        epochs=n_epochs,\n",
    "#         initial_epoch=history_cb.last_epoch + 1,  # for some reason it is 0-starting and others 1-starting...\n",
    "#         epochs=history_cb.last_epoch + 1 + n_epochs,  \n",
    "    #     initial_epoch=113,\n",
    "    #     epochs=126,\n",
    "\n",
    "        # others\n",
    "        callbacks=callbacks,  \n",
    "        verbose=2,\n",
    "        use_multiprocessing=False,   \n",
    "    );\n",
    "\n",
    "except Exception as ex:\n",
    "    slack.notify_error()\n",
    "    raise ex\n",
    "    \n",
    "else:\n",
    "    slack.notify_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows := 2, ncols := 1, figsize=(2.5 * (sz := 5), nrows * sz), dpi=100)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "hist_display = viz.TrainingHistoryDisplay(\n",
    "    history_cb.history, \n",
    "    model_name=tomo2seg_model.name,\n",
    "    loss_name=model.loss.__name__,\n",
    "    x_axis_mode=(\n",
    "        \"epoch\", \n",
    "        \"batch\",\n",
    "        \"crop\", \n",
    "        \"voxel\",\n",
    "        \"time\",\n",
    "    ),\n",
    ").plot(\n",
    "    axs, \n",
    "    with_lr=True,\n",
    "    metrics=(\n",
    "        \"loss\", \n",
    "#         \"jaccard2.class_idx=0\",\n",
    "#         \"jaccard2.class_idx=1\",\n",
    "#         \"jaccard2.class_idx=2\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[-1].set_yscale(\"log\")\n",
    "\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"loss\"][0])\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"val_loss\"][0], txt_kwargs=dict(rotation=0))\n",
    "\n",
    "hist_display.fig_.savefig(\n",
    "    tomo2seg_model.model_path / (hist_display.title + \".png\"),\n",
    "    format='png',\n",
    ")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "outputs": [],
   "source": [
    "history_cb.dataframe.to_csv(history_cb.csv_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [],
   "source": [
    "model.save(tomo2seg_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"train-03.ipynb\"\n",
    "import os\n",
    "this_dir = os.getcwd()\n",
    "logger.warning(f\"{this_nb_name=} {this_dir=}\")\n",
    "\n",
    "os.system(f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {str(tomo2seg_model.model_path)} --to html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks as keras_callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics as keras_metrics\n",
    "\n",
    "from tomo2seg import slack\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    MetaCrop3DGenerator, VolumeCropSequence,\n",
    "    UniformGridPosition, SequentialGridPosition,\n",
    "    ET3DUniformCuboidAlmostEverywhere, ET3DConstantEverywhere, \n",
    "    GTUniformEverywhere, GTConstantEverywhere, \n",
    "    VSConstantEverywhere, VSUniformEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg import callbacks as tomo2seg_callbacks\n",
    "from tomo2seg import losses as tomo2seg_losses\n",
    "from tomo2seg.schedule import ComposedSchedule, LogSpaceSchedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-4-f5dd942bd525>:<module>:005}::[2020-11-30::16:42:19.159]\n",
      "runid=1606750939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time())\n",
    "# runid = 1606238421\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:001}::[2020-11-30::16:42:19.220]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:002}::[2020-11-30::16:42:19.357]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-5-7a7728cf1275>:<module>:003}::[2020-11-30::16:42:19.726]\n",
      "Both here should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-6-f863a788f16a>:<module>:010}::[2020-11-30::16:42:19.811]\n",
      "volume_name='PA66GF30' volume_version='v1' labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:237}::[2020-11-30::16:42:19.870]\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "ERROR::tomo2seg::{data.py:with_check:255}::[2020-11-30::16:42:19.891]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels.raw\n",
      "\n",
      "WARNING::tomo2seg::{data.py:with_check:259}::[2020-11-30::16:42:19.925]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.weights.raw\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:194}::[2020-11-30::16:42:19.926]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:007}::[2020-11-30::16:42:19.942]\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [0, 1300], 'alias': 'train'}, 'val': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1600, 1900], 'alias': 'val'}, 'test': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1300, 1600], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:024}::[2020-11-30::16:42:19.943]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:028}::[2020-11-30::16:42:29.994]\n",
      "voldata.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:033}::[2020-11-30::16:42:29.996]\n",
      "voldata_train.shape=(1300, 1040, 1300)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:034}::[2020-11-30::16:42:29.997]\n",
      "voldata_val.shape=(1300, 1040, 300)\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:040}::[2020-11-30::16:42:33.161]\n",
      "vollabels.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:045}::[2020-11-30::16:42:33.163]\n",
      "vollabels_train.shape=(1300, 1040, 1300)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-7-6e0649e4ec97>:<module>:046}::[2020-11-30::16:42:33.164]\n",
      "vollabels_val.shape=(1300, 1040, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "n_classes = len(volume.metadata.labels)\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "\n",
    "logger.debug(f\"{voldata_train.shape=}\")\n",
    "logger.debug(f\"{voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "\n",
    "logger.debug(f\"{vollabels_train.shape=}\")\n",
    "logger.debug(f\"{vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already deleted (:\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "except NameError:\n",
    "    print(\"already deleted (:\")\n",
    "else:\n",
    "    del tomo2seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "# crop_shape = (256, 256, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "# bigger crops will have less border effects (?)\n",
    "crop_shape = (48, 48, 48, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "model_master_name = \"unet3d\"\n",
    "model_version = \"vanilla03-f16\"\n",
    "model_factory_function = modular_unet.u_net\n",
    "model_factory_kwargs = {\n",
    "    **modular_unet.kwargs_vanilla03,\n",
    "    **dict(\n",
    "        convlayer=modular_unet.ConvLayer.conv3d,\n",
    "        input_shape = crop_shape,\n",
    "        output_channels=n_classes,\n",
    "#         nb_filters_0 = 2,\n",
    "#         nb_filters_0 = 4,\n",
    "#         nb_filters_0 = 8,\n",
    "        nb_filters_0 = 16,\n",
    "#         nb_filters_0 = 32,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-10-2291d74903ed>:<module>:005}::[2020-11-30::16:42:33.334]\n",
      "Creating a Tomo2SegModel.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-10-2291d74903ed>:<module>:020}::[2020-11-30::16:42:33.336]\n",
      "tomo2seg_model=Model(master_name='unet3d', version='vanilla03-f16', fold=0, runid=1606750939, factory_function='tomo2seg.modular_unet.u_net', factory_kwargs={'depth': 4, 'sigma_noise': 0, 'updown_conv_sampling': True, 'unet_block_kwargs': {'kernel_size': 3, 'res': True, 'batch_norm': True, 'dropout': 0}, 'unet_down_kwargs': {'batchnorm': True}, 'unet_up_kwargs': {'batchnorm': True}, 'convlayer': <ConvLayer.conv3d: 10>, 'input_shape': (48, 48, 48, 1), 'output_channels': 3, 'nb_filters_0': 16})\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-10-2291d74903ed>:<module>:022}::[2020-11-30::16:42:33.336]\n",
      "Creating the Keras model.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-10-2291d74903ed>:<module>:026}::[2020-11-30::16:42:33.339]\n",
      "Instantiating a new model with model_factory_function=u_net\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO::tomo2seg::{<ipython-input-10-2291d74903ed>:<module>:036}::[2020-11-30::16:42:36.510]\n",
      "Compiling the model.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jcasagrande/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/assets\n",
      "INFO::tomo2seg::{<ipython-input-10-2291d74903ed>:<module>:067}::[2020-11-30::16:42:59.833]\n",
      "Check the summary and the figure of the model in the following locations:\n",
      "/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/summary.txt\n",
      "/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/architecture.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "    \n",
    "except NameError:\n",
    "    logger.info(\"Creating a Tomo2SegModel.\")\n",
    "    \n",
    "    tomo2seg_model = Tomo2SegModel(\n",
    "        model_master_name, \n",
    "        model_version, \n",
    "        runid=runid,\n",
    "        factory_function=model_factory_function,\n",
    "        factory_kwargs=model_factory_kwargs,\n",
    "    )\n",
    "                \n",
    "else:\n",
    "    logger.warning(\"The model is already defined. To create a new one: `del tomo2seg_model`\")\n",
    "\n",
    "finally:\n",
    "    \n",
    "    logger.info(f\"{tomo2seg_model=}\")\n",
    "    \n",
    "logger.info(\"Creating the Keras model.\")\n",
    "\n",
    "with strategy.scope():\n",
    "    if not tomo2seg_model.autosaved_model_path.exists():\n",
    "        logger.info(f\"Instantiating a new model with model_factory_function={model_factory_function.__name__}\")\n",
    "      \n",
    "        model = model_factory_function(\n",
    "            name=tomo2seg_model.name,\n",
    "            **model_factory_kwargs\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\"An autosaved model already exists, loading it instead of creating a new one!\")\n",
    "        model = keras.models.load_model(tomo2seg_model.autosaved_model_path_str, compile=False)\n",
    "\n",
    "    logger.info(\"Compiling the model.\")\n",
    "\n",
    "    # using the avg jaccard is dangerous if one of the classes is too\n",
    "    # underrepresented because it's jaccard will be unstable\n",
    "    loss = tomo2seg_losses.jaccard2_flat\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=.003)\n",
    "    metrics = [\n",
    "#         tomo2seg_losses.jaccard2_macro_avg,\n",
    "#         keras_metrics.Accuracy(),\n",
    "#     ] + [\n",
    "#         tomo2seg_losses.Jaccard2(class_idx)\n",
    "#         for class_idx in range(n_classes)\n",
    "    ]\n",
    "\n",
    "    model.compile(\n",
    "        loss=loss, \n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    model.save(tomo2seg_model.model_path)\n",
    "\n",
    "    # write the model summary in a file\n",
    "    with tomo2seg_model.summary_path.open(\"w\") as f:\n",
    "        def print_to_txt(line):\n",
    "            f.writelines([line + \"\\n\"])\n",
    "        model.summary(print_fn=print_to_txt, line_length=140)\n",
    "\n",
    "    # same for the architecture\n",
    "    utils.plot_model(model, show_shapes=True, to_file=tomo2seg_model.architecture_plot_path);\n",
    "\n",
    "    logger.info(f\"Check the summary and the figure of the model in the following locations:\\n{tomo2seg_model.summary_path}\\n{tomo2seg_model.architecture_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "# Data crop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-11-19fcba377971>:<module>:006}::[2020-11-30::16:42:59.934]\n",
      "batch_size_per_replica=8\n",
      "n_replicas=2\n",
      "batch_size=16\n",
      "common_random_state=143\n",
      "crop_shape=(48, 48, 48, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size_per_replica = 8\n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "\n",
    "common_random_state = 143\n",
    "\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\\n{common_random_state=}\\n{crop_shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:431}::[2020-11-30::16:42:59.997]\n",
      "Built UniformGridPosition from volume_shape=(1300, 1040, 1300) and crop_shape=(48, 48, 48, 1) ==> {'x_range': (0, 1253), 'y_range': (0, 993), 'z_range': (0, 1253)}\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:688}::[2020-11-30::16:42:59.998]\n",
      "Initializing ET3DConstantEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:688}::[2020-11-30::16:43:00.000]\n",
      "Initializing GTUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:688}::[2020-11-30::16:43:00.001]\n",
      "Initializing VSUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:1279}::[2020-11-30::16:43:00.001]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:__post_init__:1307}::[2020-11-30::16:43:00.003]\n",
      "A meta crops history file path was given but it still doesn't exist. Writing csv headers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = voldata_train\n",
    "labels = vollabels_train\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := UniformGridPosition.build_from_volume_crop_shapes(\n",
    "                volume_shape=volume_shape, \n",
    "                crop_shape=crop_shape,\n",
    "                random_state=RandomState(common_random_state),\n",
    "            )\n",
    "        ),\n",
    "        # it is too slow to use this\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator=grid_pos_gen),\n",
    "#         gt_field=GTUniformEverywhere.build_2d(\n",
    "        gt_field=GTUniformEverywhere.build_3d(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "        ),\n",
    "        vs_field=VSUniformEverywhere.build_plus_or_mines(\n",
    "            shift=1. / 255 / 2,  # half a value to both sides +/-\n",
    "            grid_position_generator=grid_pos_gen,\n",
    "            random_state=RandomState(common_random_state),\n",
    "        ),\n",
    "        is_2halfd=True,\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "#     epoch_size=5,\n",
    "    epoch_size=1,\n",
    "    meta_crops_hist_path=tomo2seg_model.train_metacrop_history_path,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    "#     output_as_2d=True,\n",
    "#     output_as_2halfd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{volume_sequence.py:build_min_overlap:499}::[2020-11-30::16:43:00.072]\n",
      "Building SequentialGridPosition with minimal overlap (smallest n_steps in each directions) n_steps={'n_steps_x': 28, 'n_steps_y': 22, 'n_steps_z': 7}.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:build_min_overlap:502}::[2020-11-30::16:43:00.073]\n",
      "n_steps_kwargs={'n_steps_x': 15, 'n_steps_y': 15} was given --> effective n_steps={'n_steps_x': 15, 'n_steps_y': 15, 'n_steps_z': 7}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:431}::[2020-11-30::16:43:00.074]\n",
      "Built SequentialGridPosition from volume_shape=(1300, 1040, 300) and crop_shape=(48, 48, 48, 1) ==> {'x_range': (0, 1253), 'y_range': (0, 993), 'z_range': (0, 253)}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:__post_init__:479}::[2020-11-30::16:43:00.079]\n",
      "The SequentialGridPosition has len(self.positions)=1575 different positions (therefore crops).\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:688}::[2020-11-30::16:43:00.079]\n",
      "Initializing ET3DConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:688}::[2020-11-30::16:43:00.080]\n",
      "Initializing GTConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:688}::[2020-11-30::16:43:00.081]\n",
      "Initializing VSConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:1279}::[2020-11-30::16:43:00.082]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:1311}::[2020-11-30::16:43:00.082]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# val volume\n",
    "\n",
    "data = voldata_val\n",
    "labels = vollabels_val\n",
    "volume_shape = data.shape\n",
    "labels_list = volume.metadata.labels\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    # data source\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    labels=labels_list,\n",
    "    \n",
    "    # data augmentation\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=(\n",
    "            grid_pos_gen := SequentialGridPosition.build_min_overlap(\n",
    "                volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "                # reduce the total number of crops\n",
    "                n_steps_x=15,\n",
    "                n_steps_y=15,\n",
    "#                 n_steps_z=60,\n",
    "            )\n",
    "#             grid_pos_gen := SequentialGridPosition.build_from_volume_crop_shapes(\n",
    "#                 volume_shape=volume_shape, crop_shape=crop_shape,\n",
    "#                 n_steps_x=2, n_steps_y=2, n_steps_z=200,\n",
    "#             )\n",
    "        ),\n",
    "        et_field=ET3DConstantEverywhere.build_no_displacement(grid_position_generator=grid_pos_gen),\n",
    "#         gt_field=GTConstantEverywhere.build_gt2d_identity(grid_position_generator=grid_pos_gen),\n",
    "        gt_field=GTConstantEverywhere.build_gt3d_identity(grid_position_generator=grid_pos_gen),\n",
    "        vs_field=VSConstantEverywhere.build_no_shift(grid_position_generator=grid_pos_gen),\n",
    "        is_2halfd=True,\n",
    "    ),\n",
    "    \n",
    "    # others\n",
    "    batch_size=batch_size,\n",
    "    epoch_size=len(grid_pos_gen),  # go through all the crops in validation    \n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    "    \n",
    "#     output_as_2d=True,\n",
    "#     output_as_2halfd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "autosave_cb = keras_callbacks.ModelCheckpoint(\n",
    "    tomo2seg_model.autosaved_model_path_str, \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=2, \n",
    "    save_best_only=True, \n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "# todo load if it already exists\n",
    "try:\n",
    "    history_cb\n",
    "    \n",
    "except NameError:\n",
    "    history_cb = tomo2seg_callbacks.History(\n",
    "        optimizer=model.optimizer,\n",
    "        crop_seq_train=crop_seq_train,\n",
    "        crop_seq_val=crop_seq_val,\n",
    "        backup=1,\n",
    "        csv_path=tomo2seg_model.history_path,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    logger.warning(\"The history callback already exists!\")\n",
    "    \n",
    "    history_df = history_cb.dataframe\n",
    "\n",
    "    try:\n",
    "        history_df_temp = pd.read_csv(tomo2seg_model.history_path)\n",
    "        # keep the longest one\n",
    "        history_df = history_df if history_df.shape[0] >= history_df_temp.shape[0] else history_df_temp\n",
    "        del history_df_temp\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "finally:\n",
    "    # make sure the correct objects are linked \n",
    "    history_cb.model = model\n",
    "    history_cb.crop_seq_train = crop_seq_train\n",
    "    history_cb.crop_seq_val = crop_seq_val\n",
    "    # todo do the same with other objs in history_cb\n",
    "    \n",
    "history_plot_cb = tomo2seg_callbacks.HistoryPlot(\n",
    "    history_callback=history_cb,\n",
    "    save_path=tomo2seg_model.train_history_plot_wip_path\n",
    ")\n",
    "\n",
    "early_stop_cb = keras_callbacks.EarlyStopping(  # todo modify the early stopping to take more conditions (don't stop too early before it doesnt break the jaccard2=.32)\n",
    "    monitor='val_loss', \n",
    "    min_delta=.1 / 100, \n",
    "    patience=50,\n",
    "    verbose=2, \n",
    "    mode='auto',\n",
    "    baseline=.71,  # 0th-order classifier\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training\n",
    "\n",
    "stuff that i use after the training but i want it to appear in the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Volume slices\n",
    "\n",
    "todo do this in a notebook\n",
    "\n",
    "## Generator samples\n",
    "\n",
    "todo do this in a notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangular log lr schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.254]\n",
      "LogSpaceSchedule ==> self.n=10\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.255]\n",
      "LogSpaceSchedule ==> self.n=30\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.256]\n",
      "LogSpaceSchedule ==> self.n=20\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.257]\n",
      "LogSpaceSchedule ==> self.n=40\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.258]\n",
      "LogSpaceSchedule ==> self.n=20\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.258]\n",
      "LogSpaceSchedule ==> self.n=40\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-11-30::16:43:00.259]\n",
      "LogSpaceSchedule ==> self.n=100\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:107}::[2020-11-30::16:43:00.260]\n",
      "ComposedSchedule ==> self.n=260\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-15-7a47e9cbd7e3>:<module>:021}::[2020-11-30::16:43:00.261]\n",
      "(0, 260)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### from tensorflow.keras import backend as K\n",
    "# lr = 0.001\n",
    "# K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "lr_schedule_cb = keras_callbacks.LearningRateScheduler(\n",
    "    schedule= (schedule := ComposedSchedule(\n",
    "        offset_epoch=0,\n",
    "        sub_schedules=[\n",
    "            LogSpaceSchedule(0, wait=0, start=-4, stop=-3, n_between_scales=8), \n",
    "            LogSpaceSchedule(10, wait=20, start=-3, stop=-4, n_between_scales=8),\n",
    "            LogSpaceSchedule(40, wait=0, start=-4, stop=-3, n_between_scales=18),\n",
    "            LogSpaceSchedule(60, wait=20, start=-3, stop=-4, n_between_scales=18),\n",
    "            LogSpaceSchedule(100, wait=0, start=-4, stop=-3, n_between_scales=18),\n",
    "            LogSpaceSchedule(120, wait=20, start=-3, stop=-4, n_between_scales=18),\n",
    "            LogSpaceSchedule(160, wait=50, start=-4, stop=-5, n_between_scales=48),\n",
    "        ]\n",
    "    )),\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.info(f\"{schedule.range}\")\n",
    "\n",
    "crop_seq_train.epoch_size = 10\n",
    "\n",
    "callbacks = [\n",
    "    keras_callbacks.TerminateOnNaN(),\n",
    "    autosave_cb,\n",
    "    history_cb,\n",
    "    history_plot_cb,\n",
    "    lr_schedule_cb,\n",
    "#     early_stop_cb,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/400\n",
      "INFO:tensorflow:batch_all_reduce: 142 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 142 all-reduces with algorithm = nccl, num_packs = 1\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66090, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::16:55:13.135]\n",
      "Saving backup of the training history epoch=0 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{callbacks.py:on_epoch_end:103}::[2020-11-30::16:55:13.176]\n",
      "epoch=0 is too early to plot something.\n",
      "\n",
      "ERROR::tomo2seg::{callbacks.py:on_epoch_end:144}::[2020-11-30::16:55:13.278]\n",
      "AssertionError occurred while trying to plot the history.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/callbacks.py\", line 115, in on_epoch_end\n",
      "    hist_display = viz.TrainingHistoryDisplay(\n",
      "  File \"<string>\", line 9, in __init__\n",
      "  File \"/home/users/jcasagrande/projects/tomo2seg/tomo2seg/viz.py\", line 254, in __post_init__\n",
      "    assert len(x_axis) > 1, \"You don't have enough epochs to plot. Go to the gym and call me later.\"\n",
      "AssertionError: You don't have enough epochs to plot. Go to the gym and call me later.\n",
      "10/10 - 603s - loss: 0.3522 - val_loss: 0.6609 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0001291549665014884.\n",
      "Epoch 2/400\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66090 to 0.59363, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::17:05:14.981]\n",
      "Saving backup of the training history epoch=1 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{callbacks.py:on_epoch_end:103}::[2020-11-30::17:05:15.017]\n",
      "epoch=1 is too early to plot something.\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::17:05:15.073]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:05:15.118]\n",
      "train: argmin=1 --> min=0.0947\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:05:15.121]\n",
      "val: argmin=1 --> min=0.594\n",
      "\n",
      "10/10 - 601s - loss: 0.0947 - val_loss: 0.5936 - lr: 1.2915e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001668100537200059.\n",
      "Epoch 3/400\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.59363 to 0.50417, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::17:15:16.010]\n",
      "Saving backup of the training history epoch=2 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::17:15:16.098]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:15:16.140]\n",
      "train: argmin=2 --> min=0.0522\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:15:16.144]\n",
      "val: argmin=2 --> min=0.504\n",
      "\n",
      "10/10 - 599s - loss: 0.0522 - val_loss: 0.5042 - lr: 1.6681e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00021544346900318845.\n",
      "Epoch 4/400\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50417 to 0.40761, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::17:25:17.567]\n",
      "Saving backup of the training history epoch=3 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::17:25:17.676]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:25:17.720]\n",
      "train: argmin=3 --> min=0.0373\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:25:17.724]\n",
      "val: argmin=3 --> min=0.408\n",
      "\n",
      "10/10 - 600s - loss: 0.0373 - val_loss: 0.4076 - lr: 2.1544e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0002782559402207126.\n",
      "Epoch 5/400\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40761 to 0.32625, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::17:35:19.326]\n",
      "Saving backup of the training history epoch=4 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::17:35:19.441]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:35:19.487]\n",
      "train: argmin=4 --> min=0.0334\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:35:19.491]\n",
      "val: argmin=4 --> min=0.326\n",
      "\n",
      "10/10 - 600s - loss: 0.0334 - val_loss: 0.3263 - lr: 2.7826e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00035938136638046257.\n",
      "Epoch 6/400\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32625 to 0.27280, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::17:45:21.012]\n",
      "Saving backup of the training history epoch=5 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::17:45:21.203]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:45:21.252]\n",
      "train: argmin=5 --> min=0.0319\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:45:21.256]\n",
      "val: argmin=5 --> min=0.273\n",
      "\n",
      "10/10 - 601s - loss: 0.0319 - val_loss: 0.2728 - lr: 3.5938e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00046415888336127773.\n",
      "Epoch 7/400\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27280 to 0.23859, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::17:55:24.832]\n",
      "Saving backup of the training history epoch=6 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::17:55:25.011]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:55:25.058]\n",
      "train: argmin=6 --> min=0.0283\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::17:55:25.062]\n",
      "val: argmin=6 --> min=0.239\n",
      "\n",
      "10/10 - 602s - loss: 0.0283 - val_loss: 0.2386 - lr: 4.6416e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0005994842503189409.\n",
      "Epoch 8/400\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23859 to 0.21833, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::18:05:23.288]\n",
      "Saving backup of the training history epoch=7 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::18:05:23.362]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:05:23.937]\n",
      "train: argmin=6 --> min=0.0283\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:05:23.940]\n",
      "val: argmin=7 --> min=0.218\n",
      "\n",
      "10/10 - 597s - loss: 0.0298 - val_loss: 0.2183 - lr: 5.9948e-04\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.000774263682681127.\n",
      "Epoch 9/400\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.21833 to 0.20903, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::18:15:25.453]\n",
      "Saving backup of the training history epoch=8 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::18:15:25.562]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:15:25.609]\n",
      "train: argmin=6 --> min=0.0283\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:15:25.613]\n",
      "val: argmin=8 --> min=0.209\n",
      "\n",
      "10/10 - 600s - loss: 0.0291 - val_loss: 0.2090 - lr: 7.7426e-04\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/400\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20903 to 0.20352, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::18:25:30.725]\n",
      "Saving backup of the training history epoch=9 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::18:25:39.130]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:25:39.181]\n",
      "train: argmin=9 --> min=0.0267\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:25:39.185]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 612s - loss: 0.0267 - val_loss: 0.2035 - lr: 0.0010\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 11/400\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::18:35:28.564]\n",
      "Saving backup of the training history epoch=10 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::18:35:28.700]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:35:28.748]\n",
      "train: argmin=10 --> min=0.0233\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:35:28.752]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 588s - loss: 0.0233 - val_loss: 0.2115 - lr: 0.0010\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 12/400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::18:45:18.079]\n",
      "Saving backup of the training history epoch=11 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::18:45:18.141]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:45:18.173]\n",
      "train: argmin=11 --> min=0.0214\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:45:18.175]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 588s - loss: 0.0214 - val_loss: 0.2230 - lr: 0.0010\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 13/400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::18:55:07.387]\n",
      "Saving backup of the training history epoch=12 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::18:55:07.471]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:55:07.510]\n",
      "train: argmin=12 --> min=0.021\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::18:55:07.513]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 588s - loss: 0.0210 - val_loss: 0.2270 - lr: 0.0010\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 14/400\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::19:04:56.624]\n",
      "Saving backup of the training history epoch=13 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::19:04:56.698]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:04:56.736]\n",
      "train: argmin=12 --> min=0.021\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:04:56.738]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 588s - loss: 0.0211 - val_loss: 0.2377 - lr: 0.0010\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 15/400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::19:14:46.639]\n",
      "Saving backup of the training history epoch=14 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::19:14:46.720]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:14:47.168]\n",
      "train: argmin=12 --> min=0.021\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:14:47.170]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 589s - loss: 0.0218 - val_loss: 0.2370 - lr: 0.0010\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 16/400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::19:24:37.218]\n",
      "Saving backup of the training history epoch=15 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::19:24:37.297]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:24:37.335]\n",
      "train: argmin=15 --> min=0.0207\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:24:37.337]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 589s - loss: 0.0207 - val_loss: 0.2230 - lr: 0.0010\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 17/400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::19:34:27.479]\n",
      "Saving backup of the training history epoch=16 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::19:34:27.581]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:34:27.627]\n",
      "train: argmin=15 --> min=0.0207\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:34:27.630]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 589s - loss: 0.0209 - val_loss: 0.2206 - lr: 0.0010\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 18/400\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::19:44:17.704]\n",
      "Saving backup of the training history epoch=17 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::19:44:17.775]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:44:18.252]\n",
      "train: argmin=15 --> min=0.0207\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:44:18.254]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 589s - loss: 0.0209 - val_loss: 0.2170 - lr: 0.0010\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 19/400\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20352\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::19:54:08.619]\n",
      "Saving backup of the training history epoch=18 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::19:54:08.695]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:54:08.732]\n",
      "train: argmin=15 --> min=0.0207\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::19:54:08.735]\n",
      "val: argmin=9 --> min=0.204\n",
      "\n",
      "10/10 - 589s - loss: 0.0222 - val_loss: 0.2116 - lr: 0.0010\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 20/400\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20352 to 0.17283, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::20:04:10.812]\n",
      "Saving backup of the training history epoch=19 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::20:04:10.950]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:04:10.996]\n",
      "train: argmin=19 --> min=0.0193\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:04:11.000]\n",
      "val: argmin=19 --> min=0.173\n",
      "\n",
      "10/10 - 601s - loss: 0.0193 - val_loss: 0.1728 - lr: 0.0010\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 21/400\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17283\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::20:14:01.060]\n",
      "Saving backup of the training history epoch=20 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::20:14:01.140]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:14:01.175]\n",
      "train: argmin=19 --> min=0.0193\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:14:01.177]\n",
      "val: argmin=19 --> min=0.173\n",
      "\n",
      "10/10 - 589s - loss: 0.0202 - val_loss: 0.1917 - lr: 0.0010\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 22/400\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17283\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::20:23:51.406]\n",
      "Saving backup of the training history epoch=21 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::20:23:51.498]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:23:51.543]\n",
      "train: argmin=19 --> min=0.0193\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:23:51.546]\n",
      "val: argmin=19 --> min=0.173\n",
      "\n",
      "10/10 - 589s - loss: 0.0198 - val_loss: 0.1939 - lr: 0.0010\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 23/400\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17283\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::20:33:42.149]\n",
      "Saving backup of the training history epoch=22 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::20:33:42.235]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:33:42.279]\n",
      "train: argmin=19 --> min=0.0193\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:33:42.282]\n",
      "val: argmin=19 --> min=0.173\n",
      "\n",
      "10/10 - 589s - loss: 0.0206 - val_loss: 0.1846 - lr: 0.0010\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 24/400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17283\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::20:43:33.028]\n",
      "Saving backup of the training history epoch=23 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::20:43:33.120]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:43:33.163]\n",
      "train: argmin=19 --> min=0.0193\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:43:33.166]\n",
      "val: argmin=19 --> min=0.173\n",
      "\n",
      "10/10 - 589s - loss: 0.0204 - val_loss: 0.1817 - lr: 0.0010\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 25/400\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17283\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::20:53:24.145]\n",
      "Saving backup of the training history epoch=24 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::20:53:24.275]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:53:24.325]\n",
      "train: argmin=24 --> min=0.0188\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::20:53:24.329]\n",
      "val: argmin=19 --> min=0.173\n",
      "\n",
      "10/10 - 590s - loss: 0.0188 - val_loss: 0.1739 - lr: 0.0010\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 26/400\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17283 to 0.15523, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::21:03:26.808]\n",
      "Saving backup of the training history epoch=25 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::21:03:27.010]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:03:27.059]\n",
      "train: argmin=24 --> min=0.0188\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:03:27.063]\n",
      "val: argmin=25 --> min=0.155\n",
      "\n",
      "10/10 - 602s - loss: 0.0197 - val_loss: 0.1552 - lr: 0.0010\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 27/400\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.15523 to 0.13818, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::21:13:30.455]\n",
      "Saving backup of the training history epoch=26 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::21:13:30.673]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:13:30.724]\n",
      "train: argmin=24 --> min=0.0188\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:13:30.728]\n",
      "val: argmin=26 --> min=0.138\n",
      "\n",
      "10/10 - 602s - loss: 0.0206 - val_loss: 0.1382 - lr: 0.0010\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 28/400\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13818\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::21:23:22.349]\n",
      "Saving backup of the training history epoch=27 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::21:23:22.439]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:23:22.482]\n",
      "train: argmin=24 --> min=0.0188\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:23:22.485]\n",
      "val: argmin=26 --> min=0.138\n",
      "\n",
      "10/10 - 590s - loss: 0.0193 - val_loss: 0.1428 - lr: 0.0010\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 29/400\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.13818\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::21:33:13.235]\n",
      "Saving backup of the training history epoch=28 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::21:33:13.329]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:33:13.372]\n",
      "train: argmin=24 --> min=0.0188\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:33:13.375]\n",
      "val: argmin=26 --> min=0.138\n",
      "\n",
      "10/10 - 589s - loss: 0.0192 - val_loss: 0.1422 - lr: 0.0010\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 30/400\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.13818\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::21:43:04.500]\n",
      "Saving backup of the training history epoch=29 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::21:43:04.571]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:43:04.607]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:43:04.610]\n",
      "val: argmin=26 --> min=0.138\n",
      "\n",
      "10/10 - 590s - loss: 0.0180 - val_loss: 0.1387 - lr: 0.0010\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 31/400\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.13818\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::21:52:55.249]\n",
      "Saving backup of the training history epoch=30 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::21:52:55.366]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:52:55.415]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::21:52:55.418]\n",
      "val: argmin=26 --> min=0.138\n",
      "\n",
      "10/10 - 589s - loss: 0.0192 - val_loss: 0.1388 - lr: 0.0010\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.000774263682681127.\n",
      "Epoch 32/400\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.13818 to 0.11718, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::22:03:00.627]\n",
      "Saving backup of the training history epoch=31 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::22:03:00.871]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:03:00.921]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:03:00.924]\n",
      "val: argmin=31 --> min=0.117\n",
      "\n",
      "10/10 - 604s - loss: 0.0184 - val_loss: 0.1172 - lr: 7.7426e-04\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0005994842503189409.\n",
      "Epoch 33/400\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11718\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::22:12:52.495]\n",
      "Saving backup of the training history epoch=32 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::22:12:52.573]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:12:52.609]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:12:52.612]\n",
      "val: argmin=31 --> min=0.117\n",
      "\n",
      "10/10 - 590s - loss: 0.0192 - val_loss: 0.1214 - lr: 5.9948e-04\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.00046415888336127773.\n",
      "Epoch 34/400\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11718 to 0.10947, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::22:22:55.783]\n",
      "Saving backup of the training history epoch=33 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::22:22:55.866]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:22:55.904]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:22:55.907]\n",
      "val: argmin=33 --> min=0.109\n",
      "\n",
      "10/10 - 602s - loss: 0.0180 - val_loss: 0.1095 - lr: 4.6416e-04\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.00035938136638046257.\n",
      "Epoch 35/400\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.10947 to 0.10170, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::22:32:58.969]\n",
      "Saving backup of the training history epoch=34 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::22:32:59.062]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:32:59.103]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:32:59.105]\n",
      "val: argmin=34 --> min=0.102\n",
      "\n",
      "10/10 - 602s - loss: 0.0190 - val_loss: 0.1017 - lr: 3.5938e-04\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0002782559402207126.\n",
      "Epoch 36/400\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.10170 to 0.09786, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::22:43:02.348]\n",
      "Saving backup of the training history epoch=35 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::22:43:02.614]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:43:02.661]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:43:02.665]\n",
      "val: argmin=35 --> min=0.0979\n",
      "\n",
      "10/10 - 603s - loss: 0.0186 - val_loss: 0.0979 - lr: 2.7826e-04\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.00021544346900318845.\n",
      "Epoch 37/400\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.09786 to 0.08886, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::22:53:06.316]\n",
      "Saving backup of the training history epoch=36 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::22:53:06.559]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:53:06.610]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::22:53:06.614]\n",
      "val: argmin=36 --> min=0.0889\n",
      "\n",
      "10/10 - 602s - loss: 0.0180 - val_loss: 0.0889 - lr: 2.1544e-04\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001668100537200059.\n",
      "Epoch 38/400\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08886 to 0.08441, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::23:03:10.273]\n",
      "Saving backup of the training history epoch=37 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::23:03:10.495]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:03:10.547]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:03:10.551]\n",
      "val: argmin=37 --> min=0.0844\n",
      "\n",
      "10/10 - 602s - loss: 0.0182 - val_loss: 0.0844 - lr: 1.6681e-04\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001291549665014884.\n",
      "Epoch 39/400\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.08441 to 0.08062, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::23:13:16.095]\n",
      "Saving backup of the training history epoch=38 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::23:13:16.195]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:13:16.235]\n",
      "train: argmin=29 --> min=0.018\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:13:16.238]\n",
      "val: argmin=38 --> min=0.0806\n",
      "\n",
      "10/10 - 604s - loss: 0.0185 - val_loss: 0.0806 - lr: 1.2915e-04\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 40/400\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08062 to 0.07461, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::23:23:19.970]\n",
      "Saving backup of the training history epoch=39 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::23:23:20.049]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:23:20.086]\n",
      "train: argmin=39 --> min=0.0175\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:23:20.089]\n",
      "val: argmin=39 --> min=0.0746\n",
      "\n",
      "10/10 - 602s - loss: 0.0175 - val_loss: 0.0746 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 41/400\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.07461 to 0.06934, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::23:33:23.462]\n",
      "Saving backup of the training history epoch=40 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::23:33:23.672]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:33:23.720]\n",
      "train: argmin=40 --> min=0.0174\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:33:23.723]\n",
      "val: argmin=40 --> min=0.0693\n",
      "\n",
      "10/10 - 602s - loss: 0.0174 - val_loss: 0.0693 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.00011288378916846895.\n",
      "Epoch 42/400\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.06934 to 0.06462, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::23:43:28.367]\n",
      "Saving backup of the training history epoch=41 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::23:43:28.449]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:43:28.487]\n",
      "train: argmin=40 --> min=0.0174\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:43:28.491]\n",
      "val: argmin=41 --> min=0.0646\n",
      "\n",
      "10/10 - 603s - loss: 0.0192 - val_loss: 0.0646 - lr: 1.1288e-04\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.00012742749857031334.\n",
      "Epoch 43/400\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.06462 to 0.06075, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-11-30::23:53:32.107]\n",
      "Saving backup of the training history epoch=42 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-11-30::23:53:32.243]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:53:32.290]\n",
      "train: argmin=40 --> min=0.0174\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-11-30::23:53:32.293]\n",
      "val: argmin=42 --> min=0.0608\n",
      "\n",
      "10/10 - 602s - loss: 0.0193 - val_loss: 0.0608 - lr: 1.2743e-04\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001438449888287663.\n",
      "Epoch 44/400\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.06075 to 0.05825, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::00:03:36.764]\n",
      "Saving backup of the training history epoch=43 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::00:03:36.965]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:03:37.011]\n",
      "train: argmin=40 --> min=0.0174\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:03:37.015]\n",
      "val: argmin=43 --> min=0.0582\n",
      "\n",
      "10/10 - 603s - loss: 0.0178 - val_loss: 0.0582 - lr: 1.4384e-04\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001623776739188721.\n",
      "Epoch 45/400\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05825 to 0.05368, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::00:13:41.925]\n",
      "Saving backup of the training history epoch=44 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::00:13:42.139]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:13:42.189]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:13:42.192]\n",
      "val: argmin=44 --> min=0.0537\n",
      "\n",
      "10/10 - 604s - loss: 0.0172 - val_loss: 0.0537 - lr: 1.6238e-04\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.00018329807108324357.\n",
      "Epoch 46/400\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05368 to 0.04837, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::00:23:50.126]\n",
      "Saving backup of the training history epoch=45 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::00:23:50.304]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:23:50.349]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:23:50.352]\n",
      "val: argmin=45 --> min=0.0484\n",
      "\n",
      "10/10 - 607s - loss: 0.0183 - val_loss: 0.0484 - lr: 1.8330e-04\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.00020691380811147902.\n",
      "Epoch 47/400\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04837\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::00:33:43.354]\n",
      "Saving backup of the training history epoch=46 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::00:33:43.479]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:33:43.526]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:33:43.529]\n",
      "val: argmin=45 --> min=0.0484\n",
      "\n",
      "10/10 - 591s - loss: 0.0189 - val_loss: 0.0491 - lr: 2.0691e-04\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.00023357214690901214.\n",
      "Epoch 48/400\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.04837 to 0.04564, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::00:43:47.172]\n",
      "Saving backup of the training history epoch=47 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::00:43:47.493]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:43:47.543]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:43:47.547]\n",
      "val: argmin=47 --> min=0.0456\n",
      "\n",
      "10/10 - 603s - loss: 0.0182 - val_loss: 0.0456 - lr: 2.3357e-04\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.00026366508987303583.\n",
      "Epoch 49/400\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04564 to 0.04104, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::00:53:52.161]\n",
      "Saving backup of the training history epoch=48 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::00:53:52.493]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:53:52.542]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::00:53:52.545]\n",
      "val: argmin=48 --> min=0.041\n",
      "\n",
      "10/10 - 603s - loss: 0.0187 - val_loss: 0.0410 - lr: 2.6367e-04\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.00029763514416313193.\n",
      "Epoch 50/400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04104\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::01:03:45.039]\n",
      "Saving backup of the training history epoch=49 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::01:03:45.134]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:03:45.179]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:03:45.182]\n",
      "val: argmin=48 --> min=0.041\n",
      "\n",
      "10/10 - 591s - loss: 0.0183 - val_loss: 0.0414 - lr: 2.9764e-04\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0003359818286283781.\n",
      "Epoch 51/400\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04104 to 0.03847, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::01:13:49.881]\n",
      "Saving backup of the training history epoch=50 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::01:13:50.647]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:13:50.697]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:13:50.700]\n",
      "val: argmin=50 --> min=0.0385\n",
      "\n",
      "10/10 - 604s - loss: 0.0188 - val_loss: 0.0385 - lr: 3.3598e-04\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.000379269019073225.\n",
      "Epoch 52/400\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.03847 to 0.03555, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::01:23:54.693]\n",
      "Saving backup of the training history epoch=51 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::01:23:54.916]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:23:54.965]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:23:54.970]\n",
      "val: argmin=51 --> min=0.0355\n",
      "\n",
      "10/10 - 603s - loss: 0.0182 - val_loss: 0.0355 - lr: 3.7927e-04\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.00042813323987193956.\n",
      "Epoch 53/400\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03555\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::01:33:48.222]\n",
      "Saving backup of the training history epoch=52 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::01:33:48.310]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:33:48.347]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:33:48.351]\n",
      "val: argmin=51 --> min=0.0355\n",
      "\n",
      "10/10 - 592s - loss: 0.0188 - val_loss: 0.0363 - lr: 4.2813e-04\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0004832930238571752.\n",
      "Epoch 54/400\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03555 to 0.02772, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::01:43:52.717]\n",
      "Saving backup of the training history epoch=53 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::01:43:52.808]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:43:52.851]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:43:52.854]\n",
      "val: argmin=53 --> min=0.0277\n",
      "\n",
      "10/10 - 603s - loss: 0.0174 - val_loss: 0.0277 - lr: 4.8329e-04\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.000545559478116852.\n",
      "Epoch 55/400\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02772\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::01:53:45.770]\n",
      "Saving backup of the training history epoch=54 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::01:53:45.826]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:53:45.859]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::01:53:45.861]\n",
      "val: argmin=53 --> min=0.0277\n",
      "\n",
      "10/10 - 592s - loss: 0.0193 - val_loss: 0.0343 - lr: 5.4556e-04\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0006158482110660267.\n",
      "Epoch 56/400\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02772\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::02:03:38.533]\n",
      "Saving backup of the training history epoch=55 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::02:03:38.623]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:03:38.665]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:03:38.669]\n",
      "val: argmin=53 --> min=0.0277\n",
      "\n",
      "10/10 - 591s - loss: 0.0195 - val_loss: 0.0285 - lr: 6.1585e-04\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0006951927961775605.\n",
      "Epoch 57/400\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02772 to 0.02592, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::02:13:44.627]\n",
      "Saving backup of the training history epoch=56 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::02:13:44.726]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:13:44.773]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:13:44.776]\n",
      "val: argmin=56 --> min=0.0259\n",
      "\n",
      "10/10 - 605s - loss: 0.0189 - val_loss: 0.0259 - lr: 6.9519e-04\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0007847599703514606.\n",
      "Epoch 58/400\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.02592\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::02:23:37.410]\n",
      "Saving backup of the training history epoch=57 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::02:23:37.493]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:23:37.533]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:23:37.536]\n",
      "val: argmin=56 --> min=0.0259\n",
      "\n",
      "10/10 - 591s - loss: 0.0188 - val_loss: 0.0270 - lr: 7.8476e-04\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0008858667904100823.\n",
      "Epoch 59/400\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02592\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::02:33:30.357]\n",
      "Saving backup of the training history epoch=58 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::02:33:30.425]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:33:30.457]\n",
      "train: argmin=44 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:33:30.459]\n",
      "val: argmin=56 --> min=0.0259\n",
      "\n",
      "10/10 - 591s - loss: 0.0181 - val_loss: 0.0265 - lr: 8.8587e-04\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 60/400\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02592 to 0.02467, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::02:43:35.537]\n",
      "Saving backup of the training history epoch=59 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::02:43:35.642]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:43:35.690]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:43:35.693]\n",
      "val: argmin=59 --> min=0.0247\n",
      "\n",
      "10/10 - 604s - loss: 0.0172 - val_loss: 0.0247 - lr: 0.0010\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 61/400\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02467 to 0.02409, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::02:53:39.538]\n",
      "Saving backup of the training history epoch=60 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::02:53:39.629]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:53:39.669]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::02:53:39.673]\n",
      "val: argmin=60 --> min=0.0241\n",
      "\n",
      "10/10 - 602s - loss: 0.0191 - val_loss: 0.0241 - lr: 0.0010\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 62/400\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02409\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::03:03:32.751]\n",
      "Saving backup of the training history epoch=61 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::03:03:32.854]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:03:32.893]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:03:32.896]\n",
      "val: argmin=60 --> min=0.0241\n",
      "\n",
      "10/10 - 592s - loss: 0.0188 - val_loss: 0.0254 - lr: 0.0010\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 63/400\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02409 to 0.02142, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::03:13:37.383]\n",
      "Saving backup of the training history epoch=62 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::03:13:37.481]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:13:37.531]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:13:37.535]\n",
      "val: argmin=62 --> min=0.0214\n",
      "\n",
      "10/10 - 603s - loss: 0.0188 - val_loss: 0.0214 - lr: 0.0010\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 64/400\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02142\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::03:23:29.986]\n",
      "Saving backup of the training history epoch=63 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::03:23:30.084]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:23:30.127]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:23:30.130]\n",
      "val: argmin=62 --> min=0.0214\n",
      "\n",
      "10/10 - 591s - loss: 0.0185 - val_loss: 0.0222 - lr: 0.0010\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 65/400\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02142\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::03:33:22.980]\n",
      "Saving backup of the training history epoch=64 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::03:33:23.077]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:33:23.120]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:33:23.123]\n",
      "val: argmin=62 --> min=0.0214\n",
      "\n",
      "10/10 - 592s - loss: 0.0196 - val_loss: 0.0217 - lr: 0.0010\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 66/400\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.02142 to 0.02062, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::03:43:27.314]\n",
      "Saving backup of the training history epoch=65 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::03:43:27.592]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:43:27.641]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:43:27.644]\n",
      "val: argmin=65 --> min=0.0206\n",
      "\n",
      "10/10 - 603s - loss: 0.0181 - val_loss: 0.0206 - lr: 0.0010\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 67/400\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02062\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::03:53:21.562]\n",
      "Saving backup of the training history epoch=66 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::03:53:21.666]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:53:21.710]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::03:53:21.714]\n",
      "val: argmin=65 --> min=0.0206\n",
      "\n",
      "10/10 - 592s - loss: 0.0183 - val_loss: 0.0221 - lr: 0.0010\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 68/400\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.02062 to 0.02026, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::04:03:26.349]\n",
      "Saving backup of the training history epoch=67 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::04:03:26.449]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:03:26.492]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:03:26.495]\n",
      "val: argmin=67 --> min=0.0203\n",
      "\n",
      "10/10 - 603s - loss: 0.0181 - val_loss: 0.0203 - lr: 0.0010\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 69/400\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02026\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::04:13:19.201]\n",
      "Saving backup of the training history epoch=68 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::04:13:19.255]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:13:19.284]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:13:19.287]\n",
      "val: argmin=67 --> min=0.0203\n",
      "\n",
      "10/10 - 591s - loss: 0.0192 - val_loss: 0.0203 - lr: 0.0010\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 70/400\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02026 to 0.01960, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::04:23:24.124]\n",
      "Saving backup of the training history epoch=69 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::04:23:24.200]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:23:24.239]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:23:24.242]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 603s - loss: 0.0175 - val_loss: 0.0196 - lr: 0.0010\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 71/400\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::04:33:17.169]\n",
      "Saving backup of the training history epoch=70 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::04:33:17.274]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:33:17.320]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:33:17.323]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 592s - loss: 0.0183 - val_loss: 0.0206 - lr: 0.0010\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 72/400\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::04:43:10.315]\n",
      "Saving backup of the training history epoch=71 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::04:43:10.413]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:43:10.456]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:43:10.458]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 592s - loss: 0.0183 - val_loss: 0.0198 - lr: 0.0010\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 73/400\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::04:53:04.613]\n",
      "Saving backup of the training history epoch=72 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::04:53:04.693]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:53:04.730]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::04:53:04.733]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 593s - loss: 0.0175 - val_loss: 0.0198 - lr: 0.0010\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 74/400\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::05:02:57.667]\n",
      "Saving backup of the training history epoch=73 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::05:02:57.747]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:02:57.786]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:02:57.788]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 592s - loss: 0.0182 - val_loss: 0.0202 - lr: 0.0010\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 75/400\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::05:12:51.643]\n",
      "Saving backup of the training history epoch=74 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::05:12:51.754]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:12:51.801]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:12:51.805]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 593s - loss: 0.0181 - val_loss: 0.0198 - lr: 0.0010\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 76/400\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::05:22:44.397]\n",
      "Saving backup of the training history epoch=75 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::05:22:44.492]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:22:44.534]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:22:44.537]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 591s - loss: 0.0180 - val_loss: 0.0203 - lr: 0.0010\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 77/400\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::05:32:37.520]\n",
      "Saving backup of the training history epoch=76 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::05:32:37.608]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:32:37.646]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:32:37.649]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 592s - loss: 0.0188 - val_loss: 0.0220 - lr: 0.0010\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 78/400\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.01960\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::05:42:31.267]\n",
      "Saving backup of the training history epoch=77 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::05:42:31.359]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:42:31.400]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:42:31.403]\n",
      "val: argmin=69 --> min=0.0196\n",
      "\n",
      "10/10 - 592s - loss: 0.0187 - val_loss: 0.0202 - lr: 0.0010\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 79/400\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.01960 to 0.01894, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::05:52:36.678]\n",
      "Saving backup of the training history epoch=78 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::05:52:36.757]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:52:36.797]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::05:52:36.800]\n",
      "val: argmin=78 --> min=0.0189\n",
      "\n",
      "10/10 - 604s - loss: 0.0181 - val_loss: 0.0189 - lr: 0.0010\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 80/400\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.01894\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::06:02:29.614]\n",
      "Saving backup of the training history epoch=79 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::06:02:29.720]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:02:29.766]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:02:29.770]\n",
      "val: argmin=78 --> min=0.0189\n",
      "\n",
      "10/10 - 592s - loss: 0.0177 - val_loss: 0.0192 - lr: 0.0010\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 81/400\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.01894\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::06:12:23.073]\n",
      "Saving backup of the training history epoch=80 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::06:12:23.159]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:12:23.197]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:12:23.199]\n",
      "val: argmin=78 --> min=0.0189\n",
      "\n",
      "10/10 - 592s - loss: 0.0180 - val_loss: 0.0194 - lr: 0.0010\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 0.0008858667904100823.\n",
      "Epoch 82/400\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.01894\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::06:22:16.145]\n",
      "Saving backup of the training history epoch=81 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::06:22:16.260]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:22:16.308]\n",
      "train: argmin=59 --> min=0.0172\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:22:16.312]\n",
      "val: argmin=78 --> min=0.0189\n",
      "\n",
      "10/10 - 592s - loss: 0.0181 - val_loss: 0.0191 - lr: 8.8587e-04\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 0.0007847599703514615.\n",
      "Epoch 83/400\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.01894 to 0.01892, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::06:32:17.748]\n",
      "Saving backup of the training history epoch=82 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::06:32:17.834]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:32:17.877]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:32:17.880]\n",
      "val: argmin=82 --> min=0.0189\n",
      "\n",
      "10/10 - 600s - loss: 0.0166 - val_loss: 0.0189 - lr: 7.8476e-04\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 0.0006951927961775605.\n",
      "Epoch 84/400\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.01892 to 0.01886, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::06:42:20.257]\n",
      "Saving backup of the training history epoch=83 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::06:42:20.335]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:42:20.374]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:42:20.377]\n",
      "val: argmin=83 --> min=0.0189\n",
      "\n",
      "10/10 - 601s - loss: 0.0180 - val_loss: 0.0189 - lr: 6.9519e-04\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 0.0006158482110660267.\n",
      "Epoch 85/400\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.01886 to 0.01882, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::06:52:24.511]\n",
      "Saving backup of the training history epoch=84 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::06:52:24.600]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:52:24.639]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::06:52:24.643]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 603s - loss: 0.0178 - val_loss: 0.0188 - lr: 6.1585e-04\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 0.000545559478116852.\n",
      "Epoch 86/400\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::07:02:18.728]\n",
      "Saving backup of the training history epoch=85 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::07:02:18.823]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:02:18.863]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:02:18.867]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 593s - loss: 0.0184 - val_loss: 0.0190 - lr: 5.4556e-04\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 0.0004832930238571752.\n",
      "Epoch 87/400\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::07:12:12.008]\n",
      "Saving backup of the training history epoch=86 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::07:12:12.132]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:12:12.181]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:12:12.184]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0175 - val_loss: 0.0192 - lr: 4.8329e-04\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 0.00042813323987193956.\n",
      "Epoch 88/400\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::07:22:05.478]\n",
      "Saving backup of the training history epoch=87 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::07:22:05.572]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:22:05.614]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:22:05.617]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0183 - val_loss: 0.0190 - lr: 4.2813e-04\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 0.000379269019073225.\n",
      "Epoch 89/400\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::07:31:58.616]\n",
      "Saving backup of the training history epoch=88 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::07:31:58.679]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:31:58.708]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:31:58.710]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 593s - loss: 0.0175 - val_loss: 0.0191 - lr: 3.7927e-04\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 0.0003359818286283781.\n",
      "Epoch 90/400\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::07:41:52.703]\n",
      "Saving backup of the training history epoch=89 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::07:41:52.785]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:41:52.822]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:41:52.824]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0174 - val_loss: 0.0191 - lr: 3.3598e-04\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 0.00029763514416313193.\n",
      "Epoch 91/400\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::07:51:45.731]\n",
      "Saving backup of the training history epoch=90 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::07:51:45.835]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:51:45.880]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::07:51:45.883]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0175 - val_loss: 0.0192 - lr: 2.9764e-04\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 0.00026366508987303583.\n",
      "Epoch 92/400\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::08:01:39.637]\n",
      "Saving backup of the training history epoch=91 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::08:01:39.734]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:01:39.780]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:01:39.783]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0182 - val_loss: 0.0192 - lr: 2.6367e-04\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 0.00023357214690901214.\n",
      "Epoch 93/400\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::08:11:32.985]\n",
      "Saving backup of the training history epoch=92 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::08:11:33.084]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:11:33.129]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:11:33.132]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0171 - val_loss: 0.0191 - lr: 2.3357e-04\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 0.00020691380811147902.\n",
      "Epoch 94/400\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.01882\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::08:21:26.164]\n",
      "Saving backup of the training history epoch=93 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::08:21:26.238]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:21:26.268]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:21:26.271]\n",
      "val: argmin=84 --> min=0.0188\n",
      "\n",
      "10/10 - 592s - loss: 0.0174 - val_loss: 0.0193 - lr: 2.0691e-04\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 0.00018329807108324357.\n",
      "Epoch 95/400\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.01882 to 0.01869, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::08:31:27.377]\n",
      "Saving backup of the training history epoch=94 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::08:31:27.455]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:31:27.493]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:31:27.496]\n",
      "val: argmin=94 --> min=0.0187\n",
      "\n",
      "10/10 - 600s - loss: 0.0177 - val_loss: 0.0187 - lr: 1.8330e-04\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 0.0001623776739188721.\n",
      "Epoch 96/400\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.01869\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::08:41:21.313]\n",
      "Saving backup of the training history epoch=95 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::08:41:21.376]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:41:21.411]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:41:21.414]\n",
      "val: argmin=94 --> min=0.0187\n",
      "\n",
      "10/10 - 592s - loss: 0.0178 - val_loss: 0.0188 - lr: 1.6238e-04\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 0.0001438449888287663.\n",
      "Epoch 97/400\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.01869\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::08:51:14.699]\n",
      "Saving backup of the training history epoch=96 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::08:51:14.781]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:51:14.818]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::08:51:14.820]\n",
      "val: argmin=94 --> min=0.0187\n",
      "\n",
      "10/10 - 592s - loss: 0.0171 - val_loss: 0.0188 - lr: 1.4384e-04\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 0.00012742749857031348.\n",
      "Epoch 98/400\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.01869 to 0.01866, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::09:01:19.879]\n",
      "Saving backup of the training history epoch=97 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::09:01:19.954]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:01:19.992]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:01:19.995]\n",
      "val: argmin=97 --> min=0.0187\n",
      "\n",
      "10/10 - 604s - loss: 0.0166 - val_loss: 0.0187 - lr: 1.2743e-04\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 0.00011288378916846895.\n",
      "Epoch 99/400\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01866 to 0.01861, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939.autosaved.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::09:11:25.394]\n",
      "Saving backup of the training history epoch=98 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::09:11:25.468]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:11:25.507]\n",
      "train: argmin=82 --> min=0.0166\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:11:25.510]\n",
      "val: argmin=98 --> min=0.0186\n",
      "\n",
      "10/10 - 604s - loss: 0.0171 - val_loss: 0.0186 - lr: 1.1288e-04\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 100/400\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01861\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::09:21:18.388]\n",
      "Saving backup of the training history epoch=99 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::09:21:18.469]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:21:18.507]\n",
      "train: argmin=99 --> min=0.0162\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:21:18.509]\n",
      "val: argmin=98 --> min=0.0186\n",
      "\n",
      "10/10 - 592s - loss: 0.0162 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 101/400\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01861\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:085}::[2020-12-01::09:31:11.952]\n",
      "Saving backup of the training history epoch=100 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet3d.vanilla03-f16.fold000.1606-750-939/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-01::09:31:12.009]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:31:12.044]\n",
      "train: argmin=99 --> min=0.0162\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-01::09:31:12.047]\n",
      "val: argmin=98 --> min=0.0186\n",
      "\n",
      "10/10 - 592s - loss: 0.0171 - val_loss: 0.0187 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to 0.00011288378916846895.\n",
      "Epoch 102/400\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 400\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        # data sequences\n",
    "        x=crop_seq_train,\n",
    "        validation_data=crop_seq_val,\n",
    "\n",
    "        # epochs\n",
    "        initial_epoch=0,\n",
    "        epochs=n_epochs,\n",
    "#         initial_epoch=history_cb.last_epoch + 1,  # for some reason it is 0-starting and others 1-starting...\n",
    "#         epochs=history_cb.last_epoch + 1 + n_epochs,  \n",
    "    #     initial_epoch=113,\n",
    "    #     epochs=126,\n",
    "\n",
    "        # others\n",
    "        callbacks=callbacks,  \n",
    "        verbose=2,\n",
    "        use_multiprocessing=False,   \n",
    "    );\n",
    "\n",
    "except Exception as ex:\n",
    "    slack.notify_error()\n",
    "    raise ex\n",
    "    \n",
    "else:\n",
    "    slack.notify_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows := 2, ncols := 1, figsize=(2.5 * (sz := 5), nrows * sz), dpi=100)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "hist_display = viz.TrainingHistoryDisplay(\n",
    "    history_cb.history, \n",
    "    model_name=tomo2seg_model.name,\n",
    "    loss_name=model.loss.__name__,\n",
    "    x_axis_mode=(\n",
    "        \"epoch\", \n",
    "        \"batch\",\n",
    "        \"crop\", \n",
    "        \"voxel\",\n",
    "        \"time\",\n",
    "    ),\n",
    ").plot(\n",
    "    axs, \n",
    "    with_lr=True,\n",
    "    metrics=(\n",
    "        \"loss\", \n",
    "#         \"jaccard2.class_idx=0\",\n",
    "#         \"jaccard2.class_idx=1\",\n",
    "#         \"jaccard2.class_idx=2\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[-1].set_yscale(\"log\")\n",
    "\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"loss\"][0])\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"val_loss\"][0], txt_kwargs=dict(rotation=0))\n",
    "\n",
    "hist_display.fig_.savefig(\n",
    "    tomo2seg_model.model_path / (hist_display.title + \".png\"),\n",
    "    format='png',\n",
    ")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "outputs": [],
   "source": [
    "history_cb.dataframe.to_csv(history_cb.csv_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [],
   "source": [
    "model.save(tomo2seg_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"train-03.ipynb\"\n",
    "import os\n",
    "this_dir = os.getcwd()\n",
    "logger.warning(f\"{this_nb_name=} {this_dir=}\")\n",
    "\n",
    "os.system(f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {str(tomo2seg_model.model_path)} --to html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

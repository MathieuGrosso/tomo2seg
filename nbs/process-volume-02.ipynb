{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pprint as pprint_module\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "import copy\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "from progressbar import progressbar as pbar\n",
    "from enum import Enum\n",
    "import re\n",
    "from enum import Enum\n",
    "from matplotlib import patches\n",
    "import seaborn as sns\n",
    "from typing import Type\n",
    "from dataclasses import dataclass\n",
    "import dataclasses\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from cnn_segm import keras_custom_loss\n",
    "\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    VolumeCropSequence, MetaCrop3DGenerator, VSConstantEverywhere, \n",
    "    GTConstantEverywhere, SequentialGridPosition, ET3DConstantEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg.data import EstimationVolume\n",
    "from tomo2seg import viz\n",
    "from tomo2seg import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-17-bba693eaf462>:<module>:008}::[2020-12-08::15:14:30.411]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-17-bba693eaf462>:<module>:009}::[2020-12-08::15:14:30.413]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-17-bba693eaf462>:<module>:010}::[2020-12-08::15:14:30.414]\n",
      "Should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-17-bba693eaf462>:<module>:011}::[2020-12-08::15:14:30.416]\n",
      "Should return 2 devices...\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "\n",
    "n_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "    \n",
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {n_gpus}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\")\n",
    "logger.debug(f\"Should return 2 devices...\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomo2seg.datasets import (\n",
    "#     VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_NEIGHBOUR as VOLUME_NAME_VERSION,    \n",
    "#     VOLUME_COMPOSITE_FLEX as VOLUME_NAME_VERSION,    \n",
    "    VOLUME_COMPOSITE_BIAXE as VOLUME_NAME_VERSION,    \n",
    ")\n",
    "\n",
    "# runid = 1607343593\n",
    "try:\n",
    "    runid\n",
    "except NameError:\n",
    "    runid = int(time.time())\n",
    "\n",
    "args = process.ProcessVolumeArgs(\n",
    "    model_name=\"unet2d.vanilla03-f16.fold000.1606-505-109\",\n",
    "    model_type=process.ModelType.input2d, \n",
    "    \n",
    "    volume_name=VOLUME_NAME_VERSION[0], \n",
    "    volume_version=VOLUME_NAME_VERSION[1], \n",
    "    \n",
    "    partition_alias=None,\n",
    "    \n",
    "    cropping_strategy=process.CroppingStrategy.maximum_size_reduced_overlap, \n",
    "    aggregation_strategy=process.AggregationStrategy.average_probabilities, \n",
    "    \n",
    "    runid=runid,\n",
    "    probabilities_dtype = np.float16,\n",
    "    \n",
    "    opts=process.ProcessVolumeOpts(\n",
    "        save_probas_by_class = False,\n",
    "        debug__save_figs = True,\n",
    "    ), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:258}::[2020-12-08::15:00:57.195]\n",
      "vol=Volume(name='PA66GF30', version='biaxe', _metadata=None)\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:195}::[2020-12-08::15:00:57.197]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.biaxe/PA66GF30.biaxe.metadata.yml`.\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata_path:328}::[2020-12-08::15:00:57.214]\n",
      "Creating metadata file /home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057.metadata.yml.\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:__setitem__:336}::[2020-12-08::15:00:57.239]\n",
      "Writing to file self.metadata_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057.metadata.yml').\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:__setitem__:336}::[2020-12-08::15:00:57.274]\n",
      "Writing to file self.metadata_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057.metadata.yml').\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:__setitem__:336}::[2020-12-08::15:00:57.290]\n",
      "Writing to file self.metadata_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057.metadata.yml').\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tomo2seg_model = Tomo2SegModel.build_from_model_name(args.model_name)\n",
    "\n",
    "volume = Volume.with_check(\n",
    "    name=args.volume_name, version=args.volume_version\n",
    ")\n",
    "\n",
    "partition = volume[args.partition_alias] if args.partition_alias is not None else None\n",
    "\n",
    "estimation_volume = EstimationVolume.from_objects(\n",
    "    volume=volume, \n",
    "    model=tomo2seg_model, \n",
    "    set_partition=partition,\n",
    "    runid=runid,\n",
    ")\n",
    "\n",
    "# this is informal metadata for human use\n",
    "estimation_volume[\"aggregation_strategy\"] = args.aggregation_strategy.name\n",
    "estimation_volume[\"cropping_strategy\"] = args.cropping_strategy.name\n",
    "estimation_volume[\"probabilities_dtype\"] = args.probabilities_dtype.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-6-ce63d89898fb>:<module>:001}::[2020-12-08::15:00:57.382]\n",
      "args\n",
      "{   'aggregation_strategy': <AggregationStrategy.average_probabilities: 0>,\n",
      "    'cropping_strategy': <CroppingStrategy.minimum_overlap: 1>,\n",
      "    'model_name': 'unet2d.vanilla03-f16.fold000.1606-505-109',\n",
      "    'model_type': <ModelType.input2d: 0>,\n",
      "    'opts': {'debug__save_figs': True, 'save_probas_by_class': False},\n",
      "    'partition_alias': None,\n",
      "    'probabilities_dtype': <class 'numpy.float16'>,\n",
      "    'runid': 1607436057,\n",
      "    'volume_name': 'PA66GF30',\n",
      "    'volume_version': 'biaxe'}\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-6-ce63d89898fb>:<module>:002}::[2020-12-08::15:00:57.384]\n",
      "estimation_volume=EstimationVolume(volume_fullname='PA66GF30.biaxe', model_name='unet2d.vanilla03-f16.fold000.1606-505-109', runid=1607436057, partition=None)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-6-ce63d89898fb>:<module>:004}::[2020-12-08::15:00:57.385]\n",
      "volume=Volume(name='PA66GF30', version='biaxe', _metadata=Volume.Metadata(dimensions=[1579, 1845, 2002], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions=None))\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-6-ce63d89898fb>:<module>:005}::[2020-12-08::15:00:57.386]\n",
      "partition=None\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-6-ce63d89898fb>:<module>:006}::[2020-12-08::15:00:57.388]\n",
      "tomo2seg_model=Model(master_name='unet2d', version='vanilla03-f16', fold=0, runid=1606505109, factory_function=None, factory_kwargs=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"args\\n{pprint_module.PrettyPrinter(indent=4, compact=False).pformat(dataclasses.asdict(args))}\")\n",
    "logger.info(f\"{estimation_volume=}\")\n",
    "            \n",
    "logger.debug(f\"{volume=}\")\n",
    "logger.debug(f\"{partition=}\")\n",
    "logger.debug(f\"{tomo2seg_model=}\")\n",
    "\n",
    "if args.model_type == process.ModelType.input2halfd:\n",
    "    raise NotImplementedError(f\"{args.model_type=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gpu distribution strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-19-64511e033ae3>:<module>:009}::[2020-12-08::15:14:43.177]\n",
      "one_device=<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7f1978116ac0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "# strategy = tf.distribute.MirroredStrategy()  \n",
    "\n",
    "# there is a bug with MirroredStrategy when you model.predict() with batch_size=1\n",
    "# https://docs.google.com/document/d/17X1CUvGtlio3pkbKFemSGbF2Qnn0vWAZfCLsgFPoOqg/edit?usp=sharing\n",
    "one_device = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "# logger.info(f\"Because {args.model_type=}, MirroredStrategy cannot be used. Switched to {strategy.__class__.__name__}.\")\n",
    "    \n",
    "logger.debug(f\"{one_device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-101-7454cecbba19>:<module>:037}::[2020-12-08::17:27:44.413]\n",
      "Loading model with OneDeviceStrategy.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:003}::[2020-12-08::17:27:44.415]\n",
      "Loading model from autosaved file: unet2d.vanilla03-f16.fold000.1606-505-109.autosaved.hdf5\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:010}::[2020-12-08::17:27:47.706]\n",
      "Changing the model's input type to accept any size of crop.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:016}::[2020-12-08::17:27:47.708]\n",
      "input_n_channels=(1,)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:024}::[2020-12-08::17:27:47.711]\n",
      "anysize_input=<tf.Tensor 'input_any_image_size_1:0' shape=(None, None, None, None, 1) dtype=float32>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    \n",
    "    logger.info(f\"Loading model from autosaved file: {tomo2seg_model.autosaved_model_path.name}\")\n",
    "    \n",
    "    model = tf.keras.models.load_model(\n",
    "        tomo2seg_model.autosaved_model_path_str,\n",
    "        compile=False\n",
    "    )\n",
    "    \n",
    "    logger.debug(\"Changing the model's input type to accept any size of crop.\")\n",
    "    \n",
    "    in_ = model.layers[0]\n",
    "    in_shape = in_.input_shape[0]\n",
    "    input_n_channels = in_shape[-1:]\n",
    "\n",
    "    logger.debug(f\"{input_n_channels=}\")\n",
    "    \n",
    "    # make it capable of getting any dimension in the input\n",
    "    anysize_input = layers.Input(\n",
    "        shape=[None, None, None] + list(input_n_channels),\n",
    "        name=\"input_any_image_size\"\n",
    "    )\n",
    "    \n",
    "    logger.debug(f\"{anysize_input=}\")\n",
    "    \n",
    "    model.layers[0] = anysize_input\n",
    "    \n",
    "    # todo keep this somewhere instead of copying and pasting\n",
    "    optimizer = optimizers.Adam()\n",
    "    loss_func = keras_custom_loss.jaccard2_loss\n",
    "\n",
    "    model.compile(loss=loss_func, optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "with one_device.scope():\n",
    "    logger.info(f\"Loading model with {one_device.__class__.__name__}.\")\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-25-777069a45709>:<module>:014}::[2020-12-08::15:18:35.862]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1579 x 1845 x 2002\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-25-777069a45709>:<module>:018}::[2020-12-08::15:19:20.623]\n",
      "voldata.shape=(1579, 1845, 2002)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-777069a45709>:<module>:025}::[2020-12-08::15:19:20.629]\n",
      "No partition.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-777069a45709>:<module>:030}::[2020-12-08::15:19:20.631]\n",
      "data_volume.shape=(1579, 1845, 2002)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-777069a45709>:<module>:031}::[2020-12-08::15:19:20.632]\n",
      "data_volume.size=5832336510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(f\"Loading data from disk at file: {volume.data_path.name}\")\n",
    "\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "if partition is not None:\n",
    "    logger.debug(f\"Cutting data with {partition.alias=}\")\n",
    "    data_volume = partition.get_volume_partition(voldata)\n",
    "\n",
    "else:\n",
    "    logger.debug(f\"No partition.\")\n",
    "    data_volume = voldata\n",
    "\n",
    "del voldata\n",
    "\n",
    "logger.debug(f\"{data_volume.shape=}\")\n",
    "logger.debug(f\"{data_volume.size=}  ({humanize.intword(data_volume.size)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-77-789dccd181b8>:<module>:004}::[2020-12-08::16:51:51.707]\n",
      "figs_dir=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.biaxe.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-436-057')\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-77-789dccd181b8>:<module>:009}::[2020-12-08::16:51:51.708]\n",
      "volume_shape=(1579, 1845, 2002)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    figs_dir = estimation_volume.dir\n",
    "    \n",
    "    logger.debug(f\"{figs_dir=}\")\n",
    "    figs_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "volume_shape = data_volume.shape\n",
    "\n",
    "logger.info(f\"{volume_shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-85-887b344415fa>:<module>:004}::[2020-12-08::16:57:59.069]\n",
      "MAX_N_VOXELS=169869312 (169,869,312)\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-85-887b344415fa>:<module>:005}::[2020-12-08::16:57:59.071]\n",
      "MULTIPLE_REQUIREMENT=16\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-85-887b344415fa>:<module>:024}::[2020-12-08::16:57:59.072]\n",
      "the max overlap in each direction will be (21, 27, 30)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-85-887b344415fa>:<module>:029}::[2020-12-08::16:57:59.073]\n",
      "crop_dims_multiple_16=(800, 928, 1008) using args.cropping_strategy=<CroppingStrategy.maximum_size_reduced_overlap: 1>\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-85-887b344415fa>:<module>:045}::[2020-12-08::16:57:59.075]\n",
      "ideal crop_shape=(800, 928, 1) for args.model_type=<ModelType.input2d: 0> now let's see if the maximum number of voxels is ok...\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-85-887b344415fa>:<module>:053}::[2020-12-08::16:57:59.076]\n",
      "crop_shape=(800, 928, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_N_VOXELS = 6 * 8 * 4 * (96 ** 3)  # estimation from the number of voxels i know that can fit in the GPU from training unet3d.crop96\n",
    "MULTIPLE_REQUIREMENT = 16\n",
    "\n",
    "logger.info(f\"{MAX_N_VOXELS=} ({humanize.intcomma(MAX_N_VOXELS)})\")\n",
    "logger.info(f\"{MULTIPLE_REQUIREMENT=}\")\n",
    "\n",
    "if args.cropping_strategy == process.CroppingStrategy.maximum_size:\n",
    "    crop_dims_multiple_16 = process.get_largest_crop_multiple(\n",
    "        volume_shape, \n",
    "        multiple_of=MULTIPLE_REQUIREMENT\n",
    "    )\n",
    "\n",
    "elif args.cropping_strategy == process.CroppingStrategy.maximum_size_reduced_overlap:\n",
    "    # it's not necessarily the real minimum, just an easy way to get a big crop with less overlap\n",
    "    # get the largest multiple of the requirement above the dimension size / 2\n",
    "    # that will give a max overlap of 2 * MULTIPLE_REQUIREMENT - 1\n",
    "    # e.g. with MULTIPLE_REQUIREMENT = 16, the maximum overlap is 31\n",
    "    crop_dims_multiple_16 = tuple(\n",
    "        (1 + int((dim / 2) // MULTIPLE_REQUIREMENT)) * MULTIPLE_REQUIREMENT if dim % MULTIPLE_REQUIREMENT != 0 else\n",
    "        dim\n",
    "        for dim in volume_shape\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"the max overlap in each direction will be {tuple(int(2 * MULTIPLE_REQUIREMENT - s % MULTIPLE_REQUIREMENT) for s in volume_shape)}\")\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"{args.cropping_strategy=}\")\n",
    "\n",
    "logger.debug(f\"{crop_dims_multiple_16=} using {args.cropping_strategy=}\")\n",
    "\n",
    "# it has to be multiple of 16 because of the 4 cascaded 2x2-strided 2x2-downsamplings in u-net\n",
    "if args.model_type == process.ModelType.input2d:\n",
    "    crop_shape = (\n",
    "        crop_dims_multiple_16[0],\n",
    "        crop_dims_multiple_16[1],\n",
    "        1,\n",
    "    )\n",
    "\n",
    "elif args.model_type == process.ModelType.input2halfd:\n",
    "    raise NotImplemented()\n",
    "    \n",
    "elif args.model_type == process.ModelType.input3d:\n",
    "    crop_shape = crop_dims_multiple_16\n",
    "\n",
    "logger.debug(f\"ideal {crop_shape=} for {args.model_type=} now let's see if the maximum number of voxels is ok...\")\n",
    "\n",
    "crop_shape = process.reduce_dimensions(\n",
    "    crop_shape,\n",
    "    max_nvoxels=MAX_N_VOXELS,\n",
    "    multiple_of=MULTIPLE_REQUIREMENT,\n",
    ")\n",
    "    \n",
    "logger.info(f\"{crop_shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-87-9002bd14f40b>:<module>:006}::[2020-12-08::16:59:18.107]\n",
      "n_steps=(2, 2, 2002)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-87-9002bd14f40b>:<module>:028}::[2020-12-08::16:59:18.112]\n",
      "min(x0s)=0, max(x0s)=779, len(x0s)=2\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-87-9002bd14f40b>:<module>:029}::[2020-12-08::16:59:18.113]\n",
      "min(y0s)=0, max(y0s)=917, len(y0s)=2\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-87-9002bd14f40b>:<module>:030}::[2020-12-08::16:59:18.115]\n",
      "min(z0s)=0, max(z0s)=2001, len(z0s)=2002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_steps = tuple(\n",
    "    int(np.ceil(vol_dim / crop_dim))\n",
    "    for vol_dim, crop_dim in zip(volume_shape, crop_shape)\n",
    ")\n",
    "\n",
    "logger.debug(f\"{n_steps=}\")\n",
    "\n",
    "def get_coordinates_iterator(n_steps_):\n",
    "    assert len(n_steps_) == 3\n",
    "    return itertools.product(*(range(n_steps_[dim]) for dim in range(3)))\n",
    "\n",
    "get_ijk_iterator = functools.partial(\n",
    "    get_coordinates_iterator, copy.copy(n_steps)\n",
    ")\n",
    "\n",
    "get_kji_iterator = functools.partial(\n",
    "    get_coordinates_iterator, tuple(reversed(n_steps))\n",
    ")\n",
    "\n",
    "# coordinates (xs, ys, and zs) of the front upper left corners of the crops\n",
    "x0s, y0s, z0s = tuple(\n",
    "    tuple(map(\n",
    "        int, \n",
    "        np.linspace(0, vol_dim - crop_dim, n)\n",
    "    ))\n",
    "    for vol_dim, crop_dim, n in zip(volume_shape, crop_shape, n_steps)\n",
    ")\n",
    "logger.debug(f\"{min(x0s)=}, {max(x0s)=}, {len(x0s)=}\")\n",
    "logger.debug(f\"{min(y0s)=}, {max(y0s)=}, {len(y0s)=}\")\n",
    "logger.debug(f\"{min(z0s)=}, {max(z0s)=}, {len(z0s)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crops coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-90-81c28bea32a8>:<module>:001}::[2020-12-08::17:02:36.493]\n",
      "Generating the crop coordinates.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-90-81c28bea32a8>:<module>:015}::[2020-12-08::17:02:36.567]\n",
      "crops_coordinates.shape=(2, 2, 2002, 3, 2)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-90-81c28bea32a8>:<module>:020}::[2020-12-08::17:02:36.569]\n",
      "crops_coordinates_sequential.shape=(8008, 3, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"Generating the crop coordinates.\")\n",
    "\n",
    "crops_coordinates = np.array(\n",
    "    [\n",
    "        (\n",
    "            (x0, x0 + crop_shape[0]), \n",
    "            (y0, y0 + crop_shape[1]),\n",
    "            (z0, z0 + crop_shape[2]),\n",
    "        )\n",
    "        for x0, y0, z0 in itertools.product(x0s, y0s, z0s)\n",
    "    ], \n",
    "    dtype=tuple\n",
    ").reshape(len(x0s), len(y0s), len(z0s), 3, 2).astype(int)  # 3 = nb of dimenstions, 2 = (start, end)\n",
    "\n",
    "logger.debug(f\"{crops_coordinates.shape=}\")\n",
    "\n",
    "# 'F' reshapes with x varying fastest and z slowest\n",
    "crops_coordinates_sequential = crops_coordinates.reshape(-1, 3, 2, order='F')  \n",
    "\n",
    "logger.debug(f\"{crops_coordinates_sequential.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orthogonal slices plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-89-ae231ce72243>:<module>:011}::[2020-12-08::17:01:07.396]\n",
      "Saving figure (figname := display.title + '.png')='PA66GF30.biaxe.orthogonal-slices-display.x=789-y=922-z=1001.png'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(sz := 15, sz), dpi=120)\n",
    "    fig.set_tight_layout(True)\n",
    "    \n",
    "    display = viz.OrthogonalSlicesDisplay(\n",
    "        volume=data_volume,\n",
    "        volume_name=volume.fullname,\n",
    "    ).plot(axs=axs,)\n",
    "    \n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        dpi=200, format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:005}::[2020-12-08::17:11:38.336]\n",
      "Segmenting one crop for debug crop_ijk=(0, 0, 0)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:011}::[2020-12-08::17:11:38.338]\n",
      "crop_data.shape=(800, 928, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:019}::[2020-12-08::17:11:38.339]\n",
      "modelin_target_shape=(1, 800, 928, 1, 1)\n",
      "\n",
      "1/1 - 0s\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:031}::[2020-12-08::17:11:38.626]\n",
      "modelout.shape=(1, 800, 928, 3)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:035}::[2020-12-08::17:11:38.627]\n",
      "n_classes=3\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:040}::[2020-12-08::17:11:38.628]\n",
      "crop_probas_target_shape=[800, 928, 1, 3]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:044}::[2020-12-08::17:11:38.644]\n",
      "crop_probas.shape=(800, 928, 1, 3)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:045}::[2020-12-08::17:11:38.666]\n",
      "crop_probas.dtype=dtype('float16')\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:050}::[2020-12-08::17:11:38.685]\n",
      "crop_preds.shape=(800, 928, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-93-1c353b778d0a>:<module>:051}::[2020-12-08::17:11:38.686]\n",
      "crop_preds.dtype=dtype('int8')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crop_ijk = (0, 0, 0)\n",
    "i, j, k = crop_ijk\n",
    "crop_coords = crops_coordinates[i, j, k]\n",
    "\n",
    "logger.info(f\"Segmenting one crop for debug {crop_ijk=}\")\n",
    "\n",
    "slice3d = tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "crop_data = data_volume[slice3d]\n",
    "del slice3d\n",
    "    \n",
    "logger.debug(f\"{crop_data.shape=}\")\n",
    "\n",
    "# [model] - i call it with a first crop bc if something goes wrong then the error\n",
    "# will appear here instead of in a loop\n",
    "\n",
    "# modelin\n",
    "modelin_target_shape = (1, crop_shape[0], crop_shape[1], crop_shape[2], 1)\n",
    "\n",
    "logger.debug(f\"{modelin_target_shape=}\")\n",
    "\n",
    "modelin = crop_data.reshape(modelin_target_shape) \n",
    "\n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=1,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{modelout.shape=}\")\n",
    "\n",
    "n_classes = modelout.shape[-1]\n",
    "\n",
    "assert n_classes == len(volume.metadata.labels), f\"{n_classes=} {len(volume.metadata.labels)=}\"\n",
    "\n",
    "# probas\n",
    "crop_probas_target_shape = list(crop_shape) + [n_classes]\n",
    "\n",
    "logger.debug(f\"{crop_probas_target_shape=}\")\n",
    "\n",
    "crop_probas = modelout.reshape(crop_probas_target_shape).astype(args.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{crop_probas.shape=}\")\n",
    "logger.debug(f\"{crop_probas.dtype=}\")\n",
    "\n",
    "# preds\n",
    "crop_preds = crop_probas.argmax(axis=-1).astype(np.int8)\n",
    "\n",
    "logger.debug(f\"{crop_preds.shape=}\")\n",
    "logger.debug(f\"{crop_preds.dtype=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-95-ff0f199fac4c>:<module>:015}::[2020-12-08::17:13:05.176]\n",
      "Saving figure (figname := display.title + '.png')='PA66GF30.biaxe.debug.crop-crop_ijk=(0, 0, 0).orthogonal-slices-display.x=400-y=464-z=0.png'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=3, ncols=2,\n",
    "        figsize=(2 * (sz := 20), sz), \n",
    "        dpi=120,\n",
    "    )\n",
    "\n",
    "    display = viz.OrthogonalSlicesPredictionDisplay(\n",
    "        volume_data=crop_data,\n",
    "        volume_prediction=crop_preds,\n",
    "        n_classes=n_classes,\n",
    "        volume_name=volume.fullname + f\".debug.crop-{crop_ijk=}\",\n",
    "    ).plot(axs=axs,)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )       \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-96-63e5c06b8645>:<module>:001}::[2020-12-08::17:23:34.504]\n",
      "Segmenting a batch for debug.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Segmenting a batch for debug.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-103-3ec5bded21f3>:<module>:003}::[2020-12-08::17:29:10.268]\n",
      "batch_size=2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = n_gpus\n",
    "\n",
    "logger.debug(f\"{batch_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO::tomo2seg::{<ipython-input-102-6e906eab95a7>:<module>:004}::[2020-12-08::17:28:27.651]\n",
      "Loading model with MirroredStrategy.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:003}::[2020-12-08::17:28:27.652]\n",
      "Loading model from autosaved file: unet2d.vanilla03-f16.fold000.1606-505-109.autosaved.hdf5\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "DEBUG::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:010}::[2020-12-08::17:28:32.127]\n",
      "Changing the model's input type to accept any size of crop.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:016}::[2020-12-08::17:28:32.128]\n",
      "input_n_channels=(1,)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-101-7454cecbba19>:get_model:024}::[2020-12-08::17:28:32.130]\n",
      "anysize_input=<tf.Tensor 'input_any_image_size_2:0' shape=(None, None, None, None, 1) dtype=float32>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mirror = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirror.scope():\n",
    "    logger.info(f\"Loading model with {mirror.__class__.__name__}.\")\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-110-e239b59957c3>:<module>:003}::[2020-12-08::17:36:42.275]\n",
      "batch_coords.shape=(2, 3, 2)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-110-e239b59957c3>:<module>:010}::[2020-12-08::17:36:42.278]\n",
      "batch_slices=[(slice(0, 800, None), slice(0, 928, None), slice(0, 1, None)), (slice(779, 1579, None), slice(0, 928, None), slice(0, 1, None))]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-110-e239b59957c3>:<module>:017}::[2020-12-08::17:36:42.288]\n",
      "batch_data.shape=(2, 800, 928, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-110-e239b59957c3>:<module>:024}::[2020-12-08::17:36:42.289]\n",
      "modelin_target_shape=(2, 800, 928, 1, 1)\n",
      "\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 320, 320, 1) for input Tensor(\"input_2:0\", shape=(None, 320, 320, 1), dtype=float32), but it was called on an input with incompatible shape (1, 800, 928, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 320, 320, 1) for input Tensor(\"input_2:0\", shape=(None, 320, 320, 1), dtype=float32), but it was called on an input with incompatible shape (1, 800, 928, 1).\n",
      "1/1 - 0s\n",
      "DEBUG::tomo2seg::{<ipython-input-110-e239b59957c3>:<module>:036}::[2020-12-08::17:43:47.775]\n",
      "modelout.shape=(2, 800, 928, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_coords = crops_coordinates_sequential[:batch_size]\n",
    "\n",
    "logger.debug(f\"{batch_coords.shape=}\")\n",
    "\n",
    "batch_slices = [\n",
    "    tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "    for crop_coords in batch_coords\n",
    "]\n",
    "\n",
    "logger.debug(f\"{batch_slices=}\")\n",
    "\n",
    "batch_data = np.stack([\n",
    "    data_volume[slice_]\n",
    "    for slice_ in batch_slices\n",
    "], axis=0)\n",
    "\n",
    "logger.debug(f\"{batch_data.shape=}\")\n",
    "\n",
    "# [model] - now i call it with a first the mirror strategy to make sure it wont break\n",
    "\n",
    "# modelin\n",
    "modelin_target_shape = (batch_size, crop_shape[0], crop_shape[1], crop_shape[2], 1)  # adjust nb. channels\n",
    "\n",
    "logger.debug(f\"{modelin_target_shape=}\")\n",
    "\n",
    "modelin = batch_data.reshape(modelin_target_shape) \n",
    "\n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=batch_size,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{modelout.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-113-d17f03134596>:<module>:004}::[2020-12-08::17:48:34.574]\n",
      "batch_probas_target_shape=[2, 800, 928, 1, 3]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-113-d17f03134596>:<module>:008}::[2020-12-08::17:48:34.648]\n",
      "batch_probas.shape=(2, 800, 928, 1, 3)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-113-d17f03134596>:<module>:009}::[2020-12-08::17:48:34.650]\n",
      "batch_probas.dtype=dtype('float16')\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-113-d17f03134596>:<module>:014}::[2020-12-08::17:48:34.718]\n",
      "batch_preds.shape=(2, 800, 928, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-113-d17f03134596>:<module>:015}::[2020-12-08::17:48:34.719]\n",
      "batch_preds.dtype=dtype('int8')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# probas\n",
    "batch_probas_target_shape = [batch_size] + list(crop_shape) + [n_classes]\n",
    "\n",
    "logger.debug(f\"{batch_probas_target_shape=}\")\n",
    "\n",
    "batch_probas = modelout.reshape(batch_probas_target_shape).astype(args.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{batch_probas.shape=}\")\n",
    "logger.debug(f\"{batch_probas.dtype=}\")\n",
    "\n",
    "# preds\n",
    "batch_preds = batch_probas.argmax(axis=-1).astype(np.int8)\n",
    "\n",
    "logger.debug(f\"{batch_preds.shape=}\")\n",
    "logger.debug(f\"{batch_preds.dtype=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segment the largest `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_N_VOXELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-118-154069748d84>:<module>:003}::[2020-12-08::18:08:27.485]\n",
      "batch_size_increased=6\n",
      "\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 320, 320, 1) for input Tensor(\"input_2:0\", shape=(None, 320, 320, 1), dtype=float32), but it was called on an input with incompatible shape (3, 800, 928, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 320, 320, 1) for input Tensor(\"input_2:0\", shape=(None, 320, 320, 1), dtype=float32), but it was called on an input with incompatible shape (3, 800, 928, 1).\n"
     ]
    }
   ],
   "source": [
    "batch_size_increased = batch_size + 2 * n_gpus\n",
    "\n",
    "logger.debug(f\"{batch_size_increased=}\")\n",
    "\n",
    "batch_coords = crops_coordinates_sequential[:batch_size_increased]\n",
    "batch_slices = [\n",
    "    tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "    for crop_coords in batch_coords\n",
    "]\n",
    "batch_data = np.stack([data_volume[slice_] for slice_ in batch_slices], axis=0)\n",
    "# [model]\n",
    "# modelin\n",
    "modelin_target_shape = (batch_size_increased, crop_shape[0], crop_shape[1], crop_shape[2], 1)  # adjust nb. channels\n",
    "modelin = batch_data.reshape(modelin_target_shape) \n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=batch_size_increased,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_volume_target_shape = list(volume_shape) + [n_classes]\n",
    "\n",
    "logger.debug(f\"{proba_volume_target_shape=}\")\n",
    "\n",
    "proba_volume = np.zeros(proba_volume_target_shape, dtype=opts.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{proba_volume.shape=}\")\n",
    "\n",
    "redundancies_count_target_shape = volume_shape\n",
    "\n",
    "logger.debug(f\"{redundancies_count_target_shape=}\")\n",
    "\n",
    "redundancies_count = np.zeros(redundancies_count_target_shape, dtype=np.int8)  # only one channel\n",
    "\n",
    "logger.debug(f\"{redundancies_count.shape=}\")\n",
    "\n",
    "n_iterations = n_steps[0] * n_steps[1] * n_steps[2]\n",
    "\n",
    "logger.debug(f\"{n_iterations=}\")\n",
    "\n",
    "logger.debug(\"Predicting and summing up the crops' probabilities.\")\n",
    "for coord in pbar(crops_coordinates_sequential, prefix=\"predict-and-sum-probas\", max_value=n_iterations):\n",
    "    # [model]\n",
    "    slice3d = tuple(slice(*coords_) for coords_ in coord)\n",
    "    crop_data = data_volume[slice3d]\n",
    "    modelin = crop_data.reshape(modelin_target_shape)\n",
    "    modelout = model.predict(modelin, batch_size=1, steps=1)\n",
    "    proba_volume[slice3d] += modelout.astype(opts.probabilities_dtype).reshape(crop_probas_target_shape)\n",
    "    redundancies_count[slice3d] += np.ones(crop_shape, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del voldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the min and max probas are coherent with the min/max redundancy\n",
    "min_proba_sum = proba_volume.min(axis=0).min(axis=0).min(axis=0)\n",
    "max_proba_sum = proba_volume.max(axis=0).max(axis=0).max(axis=0)\n",
    "min_redundancy = np.min(redundancies_count)\n",
    "max_redundancy = np.max(redundancies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min_redundancy >= 1, f\"{min_redundancy=}\"\n",
    "assert np.all(min_proba_sum >= 0), f\"{min_proba_sum=}\"\n",
    "assert np.all(max_proba_sum <= max_redundancy), f\"{max_proba_sum=} {max_redundancy=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each probability channel by the number of times it was summed (avg proba)\n",
    "logger.debug(f\"Dividing probability redundancies.\")\n",
    "for klass_idx in pbar(range(n_classes), max_value=n_classes, prefix=\"redundancies-per-class\"):\n",
    "    proba_volume[:, :, :, klass_idx] = proba_volume[:, :, :, klass_idx] / redundancies_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del redundancies_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes it more stable so that the sum is 1\n",
    "proba_volume[:, :, :] /= proba_volume[:, :, :].sum(axis=-1, keepdims=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that proba distribs sum to 1\n",
    "min_proba = proba_volume.min(axis=0).min(axis=0).min(axis=0)\n",
    "max_proba = proba_volume.max(axis=0).max(axis=0).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(min_proba >= 0), f\"{min_proba=}\"\n",
    "assert np.all(max_proba <= 1), f\"{max_proba=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distrib_proba_sum = proba_volume.sum(axis=-1).min()\n",
    "max_distrib_proba_sum = proba_volume.sum(axis=-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(min_distrib_proba_sum, 1, atol=.001), f\"{min_distrib_proba_sum=}\"\n",
    "assert np.isclose(max_distrib_proba_sum, 1, atol=.001), f\"{max_distrib_proba_sum=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proba 2 pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_volume = np.empty(proba_volume.shape[:3], dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(proba_volume, axis=-1, out=pred_volume)\n",
    "\n",
    "logger.debug(f\"{pred_volume.shape=}\")\n",
    "logger.debug(f\"{pred_volume.min()=}\")\n",
    "logger.debug(f\"{pred_volume.max()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Writing probabilities on disk at `{estimation_volume.probabilities_path}`\")\n",
    "np.save(estimation_volume.probabilities_path, proba_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opts.save_probas_by_class:\n",
    "    for klass_idx in volume.metadata.labels:\n",
    "        logger.debug(f\"Writing probabilities of class `{klass_idx}` on disk at `{(str_path := str(estimation_volume.get_class_probability_path(klass_idx)))=}`\")\n",
    "        file_utils.HST_write(proba_volume[:, :, :, klass_idx], str_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Writing predictions on disk at `{(str_path := str(estimation_volume.predictions_path))}`\")\n",
    "file_utils.HST_write(pred_volume, str_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-z-slice-crops-locations.png\n",
    "\n",
    "not kept, search fro `one-z-slice-crops-locations.png` in `process-3d-crops-entire-2d-slice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debug__materialize_crops\n",
    "\n",
    "same for\n",
    "`debug__materialize_crops`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"process-volume-01.ipynb\"\n",
    "this_dir = os.getcwd()\n",
    "save_nb_dir = str(estimation_volume.dir)\n",
    "\n",
    "logger.warning(f\"{this_nb_name=}\")\n",
    "logger.warning(f\"{this_dir=}\")\n",
    "logger.warning(f\"{save_nb_dir=}\")\n",
    "\n",
    "command = f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {save_nb_dir} --to html\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

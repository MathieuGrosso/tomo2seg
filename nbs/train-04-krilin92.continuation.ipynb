{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import functools\n",
    "import operator\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks as keras_callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics as keras_metrics\n",
    "\n",
    "from tomo2seg import slack\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    MetaCrop3DGenerator, VolumeCropSequence,\n",
    "    UniformGridPosition, SequentialGridPosition,\n",
    "    ET3DUniformCuboidAlmostEverywhere, ET3DConstantEverywhere, \n",
    "    GTUniformEverywhere, GTConstantEverywhere, \n",
    "    VSConstantEverywhere, VSUniformEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg import callbacks as tomo2seg_callbacks\n",
    "from tomo2seg import losses as tomo2seg_losses\n",
    "from tomo2seg import schedule as tomo2seg_schedule\n",
    "from tomo2seg import utils as tomo2seg_utils\n",
    "from tomo2seg import slackme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this registers a custom exception handler for the whole current notebook\n",
    "get_ipython().set_custom_exc((Exception,), slackme.custom_exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-33-0741b9f149a3>:<module>:011}::[2020-12-11::10:57:38.353]\n",
      "MULTIPLE_REQUIREMENT=16\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-33-0741b9f149a3>:<module>:023}::[2020-12-11::10:57:38.354]\n",
      "MAX_INTERNAL_NVOXELS=133632000.0 (133,632,000.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "\n",
    "    class EarlyStopMode(Enum):\n",
    "        no_early_stop = 0\n",
    "    \n",
    "    early_stop_mode: EarlyStopMode\n",
    "    \n",
    "    \n",
    "MULTIPLE_REQUIREMENT = 16\n",
    "logger.info(f\"{MULTIPLE_REQUIREMENT=}\")\n",
    "\n",
    "# these are estimates based on things i've seen fit in the GPU\n",
    "MAX_INTERNAL_NVOXELS = max(\n",
    "    # seen cases\n",
    "    4 * (8 * 6) * (96**3),\n",
    "    8 * (16 * 6) * (320**2),  \n",
    "    3 * (16 * 6) * (800 * 928),\n",
    ")\n",
    "\n",
    "MAX_INTERNAL_NVOXELS *= 5/8  # a smaller gpu on other pcs...\n",
    "\n",
    "logger.info(f\"{MAX_INTERNAL_NVOXELS=} ({humanize.intcomma(MAX_INTERNAL_NVOXELS)})\")\n",
    "\n",
    "# override_batch_size = None\n",
    "# doing this to reproduce the same conditions...\n",
    "override_batch_size_per_gpu = 8\n",
    "\n",
    "is_continuation = True\n",
    "override_runid = 1607533765\n",
    "\n",
    "# None: continue from the latest model\n",
    "# 1: continue from model.autosaved_model_path\n",
    "# 2: continue from model.autosaved2_model_path\n",
    "continue_from_autosave: Optional[int] = None \n",
    "    \n",
    "\n",
    "args = Args(\n",
    "    early_stop_mode = Args.EarlyStopMode.no_early_stop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_continuation:\n",
    "    \n",
    "    try:\n",
    "        override_runid\n",
    "        \n",
    "    except NameError as ex:\n",
    "        raise ValueError(f\"{is_continuation=} but `{ex.args[0]}` is not defined!\")\n",
    "        \n",
    "else:\n",
    "    override_runid = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-10-9ddfb71dad49>:<module>:004}::[2020-12-11::10:54:12.651]\n",
      "runid=1607533765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time()) if override_runid is None else override_runid\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-11-3220786131f1>:<module>:003}::[2020-12-11::10:54:14.438]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-11-3220786131f1>:<module>:004}::[2020-12-11::10:54:14.439]\n",
      "Num GPUs Available: 1\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-11-3220786131f1>:<module>:005}::[2020-12-11::10:54:14.440]\n",
      "Should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-11-3220786131f1>:<module>:006}::[2020-12-11::10:54:14.558]\n",
      "Should return 2 devices...\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "n_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "    \n",
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {n_gpus}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\")\n",
    "logger.debug(f\"Should return 2 devices...\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-12-cd76321aa4c8>:<module>:010}::[2020-12-11::10:54:14.612]\n",
      "volume_name='PA66GF30'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-12-cd76321aa4c8>:<module>:011}::[2020-12-11::10:54:14.613]\n",
      "volume_version='v1'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-12-cd76321aa4c8>:<module>:012}::[2020-12-11::10:54:14.613]\n",
      "labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=}\")\n",
    "logger.info(f\"{volume_version=}\")\n",
    "logger.info(f\"{labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:258}::[2020-12-11::10:54:14.661]\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:195}::[2020-12-11::10:54:14.663]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:007}::[2020-12-11::10:54:14.668]\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [0, 1300], 'alias': 'train'}, 'val': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1600, 1900], 'alias': 'val'}, 'test': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1300, 1600], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:024}::[2020-12-11::10:54:14.669]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:028}::[2020-12-11::10:54:19.389]\n",
      "voldata.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:033}::[2020-12-11::10:54:19.390]\n",
      "voldata_train.shape=(1300, 1040, 1300)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:034}::[2020-12-11::10:54:19.390]\n",
      "voldata_val.shape=(1300, 1040, 300)\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:040}::[2020-12-11::10:54:20.964]\n",
      "vollabels.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:045}::[2020-12-11::10:54:20.965]\n",
      "vollabels_train.shape=(1300, 1040, 1300)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-13-6e0649e4ec97>:<module>:046}::[2020-12-11::10:54:20.966]\n",
      "vollabels_val.shape=(1300, 1040, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "n_classes = len(volume.metadata.labels)\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "\n",
    "logger.debug(f\"{voldata_train.shape=}\")\n",
    "logger.debug(f\"{voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "\n",
    "logger.debug(f\"{vollabels_train.shape=}\")\n",
    "logger.debug(f\"{vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already deleted (:\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "except NameError:\n",
    "    print(\"already deleted (:\")\n",
    "else:\n",
    "    del tomo2seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "# crop_shape = (256, 256, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "# bigger crops will have less border effects (?)\n",
    "crop_shape = (112, 112, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "model_master_name = \"unet2d\"\n",
    "model_version = \"crop112-f16\"\n",
    "model_factory_function = modular_unet.u_net\n",
    ".is_2halfd\n",
    "model_factory_kwargs = {\n",
    "    **modular_unet.kwargs_vanilla03,\n",
    "    **dict(\n",
    "        convlayer=modular_unet.ConvLayer.conv2d,\n",
    "        input_shape = crop_shape,\n",
    "        output_channels=n_classes,\n",
    "#         nb_filters_0 = 2,\n",
    "#         nb_filters_0 = 4,\n",
    "#         nb_filters_0 = 8,\n",
    "#         nb_filters_0 = 12,\n",
    "        nb_filters_0 = 16,\n",
    "#         nb_filters_0 = 32,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-16-fb6e611ab639>:<module>:005}::[2020-12-11::10:54:21.106]\n",
      "Creating a Tomo2SegModel.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-16-fb6e611ab639>:<module>:019}::[2020-12-11::10:54:21.107]\n",
      "tomo2seg_model=Model(master_name='unet2d', version='crop112-f16', fold=0, runid=1607533765, factory_function='tomo2seg.modular_unet.u_net', factory_kwargs={'depth': 4, 'sigma_noise': 0, 'updown_conv_sampling': True, 'unet_block_kwargs': {'kernel_size': 3, 'res': True, 'batch_norm': True, 'dropout': 0}, 'unet_down_kwargs': {'batchnorm': True}, 'unet_up_kwargs': {'batchnorm': True}, 'convlayer': <ConvLayer.conv2d: 0>, 'input_shape': (112, 112, 1), 'output_channels': 3, 'nb_filters_0': 16})\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-16-fb6e611ab639>:<module>:020}::[2020-12-11::10:54:21.108]\n",
      "tomo2seg_model.name='unet2d.crop112-f16.fold000.1607-533-765'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tomo2seg_model\n",
    "    \n",
    "except NameError:\n",
    "    logger.info(\"Creating a Tomo2SegModel.\")\n",
    "    \n",
    "    tomo2seg_model = Tomo2SegModel(\n",
    "        model_master_name, \n",
    "        model_version, \n",
    "        runid=runid,\n",
    "        factory_function=model_factory_function,\n",
    "        factory_kwargs=model_factory_kwargs,\n",
    "    )\n",
    "                \n",
    "else:\n",
    "    logger.warning(\"The model is already defined. To create a new one: `del tomo2seg_model`\")\n",
    "\n",
    "finally:\n",
    "    logger.info(f\"{tomo2seg_model=}\")\n",
    "    logger.info(f\"{tomo2seg_model.name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unet2d.crop112-f16.fold000.1607-533-765.autosaved.hdf5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomo2seg_model.autosaved_model_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:001}::[2020-12-11::10:54:21.216]\n",
      "Creating the Keras model.\n",
      "\n",
      "WARNING::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:006}::[2020-12-11::10:54:21.218]\n",
      "Training continuation: a model will be loaded.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:009}::[2020-12-11::10:54:21.218]\n",
      "Using the LATEST model to continue the training.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:040}::[2020-12-11::10:54:21.219]\n",
      "Loading model unet2d.crop112-f16.fold000.1607-533-765\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:055}::[2020-12-11::10:54:28.320]\n",
      "Compiling the model.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:069}::[2020-12-11::10:54:28.321]\n",
      "loss=<function jaccard2_flat at 0x7ff591f36310>\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:070}::[2020-12-11::10:54:28.322]\n",
      "optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7ff4d4485f70>\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-18-ec7ef17ce733>:<module>:071}::[2020-12-11::10:54:28.323]\n",
      "metrics=[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Creating the Keras model.\")\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    if is_continuation:\n",
    "        logger.warning(\"Training continuation: a model will be loaded.\")\n",
    "\n",
    "        if continue_from_autosave is None:\n",
    "            logger.info(\"Using the LATEST model to continue the training.\")\n",
    "            load_model_path = tomo2seg_model.model_path\n",
    "        \n",
    "        elif continue_from_autosave == 1:\n",
    "            logger.info(\"Using the AUTOSAVED model to continue the training.\")\n",
    "            load_model_path = tomo2seg_model.autosaved_model_path\n",
    "        \n",
    "        elif continue_from_autosave == 2:\n",
    "            logger.info(\"Using the (best) AUTOSAVED2 model to continue the training.\")\n",
    "            load_model_path = tomo2seg_model.autosaved2_best_model_path\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"{continue_from_autosave=}\")\n",
    "        \n",
    "    elif (\n",
    "        tomo2seg_model.model_path.exists() or\n",
    "        tomo2seg_model.autosaved_model_path.exists()\n",
    "        # todo uncomment me when implemented\n",
    "#             or tomo2seg_model.autosaved2_best_model_path.exists()\n",
    "    ):\n",
    "        logger.error(f\"The model seems to already exist but this is not a continuation. Please, make sure the arguments are correct.\")\n",
    "        raise ValueError(f\"{is_continuation=} {tomo2seg_model.name=}\")\n",
    "    \n",
    "    else:\n",
    "        logger.info(f\"A new model will be instantiated!\")\n",
    "        \n",
    "        \n",
    "    if is_continuation:\n",
    "        \n",
    "        assert load_model_path.exists(), f\"Inconsistent arguments {is_continuation=} {load_model_path=}.\"\n",
    "        \n",
    "        logger.info(f\"Loading model {load_model_path.name}\")\n",
    "        \n",
    "        model = keras.models.load_model(str(load_model_path), compile=False)\n",
    "\n",
    "        assert model.name == tomo2seg_model.name, f\"{model.name=} {tomo2seg_model.name=}\"\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        logger.info(f\"Instantiating a new model with model_factory_function={model_factory_function.__name__}.\")\n",
    "      \n",
    "        model = model_factory_function(\n",
    "            name=tomo2seg_model.name,\n",
    "            **model_factory_kwargs\n",
    "        )\n",
    "\n",
    "    logger.info(\"Compiling the model.\")\n",
    "\n",
    "    # using the avg jaccard is dangerous if one of the classes is too\n",
    "    # underrepresented because it's jaccard will be unstable\n",
    "    loss = tomo2seg_losses.jaccard2_flat\n",
    "    optimizer = optimizers.Adam(lr=.003)\n",
    "    metrics = [\n",
    "#         tomo2seg_losses.jaccard2_macro_avg,\n",
    "#         keras_metrics.Accuracy(),\n",
    "#     ] + [\n",
    "#         tomo2seg_losses.Jaccard2(class_idx)\n",
    "#         for class_idx in range(n_classes)\n",
    "    ]\n",
    "    \n",
    "    logger.debug(f\"{loss=}\")\n",
    "    logger.debug(f\"{optimizer=}\")\n",
    "    logger.debug(f\"{metrics=}\")\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "if not is_continuation:\n",
    "    \n",
    "    logger.info(f\"Saving the model at {tomo2seg_model.model_path=}.\")\n",
    "    \n",
    "    model.save(tomo2seg_model.model_path)\n",
    "\n",
    "    logger.info(f\"Writing the model summary at {tomo2seg_model.summary_path=}.\")\n",
    "    \n",
    "    with tomo2seg_model.summary_path.open(\"w\") as f:\n",
    "        def print_to_txt(line):\n",
    "            f.writelines([line + \"\\n\"])\n",
    "        model.summary(print_fn=print_to_txt, line_length=140)\n",
    "\n",
    "    logger.info(f\"Printing an image of the architecture at {tomo2seg_model.architecture_plot_path=}.\")\n",
    "    \n",
    "    utils.plot_model(model, show_shapes=True, to_file=tomo2seg_model.architecture_plot_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "# Data crop sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{utils.py:get_model_internal_nvoxel_factor:023}::[2020-12-11::10:54:29.337]\n",
      "input_layer=<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7ff4d446fd00>\n",
      "\n",
      "DEBUG::tomo2seg::{utils.py:get_model_internal_nvoxel_factor:029}::[2020-12-11::10:54:29.338]\n",
      "input_nvoxels=12544\n",
      "\n",
      "DEBUG::tomo2seg::{utils.py:get_model_internal_nvoxel_factor:041}::[2020-12-11::10:54:29.340]\n",
      "max_internal_nvoxels=1204224 (1,204,224)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:003}::[2020-12-11::10:54:29.341]\n",
      "model_internal_nvoxel_factor=96\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:007}::[2020-12-11::10:54:29.342]\n",
      "max_batch_nvoxels=1392000 (1,392,000)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:011}::[2020-12-11::10:54:29.342]\n",
      "crop_shape=(112, 112, 1) ==> crop_nvoxels=12544\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:015}::[2020-12-11::10:54:29.343]\n",
      "batch_size_per_gpu=110\n",
      "\n",
      "WARNING::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:023}::[2020-12-11::10:54:29.344]\n",
      "override_batch_size_per_gpu=8 given ==> replacing batch_size_per_gpu=8\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:025}::[2020-12-11::10:54:29.344]\n",
      "n_gpus=1\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-20-46fe188ba465>:<module>:029}::[2020-12-11::10:54:29.345]\n",
      "batch_size=8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_internal_nvoxel_factor = tomo2seg_utils.get_model_internal_nvoxel_factor(model)\n",
    "\n",
    "logger.debug(f\"{model_internal_nvoxel_factor=}\")\n",
    "\n",
    "max_batch_nvoxels = int(np.floor(MAX_INTERNAL_NVOXELS / model_internal_nvoxel_factor))\n",
    "\n",
    "logger.debug(f\"{max_batch_nvoxels=} ({humanize.intcomma(max_batch_nvoxels)})\")\n",
    "\n",
    "crop_nvoxels = functools.reduce(operator.mul, crop_shape)\n",
    "\n",
    "logger.debug(f\"{crop_shape=} ==> {crop_nvoxels=}\")\n",
    "\n",
    "max_batch_size_per_gpu = batch_size_per_gpu = int(np.floor(max_batch_nvoxels / crop_nvoxels))\n",
    "\n",
    "logger.info(f\"{batch_size_per_gpu=}\")\n",
    "\n",
    "if override_batch_size_per_gpu is not None:\n",
    "    \n",
    "    assert override_batch_size_per_gpu > 0, f\"{override_batch_size_per_gpu=}\"\n",
    "    \n",
    "    batch_size_per_gpu = override_batch_size_per_gpu\n",
    "    \n",
    "    logger.warning(f\"{override_batch_size_per_gpu=} given ==> replacing {batch_size_per_gpu=}\")\n",
    "\n",
    "logger.info(f\"{n_gpus=}\")\n",
    "\n",
    "batch_size = batch_size_per_gpu * max(1, n_gpus)\n",
    "\n",
    "logger.info(f\"{batch_size=}\")\n",
    "\n",
    "common_random_state = 143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-21-08839047e361>:<module>:008}::[2020-12-11::10:54:29.408]\n",
      "metacrop_gen_common_kwargs={'crop_shape': (112, 112, 1), 'common_random_state_seed': 143, 'is_2halfd': False, 'gt_type': <enum 'GT2D'>}\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-21-08839047e361>:<module>:019}::[2020-12-11::10:54:29.409]\n",
      "vol_crop_seq_common_kwargs={'output_as_2d': True, 'output_as_2halfd': False, 'labels': [0, 1, 2], 'debug__no_data_check': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metacrop_gen_common_kwargs = dict(\n",
    "    crop_shape=crop_shape,\n",
    "    common_random_state_seed=common_random_state,\n",
    "    is_2halfd=model_is_2halfd,\n",
    "    gt_type=volume_sequence.GT2D if model_is_2d else volume_sequence.GT3D,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{metacrop_gen_common_kwargs=}\")\n",
    "\n",
    "vol_crop_seq_common_kwargs = dict(\n",
    "    output_as_2d=model_is_2d,\n",
    "    output_as_2halfd=model_is_2halfd,\n",
    "    labels = volume.metadata.labels,\n",
    "\n",
    "    # not automated...\n",
    "    debug__no_data_check=True,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{vol_crop_seq_common_kwargs=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:438}::[2020-12-11::10:54:29.463]\n",
      "Built UniformGridPosition from volume_shape=(1300, 1040, 1300) and crop_shape=(112, 112, 1) ==> {'x_range': (0, 1189), 'y_range': (0, 929), 'z_range': (0, 1300)}\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:400}::[2020-12-11::10:54:29.464]\n",
      "UniformGridPosition ==> npositions=1435955300 (1,435,955,300)\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-11::10:54:29.465]\n",
      "Initializing ET3DConstantEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-11::10:54:29.465]\n",
      "Initializing GTUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-11::10:54:29.466]\n",
      "Initializing VSUniformEverywhere with a UniformGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:1353}::[2020-12-11::10:54:29.467]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:1385}::[2020-12-11::10:54:29.467]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = voldata_train\n",
    "labels = vollabels_train\n",
    "\n",
    "volume_shape = data.shape\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    \n",
    "    batch_size=batch_size,\n",
    "    \n",
    "    meta_crop_generator=MetaCrop3DGenerator.build_setup_train00(\n",
    "        volume_shape=volume_shape,\n",
    "        **metacrop_gen_common_kwargs\n",
    "    ),\n",
    "    \n",
    "    # this volume cropper only returns random crops, \n",
    "    # so the number of crops per epoch/batch is w/e i want\n",
    "    epoch_size=10,\n",
    "    \n",
    "    **vol_crop_seq_common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-23-b438c21e5a8d>:<module>:010}::[2020-12-11::10:54:29.515]\n",
      "val_batch_size=110\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:build_min_overlap:506}::[2020-12-11::10:54:29.515]\n",
      "Building SequentialGridPosition with minimal overlap (smallest n_steps in each directions) n_steps={'n_steps_x': 12, 'n_steps_y': 10, 'n_steps_z': 300}.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:build_min_overlap:509}::[2020-12-11::10:54:29.516]\n",
      "n_steps_kwargs={'n_steps_x': 11, 'n_steps_y': 11, 'n_steps_z': 11} was given --> effective n_steps={'n_steps_x': 11, 'n_steps_y': 11, 'n_steps_z': 11}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:build_from_volume_crop_shapes:438}::[2020-12-11::10:54:29.517]\n",
      "Built SequentialGridPosition from volume_shape=(1300, 1040, 300) and crop_shape=(112, 112, 1) ==> {'x_range': (0, 1189), 'y_range': (0, 929), 'z_range': (0, 300)}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:__post_init__:486}::[2020-12-11::10:54:29.523]\n",
      "The SequentialGridPosition has len(self.positions)=1331 different positions (therefore crops).\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-11::10:54:29.525]\n",
      "Initializing ET3DConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-11::10:54:29.526]\n",
      "Initializing GTConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:695}::[2020-12-11::10:54:29.526]\n",
      "Initializing VSConstantEverywhere with a SequentialGridPosition.\n",
      "The {x, y, z}_range values will be overwritten.\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:1353}::[2020-12-11::10:54:29.527]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:1385}::[2020-12-11::10:54:29.528]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = voldata_val\n",
    "labels = vollabels_val\n",
    "\n",
    "volume_shape = data.shape\n",
    "\n",
    "# the validation has no reproducibility issues\n",
    "# so let's push the GPUs (:\n",
    "val_batch_size = max_batch_size_per_gpu * n_gpus\n",
    "\n",
    "logger.debug(f\"{val_batch_size=}\")\n",
    "\n",
    "grid_pos_gen = SequentialGridPosition.build_min_overlap(\n",
    "    volume_shape=volume_shape, \n",
    "    crop_shape=crop_shape,\n",
    "    # reduce the total number of crops\n",
    "        n_steps_x=11,\n",
    "        n_steps_y=11,\n",
    "        n_steps_z=11,\n",
    ")\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    data_volume=data,\n",
    "    labels_volume=labels,\n",
    "    \n",
    "    batch_size=val_batch_size,\n",
    "    \n",
    "    # go through all the crops in validation\n",
    "    epoch_size=len(grid_pos_gen),      \n",
    "    \n",
    "    # data augmentation\n",
    "    meta_crop_generator=MetaCrop3DGenerator.build_setup_val00(\n",
    "        volume_shape=volume_shape,\n",
    "        grid_pos_gen=grid_pos_gen,\n",
    "        **metacrop_gen_common_kwargs,\n",
    "    ),\n",
    "    \n",
    "    **vol_crop_seq_common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-24-be8d862a0547>:<module>:009}::[2020-12-11::10:54:29.577]\n",
      "autosave_cb=<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff58009c8e0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autosave_cb = keras_callbacks.ModelCheckpoint(\n",
    "    tomo2seg_model.autosaved2_model_path_str, \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "logger.debug(f\"{autosave_cb=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-25-e64fcd7ac3fc>:<module>:007}::[2020-12-11::10:54:29.637]\n",
      "Creating a new history callback.\n",
      "\n",
      "INFO::tomo2seg::{callbacks.py:__init__:051}::[2020-12-11::10:54:29.644]\n",
      "Loading history from csv self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv').\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e64fcd7ac3fc>:<module>:040}::[2020-12-11::10:54:29.653]\n",
      "history_cb=<tomo2seg.callbacks.History object at 0x7ff591cb1fd0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is important because sometimes i update things in the notebook\n",
    "# so i need to make sure that the objects in the history cb are updated\n",
    "try:\n",
    "    history_cb\n",
    "    \n",
    "except NameError:\n",
    "    logger.info(\"Creating a new history callback.\")\n",
    "    \n",
    "    history_cb = tomo2seg_callbacks.History(\n",
    "        optimizer=model.optimizer,\n",
    "        crop_seq_train=crop_seq_train,\n",
    "        crop_seq_val=crop_seq_val,\n",
    "        backup=1,\n",
    "        csv_path=tomo2seg_model.history_path,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    logger.warning(\"The history callback already exists!\")\n",
    "    \n",
    "    history_df = history_cb.dataframe\n",
    "\n",
    "    try:\n",
    "        history_df_temp = pd.read_csv(tomo2seg_model.history_path)\n",
    "        # keep the longest one\n",
    "        history_df = history_df if history_df.shape[0] >= history_df_temp.shape[0] else history_df_temp\n",
    "        del history_df_temp\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        logger.info(\"History hasn't been saved yet.\")\n",
    "        \n",
    "finally:\n",
    "    # make sure the correct objects are linked \n",
    "    history_cb.optimizer = model.optimizer\n",
    "    history_cb.crop_seq_train = crop_seq_train\n",
    "    history_cb.crop_seq_val = crop_seq_val\n",
    "\n",
    "logger.debug(f\"{history_cb=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-26-81847b52d74e>:<module>:001}::[2020-12-11::10:54:29.701]\n",
      "history_cb.dataframe.index.size=122\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-26-81847b52d74e>:<module>:002}::[2020-12-11::10:54:29.701]\n",
      "history_cb.last_epoch=121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{history_cb.dataframe.index.size=}\")\n",
    "logger.debug(f\"{history_cb.last_epoch=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-27-6edf00a82883>:<module>:005}::[2020-12-11::10:54:29.773]\n",
      "history_plot_cb=HistoryPlot(history_callback=<tomo2seg.callbacks.History object at 0x7ff591cb1fd0>, save_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/train-hist-plot-wip.png'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_plot_cb = tomo2seg_callbacks.HistoryPlot(\n",
    "    history_callback=history_cb,\n",
    "    save_path=tomo2seg_model.train_history_plot_wip_path\n",
    ")\n",
    "logger.debug(f\"{history_plot_cb=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-39-1b2efaf987e7>:<module>:001}::[2020-12-11::11:00:36.562]\n",
      "Setting up early stop with args.early_stop_mode=<EarlyStopMode.no_early_stop: 0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Setting up early stop with {args.early_stop_mode=}\")\n",
    "\n",
    "if args.early_stop_mode == Args.EarlyStopMode.no_early_stop:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f\"{args.early_stop_mode=}\")\n",
    "#     # todo modify the early stopping to take more conditions (don't stop too early before it doesnt break the jaccard2=.32)\n",
    "#     early_stop_cb = keras_callbacks.EarlyStopping(  \n",
    "#         monitor='val_loss', \n",
    "#         min_delta=.1 / 100, \n",
    "#         patience=50,\n",
    "#         verbose=2, \n",
    "#         mode='auto',\n",
    "#         baseline=.71,  # 0th-order classifier\n",
    "#         restore_best_weights=False,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training\n",
    "\n",
    "stuff that i use after the training but i want it to appear in the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mode## Metadata\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Volume slices\n",
    "\n",
    "todo do this in a notebook\n",
    "\n",
    "## Generator samples\n",
    "\n",
    "todo do this in a notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teeth log lr schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.063]\n",
      "LogSpaceSchedule ==> self.n=10\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.065]\n",
      "LogSpaceSchedule ==> self.n=30\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.066]\n",
      "LogSpaceSchedule ==> self.n=20\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.068]\n",
      "LogSpaceSchedule ==> self.n=40\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.069]\n",
      "LogSpaceSchedule ==> self.n=20\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.070]\n",
      "LogSpaceSchedule ==> self.n=40\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:071}::[2020-12-11::10:58:58.071]\n",
      "LogSpaceSchedule ==> self.n=100\n",
      "\n",
      "INFO::tomo2seg::{schedule.py:__post_init__:107}::[2020-12-11::10:58:58.072]\n",
      "ComposedSchedule ==> self.n=260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_schedule_cb = keras_callbacks.LearningRateScheduler(\n",
    "    schedule=(schedule := tomo2seg_schedule.get_schedule00()),\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-37-3ad408f65725>:<module>:001}::[2020-12-11::10:59:07.550]\n",
      "lr_schedule_cb.schedule.range=(0, 260)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"{lr_schedule_cb.schedule.range=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-40-c16af9d5fdc3>:<module>:019}::[2020-12-11::11:01:16.310]\n",
      "using callback TerminateOnNaN\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-40-c16af9d5fdc3>:<module>:019}::[2020-12-11::11:01:16.311]\n",
      "using callback ModelCheckpoint\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-40-c16af9d5fdc3>:<module>:019}::[2020-12-11::11:01:16.311]\n",
      "using callback History\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-40-c16af9d5fdc3>:<module>:019}::[2020-12-11::11:01:16.312]\n",
      "using callback HistoryPlot\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-40-c16af9d5fdc3>:<module>:019}::[2020-12-11::11:01:16.312]\n",
      "using callback LearningRateScheduler\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras_callbacks.TerminateOnNaN(),\n",
    "    autosave_cb,\n",
    "    history_cb,\n",
    "    history_plot_cb,\n",
    "    lr_schedule_cb,\n",
    "]\n",
    "\n",
    "try:\n",
    "    early_stop_cb\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    callbacks.append(early_stop_cb)\n",
    "\n",
    "for cb in callbacks:\n",
    "    logger.debug(f\"using callback {cb.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 123/400\n",
      "\n",
      "Epoch 00123: val_loss improved from inf to 0.02434, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/unet2d.crop112-f16.fold000.1607-533-765.autosaved.123-0.0243.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::11:16:57.934]\n",
      "Saving backup of the training history epoch=122 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::11:16:58.117]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:16:58.140]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:16:58.142]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 666s - loss: 0.0182 - val_loss: 0.0243 - lr: 0.0010\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 124/400\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::11:27:40.684]\n",
      "Saving backup of the training history epoch=123 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::11:27:40.742]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:27:40.763]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:27:40.767]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 642s - loss: 0.0174 - val_loss: 0.4863 - lr: 0.0010\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 125/400\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::11:38:23.015]\n",
      "Saving backup of the training history epoch=124 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::11:38:23.073]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:38:23.097]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:38:23.099]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 642s - loss: 0.0167 - val_loss: 0.4194 - lr: 0.0010\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 126/400\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::11:49:05.546]\n",
      "Saving backup of the training history epoch=125 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::11:49:05.656]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:49:05.678]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:49:05.680]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 642s - loss: 0.0191 - val_loss: 0.3029 - lr: 0.0010\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 127/400\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::11:59:48.349]\n",
      "Saving backup of the training history epoch=126 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::11:59:48.470]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:59:48.491]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::11:59:48.493]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0182 - val_loss: 0.0521 - lr: 0.0010\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 128/400\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::12:10:32.240]\n",
      "Saving backup of the training history epoch=127 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::12:10:32.311]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:10:32.333]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:10:32.335]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 644s - loss: 0.0166 - val_loss: 0.0324 - lr: 0.0010\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 129/400\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::12:21:14.270]\n",
      "Saving backup of the training history epoch=128 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::12:21:14.337]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:21:14.358]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:21:14.360]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 642s - loss: 0.0162 - val_loss: 0.0339 - lr: 0.0010\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 130/400\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02434\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::12:31:56.342]\n",
      "Saving backup of the training history epoch=129 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::12:31:56.408]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:31:56.429]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:31:56.431]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 642s - loss: 0.0154 - val_loss: 0.0278 - lr: 0.0010\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 131/400\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02434 to 0.02307, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/unet2d.crop112-f16.fold000.1607-533-765.autosaved.131-0.0231.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::12:42:40.392]\n",
      "Saving backup of the training history epoch=130 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::12:42:40.459]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:42:40.480]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:42:40.482]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 644s - loss: 0.0168 - val_loss: 0.0231 - lr: 0.0010\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 132/400\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02307 to 0.02046, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/unet2d.crop112-f16.fold000.1607-533-765.autosaved.132-0.0205.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::12:53:23.948]\n",
      "Saving backup of the training history epoch=131 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::12:53:24.021]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:53:24.042]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::12:53:24.045]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0160 - val_loss: 0.0205 - lr: 0.0010\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 133/400\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.02046 to 0.01835, saving model to /home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/unet2d.crop112-f16.fold000.1607-533-765.autosaved.133-0.0183.hdf5\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::13:04:07.530]\n",
      "Saving backup of the training history epoch=132 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::13:04:07.609]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:04:07.630]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:04:07.632]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 644s - loss: 0.0148 - val_loss: 0.0183 - lr: 0.0010\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 134/400\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01835\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::13:14:50.588]\n",
      "Saving backup of the training history epoch=133 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::13:14:50.663]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:14:50.685]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:14:50.687]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0168 - val_loss: 0.0224 - lr: 0.0010\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 135/400\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01835\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::13:25:33.286]\n",
      "Saving backup of the training history epoch=134 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::13:25:33.367]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:25:33.388]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:25:33.392]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0169 - val_loss: 0.0298 - lr: 0.0010\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 136/400\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01835\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::13:36:16.155]\n",
      "Saving backup of the training history epoch=135 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::13:36:16.218]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:36:16.240]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:36:16.242]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0166 - val_loss: 0.0271 - lr: 0.0010\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 137/400\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01835\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::13:46:58.995]\n",
      "Saving backup of the training history epoch=136 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::13:46:59.068]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:46:59.090]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:46:59.092]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0167 - val_loss: 0.0220 - lr: 0.0010\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 138/400\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01835\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::13:57:41.541]\n",
      "Saving backup of the training history epoch=137 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::13:57:41.672]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:57:41.693]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::13:57:41.695]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 643s - loss: 0.0156 - val_loss: 0.0237 - lr: 0.0010\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 139/400\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01835\n",
      "INFO::tomo2seg::{callbacks.py:on_epoch_end:110}::[2020-12-11::14:08:24.123]\n",
      "Saving backup of the training history epoch=138 self.csv_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/models/unet2d/unet2d.crop112-f16.fold000.1607-533-765/history.csv')\n",
      "\n",
      "DEBUG::tomo2seg::{viz.py:plot:297}::[2020-12-11::14:08:24.197]\n",
      "TrainingHistoryDisplay.plot plotting loss\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::14:08:24.218]\n",
      "train: argmin=103 --> min=0.0139\n",
      "\n",
      "INFO::tomo2seg::{viz.py:mark_min_values:392}::[2020-12-11::14:08:24.220]\n",
      "val: argmin=101 --> min=0.0171\n",
      "\n",
      "10/10 - 642s - loss: 0.0159 - val_loss: 0.0218 - lr: 0.0010\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 140/400\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 400\n",
    "\n",
    "model.fit(\n",
    "    # data sequences\n",
    "    x=crop_seq_train,\n",
    "    validation_data=crop_seq_val,\n",
    "\n",
    "    # epochs\n",
    "#         initial_epoch=0,\n",
    "    epochs=n_epochs,\n",
    "    initial_epoch=history_cb.last_epoch + 1,  # for some reason it is 0-starting and others 1-starting...\n",
    "#         epochs=history_cb.last_epoch + 1 + n_epochs,  \n",
    "\n",
    "    # others\n",
    "    callbacks=callbacks,  \n",
    "    verbose=2,\n",
    "\n",
    "    # todo change the volume sequence to dinamically load the volume\n",
    "    # because it would allow me to pass just a path string therefore\n",
    "    # making it serializible ==> i will be able to multithread (:\n",
    "    use_multiprocessing=False,   \n",
    ");\n",
    "\n",
    "slack.notify_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows := 2, ncols := 1, figsize=(2.5 * (sz := 5), nrows * sz), dpi=100)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "hist_display = viz.TrainingHistoryDisplay(\n",
    "    history_cb.history, \n",
    "    model_name=tomo2seg_model.name,\n",
    "    loss_name=model.loss.__name__,\n",
    "    x_axis_mode=(\n",
    "        \"epoch\", \"batch\", \"crop\", \"voxel\", \"time\",\n",
    "    ),\n",
    ").plot(\n",
    "    axs, \n",
    "    with_lr=True,\n",
    "    metrics=(\n",
    "        \"loss\", \n",
    "    ),\n",
    ")\n",
    "\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[-1].set_yscale(\"log\")\n",
    "\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"loss\"][0])\n",
    "viz.mark_min_values(hist_display.axs_metrics_[0], hist_display.plots_[\"val_loss\"][0], txt_kwargs=dict(rotation=0))\n",
    "\n",
    "hist_display.fig_.savefig(\n",
    "    tomo2seg_model.model_path / (hist_display.title + \".png\"),\n",
    "    format='png',\n",
    ")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "outputs": [],
   "source": [
    "history_cb.dataframe.to_csv(history_cb.csv_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [],
   "source": [
    "model.save(tomo2seg_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"train-04-krilin92.continuation.ipynb\"\n",
    "import os\n",
    "this_dir = os.getcwd()\n",
    "logger.warning(f\"{this_nb_name=} {this_dir=}\")\n",
    "\n",
    "os.system(f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {str(tomo2seg_model.model_path)} --to html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

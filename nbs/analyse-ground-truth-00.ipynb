{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import functools\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import socket\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import PrettyPrinter, pprint\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import humanize\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from matplotlib import cm, patches, pyplot as plt\n",
    "from numpy import ndarray\n",
    "from numpy.random import RandomState\n",
    "from progressbar import progressbar as pbar\n",
    "from pymicro.file import file_utils\n",
    "from sklearn import metrics, metrics as met, model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import (\n",
    "    callbacks as keras_callbacks,\n",
    "    layers,\n",
    "    losses,\n",
    "    metrics as keras_metrics,\n",
    "    optimizers,\n",
    "    utils,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from yaml import YAMLObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from tomo2seg import (\n",
    "    callbacks as tomo2seg_callbacks,\n",
    "    data as tomo2seg_data,\n",
    "    losses as tomo2seg_losses,\n",
    "    schedule as tomo2seg_schedule,\n",
    "    slack,\n",
    "    slackme,\n",
    "    utils as tomo2seg_utils,\n",
    "    viz as tomo2seg_viz,\n",
    "    volume_sequence,\n",
    ")\n",
    "from tomo2seg.data import EstimationVolume, Volume\n",
    "from tomo2seg.logger import add_file_handler, dict2str, logger\n",
    "from tomo2seg.model import Model as Tomo2SegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this registers a custom exception handler for the whole current notebook\n",
    "get_ipython().set_custom_exc((Exception,), slackme.custom_exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "manual-input"
    ]
   },
   "outputs": [],
   "source": [
    "# [manual-input]\n",
    "from tomo2seg.datasets import (\n",
    "#     VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION,\n",
    "    VOLUME_FRACTURE00_SEGMENTED00 as VOLUME_NAME_VERSION,\n",
    "    VOLUME_FRACTURE00_SEGMENTED00_LABELS_REFINED3 as LABELS_VERSION,\n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "random_state_seed = 42\n",
    "runid = int(time.time())\n",
    "# runid = 1607944057\n",
    "\n",
    "# None == all\n",
    "partitions_to_compute_aliases = None\n",
    "\n",
    "logger.info(f\"{volume_name=}\")\n",
    "logger.info(f\"{volume_version=}\")\n",
    "logger.info(f\"{labels_version=}\")\n",
    "logger.info(f\"{partitions_to_compute_aliases=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "random_state = np.random.RandomState(random_state_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "\n",
    "logger.debug(f\"volum=\\n{dict2str(asdict(volume))}\")\n",
    "\n",
    "volume_partitions_aliases = tuple(volume.metadata.set_partitions.keys())\n",
    "\n",
    "if partitions_to_compute_aliases is None:\n",
    "\n",
    "    logger.info(\"Using all available parittions.\")\n",
    "    \n",
    "    partitions_to_compute_aliases = volume_partitions_aliases\n",
    "\n",
    "else:\n",
    "    assert len(partitions_to_compute_aliases) >= 0\n",
    "    \n",
    "    for part_alias in partitions_to_compute_aliases:\n",
    "\n",
    "        try:\n",
    "            volume[part_alias]\n",
    "\n",
    "        except KeyError as ex:\n",
    "            logger.exception(ex)\n",
    "            raise ValueError(f\"Invalid volume partition. {volume.fullname=} {volume_partitions_aliases=} {partitions_to_compute_aliases=}\")\n",
    "\n",
    "logger.info(f\"{partitions_to_compute_aliases=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_name = f\"{volume.fullname}.ground-truth-analysis.runid={tomo2seg_utils.fmt_runid(runid)}\"\n",
    "exec_dir = volume.dir / exec_name\n",
    "figs_dir = exec_dir\n",
    "\n",
    "logger.info(f\"{exec_name=}\")\n",
    "logger.info(f\"{exec_dir=}\")\n",
    "\n",
    "exec_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "load"
    ]
   },
   "outputs": [],
   "source": [
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "data_volume = file_utils.HST_read(\n",
    "    str(volume.data_path),  # it doesn't accept paths...\n",
    "    \n",
    "    autoparse_filename=False,  # the file names are not properly formatted\n",
    "    data_type=volume.metadata.dtype,\n",
    "    dims=volume.metadata.dimensions,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{data_volume.shape=}\")\n",
    "\n",
    "logger.info(\"Loading labels from disk.\")\n",
    "\n",
    "labels_volume = file_utils.HST_read(\n",
    "    str(volume.versioned_labels_path(labels_version)),  # it doesn't accept paths...\n",
    "    \n",
    "    autoparse_filename=False,  # the file names are not properly formatted\n",
    "    data_type=\"uint8\",\n",
    "    dims=volume.metadata.dimensions,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{labels_volume.shape=}\")\n",
    "\n",
    "def iterate_partitions() -> Tuple[ndarray, ndarray]:\n",
    "    \"\"\"avoid loading all the partitions one by one (more memory)\"\"\"\n",
    "    for partition_alias in partitions_to_compute_aliases:\n",
    "        yield (\n",
    "            partition_alias,\n",
    "            volume[partition_alias].get_volume_partition(data_volume),\n",
    "            volume[partition_alias].get_volume_partition(labels_volume),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_idx = volume.metadata.labels\n",
    "labels_names = [volume.metadata.labels_names[idx] for idx in labels_idx]\n",
    "\n",
    "labels_idx_name = list(zip(labels_idx, labels_names))\n",
    "\n",
    "n_classes = len(labels_idx)\n",
    "\n",
    "logger.debug(f\"{n_classes=}\")\n",
    "logger.debug(f\"{labels_idx=}\")\n",
    "logger.debug(f\"{labels_names=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "compute"
    ]
   },
   "source": [
    "# [compute] value histogram per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "compute"
    ]
   },
   "outputs": [],
   "source": [
    "MAX_BIN_EDGE = {\n",
    "    \"uint8\": 256,\n",
    "    \"uint16\": 65536,\n",
    "}\n",
    "\n",
    "max_bin_edge = MAX_BIN_EDGE[volume.metadata.dtype]\n",
    "\n",
    "logger.debug(f\"{max_bin_edge=}\")\n",
    "\n",
    "n_bins = 256\n",
    "\n",
    "logger.debug(f\"{n_bins=}\")\n",
    "\n",
    "hist_bin_edges = np.linspace(0, max_bin_edge, n_bins + 1).astype(int)\n",
    "\n",
    "def get_hist_per_label(data_seq, labels_seq):\n",
    "    \n",
    "    assert (tensor_order := len(data_seq.shape)) == 1, f\"{tensor_order}\"\n",
    "    \n",
    "    data_hists_per_label = np.zeros((n_classes, n_bins), dtype=np.int64) # int64 is important to not overflow\n",
    "\n",
    "    for label_idx in labels_idx:\n",
    "\n",
    "        logger.debug(f\"Computing histogram for {label_idx=}\")\n",
    "\n",
    "        data_hists_per_label[label_idx], bins = np.histogram(\n",
    "            data_seq[labels_seq == label_idx],\n",
    "            bins=hist_bin_edges,\n",
    "            density=False,\n",
    "        )\n",
    "        \n",
    "    return data_hists_per_label\n",
    "\n",
    "logger.info(f\"Computing value histograms per label on the partitions.\")\n",
    "hists_per_label = {\n",
    "    partition_alias: get_hist_per_label(part_data.ravel(), part_labels.ravel())\n",
    "    for partition_alias, part_data, part_labels in iterate_partitions()\n",
    "}\n",
    "\n",
    "logger.info(f\"Computing value histograms per label on the whole volume.\")\n",
    "hists_per_label[None] = get_hist_per_label(\n",
    "    data_volume.ravel(),\n",
    "    labels_volume.ravel(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "save"
    ]
   },
   "source": [
    "# [save] value histogram per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save"
    ]
   },
   "outputs": [],
   "source": [
    "def get_filename_value_hist_per_label(partition_: str) -> Path:\n",
    "    fname = f\"value-histogram-per-label\"\n",
    "    fname += f\".partition={partition_}\" if partition_ is not None else \"\"\n",
    "    fname += \".npy\"\n",
    "    return fname\n",
    "\n",
    "logger.info(f\"Saving value histogram per label for all partitions and the whole volume.\")\n",
    "\n",
    "for partition_alias, histogram_per_label in hists_per_label.items():\n",
    "    \n",
    "    filename = get_filename_value_hist_per_label(partition_alias)\n",
    "    \n",
    "    logger.debug(f\"Saving {partition_alias=} ==> {filename=}\")\n",
    "    \n",
    "    filepath = exec_dir / filename\n",
    "    \n",
    "    logger.debug(f\"{filepath=}\")\n",
    "\n",
    "    np.save(\n",
    "        file=filepath,\n",
    "        arr=histogram_per_label,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_volume, labels_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save"
    ]
   },
   "outputs": [],
   "source": [
    "logger.info(\"Saving bins.\")\n",
    "\n",
    "hist_bins = hist_bin_edges[:-1]\n",
    "\n",
    "filename = exec_dir / \"value-histogram-per-label.bins.npy\"\n",
    "\n",
    "logger.debug(f\"{filename=}\")\n",
    "    \n",
    "filepath = exec_dir / filename\n",
    "\n",
    "logger.debug(f\"{filepath=}\")\n",
    "\n",
    "np.save(\n",
    "    file=filepath,\n",
    "    arr=hist_bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# derived computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "compute"
    ]
   },
   "outputs": [],
   "source": [
    "class_imbalance = {\n",
    "    partition_alias: part_hist_per_label.sum(axis=1) \n",
    "    for partition_alias, part_hist_per_label in hists_per_label.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "compute"
    ]
   },
   "outputs": [],
   "source": [
    "hists = {\n",
    "    partition_alias: part_hist_per_label.sum(axis=0) \n",
    "    for partition_alias, part_hist_per_label in hists_per_label.items()\n",
    "}\n",
    "\n",
    "hists_norm = {\n",
    "    partition_alias: part_hist / part_hist.sum() \n",
    "    for partition_alias, part_hist in hists.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value histograms NORMED per label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "compute"
    ]
   },
   "outputs": [],
   "source": [
    "hists_per_label_norm = {\n",
    "    partition_alias: part_hist / part_hist.sum(axis=1, keepdims=True)\n",
    "    for partition_alias, part_hist in hists_per_label.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value histograms per label GLOBAL NORMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "compute"
    ]
   },
   "outputs": [],
   "source": [
    "hists_per_label_global_norm = {\n",
    "    partition_alias: part_hist / part_hist.sum() \n",
    "    for partition_alias, part_hist in hists_per_label.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_label_simple(label_idx):\n",
    "    return labels_names[label_idx]\n",
    "\n",
    "def get_line_label_with_nvoxels(label_idx):\n",
    "    return f\"{labels_names[label_idx]} (nvoxels: {humanize.intcomma(class_imb[label_idx])})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "for partition_alias, class_imb in class_imbalance.items():\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(sz := 7, sz), dpi=(dpi := 120))\n",
    "\n",
    "    display = tomo2seg_viz.ClassImbalanceDisplay(\n",
    "        volume_name=f\"{volume.fullname}\" + (\"\" if partition_alias is None else f\"  --  partition={partition_alias}\"),\n",
    "        labels_idx=labels_idx,\n",
    "        labels_names=labels_names,\n",
    "        labels_counts=class_imb,\n",
    "    ).plot(ax)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    \n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "for partition_alias, hist_ in hists_norm.items():\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2 * (sz := 8), sz), dpi=(dpi := 120))\n",
    "\n",
    "    # i want to get the vertical borders to show up\n",
    "    display = tomo2seg_viz.VoxelValueHistogramDisplay(\n",
    "        volume_name=f\"{volume.fullname}\" + (\"\" if partition_alias is None else f\"  --  partition={partition_alias}\"),\n",
    "        bins=hist_bins.tolist(),\n",
    "        values=hist_.tolist(),\n",
    "    ).plot(ax)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value histogram per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "manual-input",
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "for partition_alias in hists_per_label_norm.keys():\n",
    "    \n",
    "    hist_per_label_normed_global_ = hists_per_label_global_norm[partition_alias]\n",
    "    hist_per_label_normed_ = hists_per_label_norm[partition_alias]\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        nrows := 2, ncols := 1, figsize=(ncols * 1.75 * (sz := 8), nrows * sz), dpi=(dpi := 120),\n",
    "        gridspec_kw=dict(hspace=sz / 15)\n",
    "    )\n",
    "\n",
    "    display = tomo2seg_viz.VoxelValueHistogramPerClassDisplay(\n",
    "        \n",
    "        volume_name=f\"{volume.fullname}\" + (\"\" if partition_alias is None else f\"  --  partition={partition_alias}\"),\n",
    "\n",
    "        bins=hist_bins.tolist(),\n",
    "        \n",
    "        values_per_label=hist_per_label_normed_.tolist(),\n",
    "        values_per_label_global_proportion=hist_per_label_normed_global_.tolist(),\n",
    "        \n",
    "        labels_idx=labels_idx,\n",
    "        line_labels={\n",
    "            idx: get_line_label_with_nvoxels(idx) for idx in labels_idx\n",
    "        },\n",
    "        \n",
    "    ).plot(axs)\n",
    "    \n",
    "    # [manual-input]\n",
    "    axs[0].set_ylim(top=.20)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical metrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- voxel size\n",
    "- volume size\n",
    "- fiber length\n",
    "- fiber diameter\n",
    "- porosity diameter\n",
    "- fraction volumique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"analyse-ground-truth-00.ipynb\"\n",
    "\n",
    "import os\n",
    "this_dir = os.getcwd()\n",
    "logger.warning(f\"{this_nb_name=} {this_dir=}\")\n",
    "\n",
    "os.system(f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {str(exec_dir)} --to html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

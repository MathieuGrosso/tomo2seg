{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import VolumeCropSequence, MetaCrop3DGenerator, ET3DUniformCuboidAlmostEverywhere, UniformGridPosition, GTUniformEverywhere, ET3DConstantDisplacementEverywhere, VSConstantEverywhere, GTConstantEverywhere, SequentialGridPosition\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-8-cf972d05bc84>:<module>:004}::[2020-11-19::15:38:52.852]\n",
      "runid=1605796732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "runid = int(time.time())\n",
    "logger.info(f\"{runid=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-10-05ac3d1186aa>:<module>:001}::[2020-11-19::15:38:57.095]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-10-05ac3d1186aa>:<module>:002}::[2020-11-19::15:38:57.097]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-10-05ac3d1186aa>:<module>:003}::[2020-11-19::15:38:57.098]\n",
      "Both here should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-11-3d8694e42a81>:<module>:011}::[2020-11-19::15:38:57.162]\n",
      "volume_name='PA66GF30' volume_version='v1' labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    "#     VOLUME_PRECIPITATES_DRYRUN_VAL as VOLUME_NAME_VERSION\n",
    ")\n",
    "# LABELS_VERSION = None\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:217}::[2020-11-19::16:25:06.022]\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "ERROR::tomo2seg::{data.py:with_check:235}::[2020-11-19::16:25:06.025]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels.raw\n",
      "\n",
      "WARNING::tomo2seg::{data.py:with_check:239}::[2020-11-19::16:25:06.027]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.weights.raw\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:174}::[2020-11-19::16:25:06.028]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-55-3d9af8b98d34>:<module>:007}::[2020-11-19::16:25:06.034]\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [0, 1300], 'alias': 'train'}, 'val': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1600, 1900], 'alias': 'val'}, 'test': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1300, 1600], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-55-3d9af8b98d34>:<module>:022}::[2020-11-19::16:25:06.035]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-55-3d9af8b98d34>:<module>:026}::[2020-11-19::16:25:19.219]\n",
      "voldata.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-55-3d9af8b98d34>:<module>:030}::[2020-11-19::16:25:19.224]\n",
      "voldata_train.shape=(1300, 1040, 1300) voldata_val.shape=(1300, 1040, 300)\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-55-3d9af8b98d34>:<module>:036}::[2020-11-19::16:25:24.524]\n",
      "vollabels.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-55-3d9af8b98d34>:<module>:040}::[2020-11-19::16:25:24.525]\n",
      "vollabels_train.shape=(1300, 1040, 1300) vollabels_val.shape=(1300, 1040, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "logger.debug(f\"{voldata_train.shape=} {voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "logger.debug(f\"{vollabels_train.shape=} {vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "## Data Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-95-894381cd0b46>:<module>:003}::[2020-11-19::16:43:59.384]\n",
      "batch_size_per_replica=16\n",
      "n_replicas=2\n",
      "batch_size=32\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-95-894381cd0b46>:<module>:015}::[2020-11-19::16:43:59.386]\n",
      "crop_xyz_ranges_train={'x_range': (0, 1076), 'y_range': (0, 816), 'z_range': (0, 1299)}\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:645}::[2020-11-19::16:43:59.388]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:672}::[2020-11-19::16:43:59.389]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-95-894381cd0b46>:<module>:057}::[2020-11-19::16:43:59.390]\n",
      "crop_xyz_ranges_val={'x_range': (0, 1076), 'y_range': (0, 816), 'z_range': (0, 299)}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:__post_init__:161}::[2020-11-19::16:43:59.394]\n",
      "The SequentialGridPosition has len(self.positions)=960 different positions (therefore crops).\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:645}::[2020-11-19::16:43:59.395]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:672}::[2020-11-19::16:43:59.396]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size_per_replica = 16  \n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\")\n",
    "\n",
    "common_random_state = 42\n",
    "crop_shape = (224, 224, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "# train volume\n",
    "volume_shape_train = voldata_train.shape\n",
    "crop_xyz_ranges_train = {\n",
    "    \"x_range\": (0, volume_shape_train[0] - crop_shape[0]),\n",
    "    \"y_range\": (0, volume_shape_train[1] - crop_shape[1]),\n",
    "    \"z_range\": (0, volume_shape_train[2] - crop_shape[2]),\n",
    "}\n",
    "logger.debug(f\"{crop_xyz_ranges_train=}\")\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=voldata_train,\n",
    "    labels_volume=vollabels_train,\n",
    "    labels=volume.metadata.labels,\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape_train,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=UniformGridPosition(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            **crop_xyz_ranges_train,\n",
    "        ),\n",
    "        elastic_transformation_field=ET3DConstantDisplacementEverywhere.build(None, **crop_xyz_ranges_train),\n",
    "        geometric_transformation_field=GTUniformEverywhere(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            gt_type=volume_sequence.GT2D,\n",
    "            **crop_xyz_ranges_train,\n",
    "        ),\n",
    "        value_shift_field=VSConstantEverywhere.build(0, **crop_xyz_ranges_train),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "    epoch_size=100,\n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    ")\n",
    "\n",
    "# val volume\n",
    "\n",
    "volume_shape_val = voldata_val.shape\n",
    "crop_xyz_ranges_val = {\n",
    "    \"x_range\": (0, volume_shape_val[0] - crop_shape[0]),\n",
    "    \"y_range\": (0, volume_shape_val[1] - crop_shape[1]),\n",
    "    \"z_range\": (0, volume_shape_val[2] - crop_shape[2]),\n",
    "}\n",
    "crop_xyz_steps_val = {\n",
    "    \"x_step\": 269,  # 1076 / 4, obs: 1076 % 4 == 0\n",
    "    \"y_step\": 204,  # 816 / 4, obs: 816 % 4 == 0\n",
    "    \"z_step\": 5,\n",
    "}\n",
    "logger.debug(f\"{crop_xyz_ranges_val=}\")\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    data_volume=voldata_val,\n",
    "    labels_volume=vollabels_val,\n",
    "    labels=volume.metadata.labels,\n",
    "    meta_crop_generator = MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape_val,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator = (grid_position_generator_val := SequentialGridPosition(**crop_xyz_ranges_val, **crop_xyz_steps_val)),\n",
    "        elastic_transformation_field=ET3DConstantDisplacementEverywhere.build(None, **crop_xyz_ranges_val),\n",
    "        geometric_transformation_field=GTConstantEverywhere.build(volume_sequence.GT2D.identity, **crop_xyz_ranges_val,),\n",
    "        value_shift_field=VSConstantEverywhere.build(0, **crop_xyz_ranges_val),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "    epoch_size=len(grid_position_generator_val),\n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJtppItnKn5G"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tomo2seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_segm import keras_custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING::tomo2seg::{<ipython-input-82-1118c3a448a0>:<module>:022}::[2020-11-19::16:37:43.075]\n",
      "The model is already defined. To create a new one: `del tomo2seg_model`\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-82-1118c3a448a0>:<module>:025}::[2020-11-19::16:37:43.076]\n",
      "Compiling model.\n",
      "\n",
      "INFO:tensorflow:Assets written to: /home/users/jcasagrande/projects/tomo2seg/data/models/unet-2d.vanilla00.000.1605-796-732/assets\n",
      "INFO::tomo2seg::{<ipython-input-82-1118c3a448a0>:<module>:046}::[2020-11-19::16:37:56.620]\n",
      "Model(master_name='unet-2d', version='vanilla00', fold=0, runid=1605796732, factory_function='tomo2seg.modular_unet.u_net', factory_kwargs={'input_shape': (224, 224, 1), 'nb_filters_0': 6})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_master_name = \"unet-2d\"\n",
    "model_version = \"vanilla00\"\n",
    "model_factory_function = modular_unet.u_net\n",
    "model_factory_kwargs = dict(\n",
    "    input_shape = crop_shape,\n",
    "    nb_filters_0 = 6,\n",
    ")\n",
    "\n",
    "try:\n",
    "    tomo2seg_model\n",
    "    \n",
    "except NameError:\n",
    "    \n",
    "    tomo2seg_model = Tomo2SegModel(\n",
    "        model_master_name, model_version, \n",
    "        runid=runid,\n",
    "        factory_function=model_factory_function,\n",
    "        factory_kwargs=model_factory_kwargs,\n",
    "    )\n",
    "                \n",
    "else:\n",
    "    logger.warning(\"The model is already defined. To create a new one: `del tomo2seg_model`\")\n",
    "\n",
    "finally:\n",
    "    logger.info(\"Compiling model.\")\n",
    "    \n",
    "    with strategy.scope():\n",
    "        if not tomo2seg_model.autosaved_model_path.exists():\n",
    "#             assert not tomo2seg_model.model_path.exists(), f\"Please delete '{tomo2seg_model.model_path}' to resave it if you wish to regenerate it.\"\n",
    "            model = model_factory_function(\n",
    "                output_channels=len(volume.metadata.labels), \n",
    "                name=tomo2seg_model.name,\n",
    "                **model_factory_kwargs\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\"An autosaved model already exists, loading it instead of creating a new one!\")\n",
    "            model = keras.models.load_model(tomo2seg_model.autosaved_model_path_str)\n",
    "       \n",
    "        optimizer = optimizers.Adam()\n",
    "        loss_func = keras_custom_loss.jaccard2_loss\n",
    "\n",
    "        model.compile(loss=loss_func, optimizer=optimizer)\n",
    "        model.save(tomo2seg_model.model_path)\n",
    "    \n",
    "\n",
    "logger.info(f\"{tomo2seg_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 8175,
     "status": "ok",
     "timestamp": 1602255988215,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "L2U_tsMojKCD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-83-1a966c379837>:<module>:010}::[2020-11-19::16:37:59.289]\n",
      "Check the summary and the figure of the model in the following locations:\n",
      "/home/users/jcasagrande/projects/tomo2seg/data/models/unet-2d.vanilla00.000.1605-796-732/summary.txt\n",
      "/home/users/jcasagrande/projects/tomo2seg/data/models/unet-2d.vanilla00.000.1605-796-732/architecture.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write the model summary in a file\n",
    "with tomo2seg_model.summary_path.open(\"w\") as f:\n",
    "    def print_to_txt(line):\n",
    "        f.writelines([line + \"\\n\"])\n",
    "    model.summary(print_fn=print_to_txt, line_length=140)\n",
    "    \n",
    "# same for the architecture\n",
    "utils.plot_model(model, show_shapes=True, to_file=tomo2seg_model.architecture_plot_path);\n",
    "\n",
    "logger.info(f\"Check the summary and the figure of the model in the following locations:\\n{tomo2seg_model.summary_path}\\n{tomo2seg_model.architecture_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "todo check how to get the history call back so i merge it automatically\n",
    "todo add metrics to the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [],
   "source": [
    "autosave_cb = callbacks.ModelCheckpoint(\n",
    "    tomo2seg_model.autosaved_model_path, \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "logger_cb = callbacks.CSVLogger(\n",
    "    str(tomo2seg_model.logger_path), separator=\",\", append=False\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "source": [
    "def get_logspace_lr_cb(min_lr, max_lr, n_epochs, epoch_zero=0):\n",
    "    schedule = np.logspace(min_lr, max_lr, n_epochs)\n",
    "    def schedule_function(epoch, lr):\n",
    "        assert epoch - epoch_zero < n_epochs, \"Schedule is over!\"\n",
    "        return schedule[epoch - epoch_zero]\n",
    "    return tf.keras.callbacks.LearningRateScheduler(schedule_function)\n",
    "\n",
    "lr_range_test_schedule_cb = get_logspace_lr_cb(-4.5, -1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training\n",
    "\n",
    "stuff that i use after the training but i want it to appear in the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Volume slices\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "## Generator samples\n",
    "\n",
    "todo put this back to work\n",
    "\n",
    "# Learning rate range test\n",
    "\n",
    "todo put this back to work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(str(model_paths.autosaved_model_path) + \".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "lr = 0.001\n",
    "K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "cbs = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 135 all-reduces with algorithm = nccl, num_packs = 1\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-a3cc06ca14b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_seq_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_seq_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tomo2seg/condaenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    621\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    622\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=crop_seq_train,\n",
    "    validation_data=crop_seq_val,\n",
    "    epochs=30,  \n",
    "    callbacks=cbs,  \n",
    "    verbose=10,\n",
    "    use_multiprocessing=False,   \n",
    "    initial_epoch=0,\n",
    ")\n",
    "histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 224, 224, 1, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = crop_seq_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "plt.tight_layout()\n",
    "viz.display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 2nd round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateauBacktrack(\n",
    "    model,\n",
    "    str(model_paths.autosaved_model_path) + \".hdf5\",  \n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0,\n",
    "    min_lr=1e-5,\n",
    ")\n",
    "\n",
    "lr = 1.5773934e-05\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "cb = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    reduce_lr_cb,\n",
    "#     lr_range_test_schedule_cb\n",
    "]\n",
    "\n",
    "train_generator.force_shorter_epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,  \n",
    "    epochs=55,  \n",
    "    callbacks=cb,  \n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,   \n",
    "    \n",
    "    initial_epoch=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    model = tf.keras.models.load_model(str(model_paths.autosaved_model_path) + \".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateauBacktrack(\n",
    "    model,\n",
    "    str(model_paths.autosaved_model_path) + \".hdf5\",  \n",
    "    monitor=\"val_loss\",\n",
    "    factor=2./3,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0,\n",
    "    min_lr=1e-7,\n",
    ")\n",
    "\n",
    "lr = 1e-05\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "cb = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    reduce_lr_cb,\n",
    "#     lr_range_test_schedule_cb\n",
    "]\n",
    "\n",
    "train_generator.force_shorter_epoch = None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "source": [
    "history_df = pd.DataFrame({**history.history, **{\"epochs\": history.epoch}})\n",
    "history_df.to_csv(history_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [],
   "source": [
    "model.save(model_paths.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8787,
     "status": "aborted",
     "timestamp": 1602255923921,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "RRq6qKodQz0n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnVqPFS9BNCg"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JEHjvuBBIab"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1602255916978,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "KTMgQv07JkgY",
    "outputId": "69cd78fc-f0f1-46f6-f1d8-63b99d55eaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1602255916979,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "m7qeyEdDT3Hl"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume, ModelPaths\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import VolumeCropSequence, MetaCrop3DGenerator, ET3DUniformCuboidAlmostEverywhere, UniformGridPosition, GTUniformEverywhere, ET3DConstantDisplacementEverywhere, VSConstantEverywhere, GTConstantEverywhere, SequentialGridPosition\n",
    "from tomo2seg import volume_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-13-05ac3d1186aa>:<module>:001}::[2020-11-19::11:41:39.427]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-13-05ac3d1186aa>:<module>:002}::[2020-11-19::11:41:39.428]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-13-05ac3d1186aa>:<module>:003}::[2020-11-19::11:41:39.429]\n",
      "Both here should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Both here should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "strategy = tf.distribute.MirroredStrategy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8e5FhmUaKND"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-14-3d8694e42a81>:<module>:011}::[2020-11-19::11:41:58.122]\n",
      "volume_name='PA66GF30' volume_version='v1' labels_version='refined3'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_V1_LABELS_REFINED3 as LABELS_VERSION\n",
    "#     VOLUME_PRECIPITATES_DRYRUN_VAL as VOLUME_NAME_VERSION\n",
    ")\n",
    "# LABELS_VERSION = None\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "labels_version = LABELS_VERSION\n",
    "\n",
    "logger.info(f\"{volume_name=} {volume_version=} {labels_version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1602255917946,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "4CfP7usu2VKr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:218}::[2020-11-19::13:30:55.150]\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "ERROR::tomo2seg::{data.py:with_check:236}::[2020-11-19::13:30:55.156]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels.raw\n",
      "\n",
      "WARNING::tomo2seg::{data.py:with_check:240}::[2020-11-19::13:30:55.158]\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.weights.raw\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:175}::[2020-11-19::13:30:55.160]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-75-3d9af8b98d34>:<module>:007}::[2020-11-19::13:30:55.173]\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [0, 1300], 'alias': 'train'}, 'val': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1600, 1900], 'alias': 'val'}, 'test': {'x_range': [0, 1300], 'y_range': [0, 1040], 'z_range': [1300, 1600], 'alias': 'test'}}))\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-75-3d9af8b98d34>:<module>:022}::[2020-11-19::13:30:55.175]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-75-3d9af8b98d34>:<module>:026}::[2020-11-19::13:31:08.942]\n",
      "voldata.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-75-3d9af8b98d34>:<module>:030}::[2020-11-19::13:31:08.947]\n",
      "voldata_train.shape=(1300, 1040, 1300) voldata_val.shape=(1300, 1040, 300)\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-75-3d9af8b98d34>:<module>:036}::[2020-11-19::13:31:14.270]\n",
      "vollabels.shape=(1300, 1040, 1900)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-75-3d9af8b98d34>:<module>:040}::[2020-11-19::13:31:14.272]\n",
      "vollabels_train.shape=(1300, 1040, 1300) vollabels_val.shape=(1300, 1040, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "## Data\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "voldata_train = volume.train_partition.get_volume_partition(voldata)\n",
    "voldata_val = volume.val_partition.get_volume_partition(voldata)\n",
    "logger.debug(f\"{voldata_train.shape=} {voldata_val.shape=}\")\n",
    "\n",
    "del voldata\n",
    "\n",
    "## Labels\n",
    "vollabels = read_raw(volume.versioned_labels_path(labels_version))\n",
    "logger.debug(f\"{vollabels.shape=}\")\n",
    "\n",
    "vollabels_train = volume.train_partition.get_volume_partition(vollabels)\n",
    "vollabels_val = volume.val_partition.get_volume_partition(vollabels)\n",
    "logger.debug(f\"{vollabels_train.shape=} {vollabels_val.shape=}\")\n",
    "\n",
    "del vollabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnsQ7lX0bVRh"
   },
   "source": [
    "## Data Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-152-b420e7613fad>:<module>:003}::[2020-11-19::14:43:50.073]\n",
      "batch_size_per_replica=16\n",
      "n_replicas=2\n",
      "batch_size=32\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-152-b420e7613fad>:<module>:015}::[2020-11-19::14:43:50.075]\n",
      "crop_xyz_ranges_train={'x_range': (0, 1076), 'y_range': (0, 816), 'z_range': (0, 1299)}\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:644}::[2020-11-19::14:43:50.077]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:671}::[2020-11-19::14:43:50.078]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-152-b420e7613fad>:<module>:057}::[2020-11-19::14:43:50.079]\n",
      "crop_xyz_ranges_val={'x_range': (0, 1076), 'y_range': (0, 816), 'z_range': (0, 299)}\n",
      "\n",
      "INFO::tomo2seg::{volume_sequence.py:__post_init__:161}::[2020-11-19::14:43:50.086]\n",
      "The SequentialGridPosition has len(self.positions)=4784 different positions (therefore crops).\n",
      "\n",
      "DEBUG::tomo2seg::{volume_sequence.py:__post_init__:644}::[2020-11-19::14:43:50.087]\n",
      "Initializing VolumeCropSequence.\n",
      "\n",
      "WARNING::tomo2seg::{volume_sequence.py:__post_init__:671}::[2020-11-19::14:43:50.088]\n",
      "No meta crops history file path given. The randomly generated crops will not be saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size_per_replica = 16  \n",
    "batch_size = batch_size_per_replica * (n_replicas := strategy.num_replicas_in_sync)\n",
    "logger.info(f\"{batch_size_per_replica=}\\n{n_replicas=}\\n{batch_size=}\")\n",
    "\n",
    "common_random_state = 42\n",
    "crop_shape = (224, 224, 1)  # multiple of 16 (requirement of a 4-level u-net)\n",
    "\n",
    "# train volume\n",
    "volume_shape_train = voldata_train.shape\n",
    "crop_xyz_ranges_train = {\n",
    "    \"x_range\": (0, volume_shape_train[0] - crop_shape[0]),\n",
    "    \"y_range\": (0, volume_shape_train[1] - crop_shape[1]),\n",
    "    \"z_range\": (0, volume_shape_train[2] - crop_shape[2]),\n",
    "}\n",
    "logger.debug(f\"{crop_xyz_ranges_train=}\")\n",
    "\n",
    "crop_seq_train = VolumeCropSequence(\n",
    "    data_volume=voldata_train,\n",
    "    labels_volume=vollabels_train,\n",
    "    labels=volume.metadata.labels,\n",
    "    meta_crop_generator=MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape_train,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator=UniformGridPosition(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            **crop_xyz_ranges_train,\n",
    "        ),\n",
    "        elastic_transformation_field=ET3DConstantDisplacementEverywhere.build(None, **crop_xyz_ranges_train),\n",
    "        geometric_transformation_field=GTUniformEverywhere(\n",
    "            random_state=RandomState(common_random_state),\n",
    "            gt_type=volume_sequence.GT2D,\n",
    "            **crop_xyz_ranges_train,\n",
    "        ),\n",
    "        value_shift_field=VSConstantEverywhere.build(0, **crop_xyz_ranges_train),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "    epoch_size=100,\n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    ")\n",
    "\n",
    "# val volume\n",
    "\n",
    "volume_shape_val = voldata_val.shape\n",
    "crop_xyz_ranges_val = {\n",
    "    \"x_range\": (0, volume_shape_val[0] - crop_shape[0]),\n",
    "    \"y_range\": (0, volume_shape_val[1] - crop_shape[1]),\n",
    "    \"z_range\": (0, volume_shape_val[2] - crop_shape[2]),\n",
    "}\n",
    "crop_xyz_steps_val = {\n",
    "    \"x_step\": 269,  # 1076 / 4, obs: 1076 % 4 == 0\n",
    "    \"y_step\": 204,  # 816 / 4, obs: 816 % 4 == 0\n",
    "    \"z_step\": 1,\n",
    "}\n",
    "logger.debug(f\"{crop_xyz_ranges_val=}\")\n",
    "\n",
    "crop_seq_val = VolumeCropSequence(\n",
    "    data_volume=voldata_val,\n",
    "    labels_volume=vollabels_val,\n",
    "    labels=volume.metadata.labels,\n",
    "    meta_crop_generator = MetaCrop3DGenerator(\n",
    "        volume_shape=volume_shape_val,\n",
    "        crop_shape=crop_shape,\n",
    "        x0y0z0_generator = (grid_position_generator_val := SequentialGridPosition(**crop_xyz_ranges_val, **crop_xyz_steps_val)),\n",
    "        elastic_transformation_field=ET3DConstantDisplacementEverywhere.build(None, **crop_xyz_ranges_val),\n",
    "        geometric_transformation_field=GTConstantEverywhere.build(volume_sequence.GT2D.identity, **crop_xyz_ranges_val,),\n",
    "        value_shift_field=VSConstantEverywhere.build(0, **crop_xyz_ranges_val),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    # this volume cropper only returns random crops, \n",
    "    #so the number of crops per epoch/batch is w/e i want\n",
    "    epoch_size=len(grid_position_generator_val),\n",
    "    meta_crops_hist_path=None,  # todo add a new path to the model and save this\n",
    "    debug__no_data_check=True,  # remove me!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJtppItnKn5G"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "time() -> floating point number\n",
       "\n",
       "Return the current time in seconds since the Epoch.\n",
       "Fractions of a second may be present if the system clock provides them.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?time.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1605-794-534'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1605794534"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0010'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{10:04d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomo2seg.model import Model as Tomo2SegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1602255973613,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "lnPHivbmBhpY"
   },
   "outputs": [],
   "source": [
    "model_master_name = \"unet-2d-basic-00\"\n",
    "# runid = ...  # in case I want to get a previously defined model\n",
    "\n",
    "model_paths = ModelPaths(model_name)\n",
    "logger.info(\"Model paths object: %s\", model_paths)\n",
    "\n",
    "input_shape = (crop_size, crop_size, 1)\n",
    "nb_filters_0 = 12\n",
    "model_generator_function = modular_unet.u_net\n",
    "\n",
    "# lr = 4e-3\n",
    "# n_epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "executionInfo": {
     "elapsed": 10730,
     "status": "ok",
     "timestamp": 1602255986804,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "-0xU4XAueFL2",
    "outputId": "8c8a3b36-a01c-46bc-8daf-8b7dd9444ae7"
   },
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    if not pathlib.Path(str(model_paths.autosaved_model_path) + '.hdf5').exists():\n",
    "        assert not model_paths.model_path.exists(), f\"Please delete '{model_paths.model_path}' to redefine it.\"\n",
    "\n",
    "        model = model_generator_function(input_shape, nb_filters_0=nb_filters_0, output_channels=3, name=model_name)\n",
    "        model.save(filepath=model_paths.model_path, overwrite=False)\n",
    "\n",
    "    else:\n",
    "        logger.warning(\"An autosaved model already exists, loading it instead of creating a new one!\")\n",
    "        model = keras.models.load_model(str(model_paths.autosaved_model_path) + '.hdf5')\n",
    "\n",
    "\n",
    "#     optimizer = optimizers.Adam(lr=lr)\n",
    "    optimizer = optimizers.Adam()\n",
    "    loss_func = losses.categorical_crossentropy    \n",
    "    \n",
    "    model.compile(loss=loss_func, optimizer=optimizer)\n",
    "    model.save(model_paths.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8175,
     "status": "ok",
     "timestamp": 1602255988215,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "L2U_tsMojKCD"
   },
   "outputs": [],
   "source": [
    "# write the model summary in a file\n",
    "with model_paths.summary_path.open(\"w\") as f:\n",
    "    def print_to_txt(line):\n",
    "        f.writelines([line + \"\\n\"])\n",
    "    model.summary(print_fn=print_to_txt, line_length=140)\n",
    "\n",
    "# same for the architecture\n",
    "utils.plot_model(model, show_shapes=True, to_file=model_paths.architecture_plot_path);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRsccmAxOX7v"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8834,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "zRp2b17np-48"
   },
   "outputs": [],
   "source": [
    "\n",
    "autosave_cb = callbacks.ModelCheckpoint(\n",
    "    str(model_paths.autosaved_model_path) + \".hdf5\", \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateauBacktrack(\n",
    "    model,\n",
    "    str(model_paths.autosaved_model_path) + \".hdf5\", \n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0,\n",
    "    min_lr=1e-5,\n",
    "),\n",
    "\n",
    "logger_cb = callbacks.CSVLogger(\n",
    "    str(model_paths.logger_path), separator=\",\", append=False\n",
    ")\n",
    "\n",
    "def get_logspace_lr_cb(min_lr, max_lr, n_epochs, epoch_zero=0):\n",
    "    schedule = np.logspace(min_lr, max_lr, n_epochs)\n",
    "    def schedule_function(epoch, lr):\n",
    "        assert epoch - epoch_zero < n_epochs, \"Schedule is over!\"\n",
    "        return schedule[epoch - epoch_zero]\n",
    "    return tf.keras.callbacks.LearningRateScheduler(schedule_function)\n",
    "\n",
    "lr_range_test_schedule_cb = get_logspace_lr_cb(-4.5, -1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8829,
     "status": "aborted",
     "timestamp": 1602255923910,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "85CAFhUCwWoQ"
   },
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(train_labels, return_counts=True)\n",
    "# class_freqs = dict(zip(unique, counts))\n",
    "# total = sum(class_freqs.values())\n",
    "# class_freqs = {k: v / total for k, v in class_freqs.items()}\n",
    "# class_freqs\n",
    "# class_freqs_inv = {k: 1. / v for k, v in class_freqs.items()}\n",
    "# class_freqs_inv\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.keras import backend as K\n",
    "# weights = [class_freqs_inv[i] for i in range(len(class_freqs_inv))]\n",
    "\n",
    "# def weighted_cross_entropy(y_true, y_pred):\n",
    "#   Kweights = K.constant(weights)\n",
    "#   if not K.is_keras_tensor(y_pred):\n",
    "#     y_pred = K.constant(y_pred)\n",
    "#   y_true = K.cast(y_true, y_pred.dtype)\n",
    "#   return K.categorical_crossentropy(y_true, y_pred) * K.sum(y_true * y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kYnLzlFdDeY"
   },
   "source": [
    "# Summary before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8819,
     "status": "aborted",
     "timestamp": 1602255923912,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "tr6YIjw239on"
   },
   "outputs": [],
   "source": [
    "# stuff that i use after the training but i want it to appear in the \n",
    "# pre-training summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "metadata = Metadata.build(\n",
    "    model, model_paths, \n",
    "    volume_paths, train_generator, val_generator,\n",
    "    model_generator_function, nb_filters_0, input_shape,\n",
    "    n_epochs\n",
    ")\n",
    "\n",
    "print(metadata.yaml_str)\n",
    "metadata.save_yaml_file(model_paths.metadata_yml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume slices"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, axs = viz.tight_subplots(2, 2, 10, 10)\n",
    "mask = (~(train_generator.label_volume == labels.fiber)).astype(int)\n",
    "viz.plot_orthogonal_slices(axs, train_generator.source_volume, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, axs = viz.tight_subplots(2, 2, 10, 10)\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "random_batches = np.random.RandomState(10).choice(\n",
    "    list(range(len(train_generator))), 4, replace=False\n",
    ")\n",
    "for batch_index, ax in zip(random_batches, axs.ravel()):\n",
    "    ax.imshow(train_generator[batch_index][0][0, :, :, 0], cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate range test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "#     reduce_lr_cb,\n",
    "    lr_range_test_schedule_cb\n",
    "]\n",
    "\n",
    "train_generator.force_shorter_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lr_rate_range_test = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,  \n",
    "    epochs=30,  \n",
    "    callbacks=cb,  \n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,   \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "plt.tight_layout()\n",
    "viz.display_training_curves(\n",
    "    history_lr_rate_range_test.history['loss'], history_lr_rate_range_test.history['val_loss'], 'loss', 111, x=np.logspace(-4.5, -1, 30)\n",
    ")\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuEmT2AZODXi"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(str(model_paths.autosaved_model_path) + \".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "cb = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    reduce_lr_cb,\n",
    "#     lr_range_test_schedule_cb\n",
    "]\n",
    "\n",
    "train_generator.force_shorter_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,  \n",
    "    epochs=40,  \n",
    "    callbacks=cb,  \n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,   \n",
    "    \n",
    "    initial_epoch=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "plt.tight_layout()\n",
    "viz.display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 2nd round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateauBacktrack(\n",
    "    model,\n",
    "    str(model_paths.autosaved_model_path) + \".hdf5\",  \n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0,\n",
    "    min_lr=1e-5,\n",
    ")\n",
    "\n",
    "lr = 1.5773934e-05\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "cb = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    reduce_lr_cb,\n",
    "#     lr_range_test_schedule_cb\n",
    "]\n",
    "\n",
    "train_generator.force_shorter_epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,  \n",
    "    epochs=55,  \n",
    "    callbacks=cb,  \n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,   \n",
    "    \n",
    "    initial_epoch=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    model = tf.keras.models.load_model(str(model_paths.autosaved_model_path) + \".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_cb = ReduceLROnPlateauBacktrack(\n",
    "    model,\n",
    "    str(model_paths.autosaved_model_path) + \".hdf5\",  \n",
    "    monitor=\"val_loss\",\n",
    "    factor=2./3,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0,\n",
    "    min_lr=1e-7,\n",
    ")\n",
    "\n",
    "lr = 1e-05\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, lr)\n",
    "\n",
    "cb = [\n",
    "    autosave_cb,\n",
    "    logger_cb,\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    reduce_lr_cb,\n",
    "#     lr_range_test_schedule_cb\n",
    "]\n",
    "\n",
    "train_generator.force_shorter_epoch = None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 8793,
     "status": "aborted",
     "timestamp": 1602255923919,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "d-EnhRhrrEGQ"
   },
   "source": [
    "history_df = pd.DataFrame({**history.history, **{\"epochs\": history.epoch}})\n",
    "history_df.to_csv(history_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8791,
     "status": "aborted",
     "timestamp": 1602255923920,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "LQz6HBJss1o4"
   },
   "outputs": [],
   "source": [
    "model.save(model_paths.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8787,
     "status": "aborted",
     "timestamp": 1602255923921,
     "user": {
      "displayName": "João Paulo Casagrande Bertoldo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioL6iQ5PNE9hm2XaOtZd36rClxQBdpy33-9-QsTUs=s64",
      "userId": "13620585220725745309"
     },
     "user_tz": -120
    },
    "id": "RRq6qKodQz0n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2FW3h3DkQ4XcY6OgH7u/r",
   "collapsed_sections": [
    "EnVqPFS9BNCg",
    "j8e5FhmUaKND",
    "nJtppItnKn5G"
   ],
   "mount_file_id": "1LuEITv9j0lLf8Z418J3a94SjEZ8GvKvI",
   "name": "dryrun-02.ipynb",
   "provenance": [
    {
     "file_id": "1NiX28EcC_FVOYCJL4usp7n5iQ2x3aXIm",
     "timestamp": 1602152789440
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

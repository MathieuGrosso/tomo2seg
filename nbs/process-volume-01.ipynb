{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import *\n",
    "import time\n",
    "import yaml\n",
    "from yaml import YAMLObject\n",
    "import copy\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import humanize\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "from progressbar import progressbar as pbar\n",
    "from enum import Enum\n",
    "import re\n",
    "from enum import Enum\n",
    "from matplotlib import patches\n",
    "import seaborn as sns\n",
    "from typing import Type\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from cnn_segm import keras_custom_loss\n",
    "\n",
    "from tomo2seg import modular_unet\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg import data, viz\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.metadata import Metadata\n",
    "from tomo2seg.volume_sequence import (\n",
    "    VolumeCropSequence, MetaCrop3DGenerator, VSConstantEverywhere, \n",
    "    GTConstantEverywhere, SequentialGridPosition, ET3DConstantEverywhere\n",
    ")\n",
    "from tomo2seg import volume_sequence\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg.data import EstimationVolume\n",
    "from tomo2seg import AggregationStrategy\n",
    "from tomo2seg import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-3-86918d01be8a>:<module>:006}::[2020-12-07::13:19:53.271]\n",
      "tf.__version__='2.2.0'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-3-86918d01be8a>:<module>:007}::[2020-12-07::13:19:53.328]\n",
      "Num GPUs Available: 2\n",
      "This should be 2 on R790-TOMO.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-3-86918d01be8a>:<module>:008}::[2020-12-07::13:19:53.329]\n",
      "Should return 2 devices...\n",
      "tf.config.list_physical_devices('GPU')=[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-3-86918d01be8a>:<module>:009}::[2020-12-07::13:19:53.570]\n",
      "Should return 2 devices...\n",
      "tf.config.list_logical_devices('GPU')=[LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)\n",
    "\n",
    "logger.debug(f\"{tf.__version__=}\")\n",
    "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\\nThis should be 2 on R790-TOMO.\")\n",
    "logger.debug(f\"Should return 2 devices...\\n{tf.config.list_physical_devices('GPU')=}\")\n",
    "logger.debug(f\"Should return 2 devices...\\n{tf.config.list_logical_devices('GPU')=}\")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo integrate this to the model object instead\n",
    "class ModelType(Enum):\n",
    "    input2d = 0\n",
    "    input2halfd = 1\n",
    "    input3d = 2\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class Opts:\n",
    "    # this will later be useful when i transform this in python script\n",
    "    save_probas_by_class: bool\n",
    "    debug__save_figs: bool\n",
    "    debug__materialize_crops: bool\n",
    "    debug__save_processed_crops: bool\n",
    "    probabilities_dtype: Type"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls ../data/models | grep vanilla03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unet2d.vanilla03-f16.fold000.1606-505-109\"\n",
    "model_type = ModelType.input2d\n",
    "\n",
    "from tomo2seg.datasets import (\n",
    "#     VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "    VOLUME_COMPOSITE_NEIGHBOUR as VOLUME_NAME_VERSION,    \n",
    ")\n",
    "\n",
    "volume_name, volume_version = VOLUME_NAME_VERSION\n",
    "\n",
    "agg_strategy = AggregationStrategy.average_probabilities\n",
    "\n",
    "# runid = 1607330931\n",
    "try:\n",
    "    runid\n",
    "except NameError:\n",
    "    runid = int(time.time())\n",
    "    \n",
    "    \n",
    "opts = Opts(\n",
    "    save_probas_by_class = True,\n",
    "    debug__save_figs = True,\n",
    "    debug__materialize_crops = False,\n",
    "    debug__save_processed_crops = False,\n",
    "    probabilities_dtype = np.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:with_check:237}::[2020-12-07::13:19:53.746]\n",
      "vol=Volume(name='PA66GF30', version='neighbour', _metadata=None)\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:metadata:194}::[2020-12-07::13:19:53.748]\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.neighbour/PA66GF30.neighbour.metadata.yml`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tomo2seg_model = Tomo2SegModel.build_from_model_name(model_name)\n",
    "\n",
    "volume = Volume.with_check(\n",
    "    name=volume_name, version=volume_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition = volume.train_partition\n",
    "# partition = volume.val_partition\n",
    "# partition = volume.test_partition\n",
    "partition = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{data.py:metadata_path:300}::[2020-12-07::13:19:53.888]\n",
      "Creating metadata file /home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.neighbour.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-343-593/vol=PA66GF30.neighbour.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-343-593.metadata.yml.\n",
      "\n",
      "DEBUG::tomo2seg::{data.py:__setitem__:308}::[2020-12-07::13:19:53.912]\n",
      "Writing to file self.metadata_path=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.neighbour.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-343-593/vol=PA66GF30.neighbour.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-343-593.metadata.yml').\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimation_volume = EstimationVolume.from_objects(\n",
    "    volume=volume, \n",
    "    model=tomo2seg_model, \n",
    "    set_partition=partition,\n",
    "    runid=runid,\n",
    ")\n",
    "estimation_volume[\"aggregation_strategy\"] = agg_strategy.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:001}::[2020-12-07::13:19:54.003]\n",
      "model_name='unet2d.vanilla03-f16.fold000.1606-505-109'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:002}::[2020-12-07::13:19:54.004]\n",
      "model_type.name='input2d'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:003}::[2020-12-07::13:19:54.004]\n",
      "volume_name='PA66GF30'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:004}::[2020-12-07::13:19:54.006]\n",
      "volume_version='neighbour'\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:009}::[2020-12-07::13:19:54.007]\n",
      "No partition. Processing the whole volume.\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:011}::[2020-12-07::13:19:54.008]\n",
      "agg_strategy=<AggregationStrategy.average_probabilities: 0>\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:012}::[2020-12-07::13:19:54.009]\n",
      "runid=1607343593\n",
      "\n",
      "INFO::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:014}::[2020-12-07::13:19:54.011]\n",
      "estimation_volume=EstimationVolume(volume_fullname='PA66GF30.neighbour', model_name='unet2d.vanilla03-f16.fold000.1606-505-109', runid=1607343593, partition=None)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:016}::[2020-12-07::13:19:54.012]\n",
      "volume=Volume(name='PA66GF30', version='neighbour', _metadata=Volume.Metadata(dimensions=[2048, 2048, 2048], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions=None))\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:017}::[2020-12-07::13:19:54.013]\n",
      "partition=None\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-9-e319e121dae4>:<module>:018}::[2020-12-07::13:19:54.014]\n",
      "tomo2seg_model=Model(master_name='unet2d', version='vanilla03-f16', fold=0, runid=1606505109, factory_function=None, factory_kwargs=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"{model_name=}\")\n",
    "logger.info(f\"{model_type.name=}\")\n",
    "logger.info(f\"{volume_name=}\")\n",
    "logger.info(f\"{volume_version=}\")\n",
    "            \n",
    "if partition is not None:\n",
    "    logger.info(f\"{partition.alias=}\")\n",
    "else:\n",
    "    logger.info(\"No partition. Processing the whole volume.\")\n",
    "\n",
    "logger.info(f\"{agg_strategy=}\")\n",
    "logger.info(f\"{runid=}\")\n",
    "\n",
    "logger.info(f\"{estimation_volume=}\")\n",
    "            \n",
    "logger.debug(f\"{volume=}\")\n",
    "logger.debug(f\"{partition=}\")\n",
    "logger.debug(f\"{tomo2seg_model=}\")\n",
    "\n",
    "if model_type == ModelType.input2halfd:\n",
    "    raise NotImplementedError(f\"{model_type=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gpu distribution strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-15-308ff3024fce>:<module>:008}::[2020-12-07::13:21:09.827]\n",
      "Because model_type=<ModelType.input2d: 0>, MirroredStrategy cannot be used. Switched to OneDeviceStrategy\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-15-308ff3024fce>:<module>:010}::[2020-12-07::13:21:09.828]\n",
      "strategy=<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7f02b15b05e0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "# strategy = tf.distribute.MirroredStrategy()  \n",
    "\n",
    "# if model_type == ModelType.input3d:\n",
    "# there is a bug with MirroredStrategy when you model.predict() with batch_size=1\n",
    "# https://docs.google.com/document/d/17X1CUvGtlio3pkbKFemSGbF2Qnn0vWAZfCLsgFPoOqg/edit?usp=sharing\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "logger.info(f\"Because {model_type=}, MirroredStrategy cannot be used. Switched to {strategy.__class__.__name__}\")\n",
    "    \n",
    "logger.debug(f\"{strategy=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-16-4a5d2914c9e3>:<module>:011}::[2020-12-07::13:21:12.550]\n",
      "input_n_channels=(1,)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-16-4a5d2914c9e3>:<module>:019}::[2020-12-07::13:21:12.553]\n",
      "anysize_input=<tf.Tensor 'input_any_image_size_1:0' shape=(None, None, None, None, 1) dtype=float32>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model(\n",
    "        tomo2seg_model.autosaved_model_path_str,\n",
    "        compile=False\n",
    "    )\n",
    "    \n",
    "    in_ = model.layers[0]\n",
    "    in_shape = in_.input_shape[0]\n",
    "    input_n_channels = in_shape[-1:]\n",
    "\n",
    "    logger.debug(f\"{input_n_channels=}\")\n",
    "    \n",
    "    # make it capable of getting any dimension in the input\n",
    "    anysize_input = layers.Input(\n",
    "        shape=[None, None, None] + list(input_n_channels),\n",
    "        name=\"input_any_image_size\"\n",
    "    )\n",
    "    \n",
    "    logger.debug(f\"{anysize_input=}\")\n",
    "    \n",
    "    model.layers[0] = anysize_input\n",
    "    \n",
    "    # todo keep this somewhere instead of copying and pasting\n",
    "    optimizer = optimizers.Adam()\n",
    "    loss_func = keras_custom_loss.jaccard2_loss\n",
    "\n",
    "    model.compile(loss=loss_func, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-17-b6ebd6b7519a>:<module>:014}::[2020-12-07::13:21:20.563]\n",
      "Loading data from disk.\n",
      "\n",
      "data type is uint8\n",
      "volume size is 2048 x 2048 x 2048\n",
      "reading volume... from byte 0\n",
      "DEBUG::tomo2seg::{<ipython-input-17-b6ebd6b7519a>:<module>:018}::[2020-12-07::13:22:54.674]\n",
      "voldata.shape=(2048, 2048, 2048)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-17-b6ebd6b7519a>:<module>:026}::[2020-12-07::13:22:54.778]\n",
      "No partition.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-17-b6ebd6b7519a>:<module>:029}::[2020-12-07::13:22:58.683]\n",
      "data_volume.shape=(2048, 2048, 2048)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _read_raw(path_: Path, volume_: Volume): \n",
    "    # from pymicro\n",
    "    return file_utils.HST_read(\n",
    "        str(path_),  # it doesn't accept paths...\n",
    "        # pre-loaded kwargs\n",
    "        autoparse_filename=False,  # the file names are not properly formatted\n",
    "        data_type=volume.metadata.dtype,\n",
    "        dims=volume.metadata.dimensions,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "read_raw = partial(_read_raw, volume_=volume)\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "voldata = read_raw(volume.data_path) / 255  # normalize\n",
    "\n",
    "logger.debug(f\"{voldata.shape=}\")\n",
    "\n",
    "if partition is not None:\n",
    "    logger.debug(f\"Cutting data with {partition.alias=}\")\n",
    "    data_volume = partition.get_volume_partition(voldata)\n",
    "    del voldata\n",
    "\n",
    "else:\n",
    "    logger.debug(f\"No partition.\")\n",
    "    data_volume = voldata\n",
    "    \n",
    "logger.debug(f\"{data_volume.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-18-1bff9e12fad3>:<module>:003}::[2020-12-07::13:22:59.920]\n",
      "figs_dir=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/vol=PA66GF30.neighbour.set=whole-volume.model=unet2d.vanilla03-f16.fold000.1606-505-109.runid=1607-343-593')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if opts.debug__save_figs:\n",
    "    figs_dir = estimation_volume.dir\n",
    "    logger.debug(f\"{figs_dir=}\")\n",
    "    figs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes and steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-19-57c92f52b499>:<module>:005}::[2020-12-07::13:22:59.996]\n",
      "volume_shape=(2048, 2048, 2048)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-19-57c92f52b499>:<module>:037}::[2020-12-07::13:22:59.997]\n",
      "dims_multiple_16=[2048, 2048]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-19-57c92f52b499>:<module>:038}::[2020-12-07::13:22:59.999]\n",
      "crop_shape=(2048, 2048, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-19-57c92f52b499>:<module>:044}::[2020-12-07::13:23:00.000]\n",
      "n_steps=(1, 1, 2048)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-19-57c92f52b499>:<module>:066}::[2020-12-07::13:23:00.003]\n",
      "min(x0s)=0, max(x0s)=0, len(x0s)=1\n",
      "min(y0s)=0, max(y0s)=0, len(y0s)=1\n",
      "min(z0s)=0, max(z0s)=2047, len(z0s)=2048\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_3D_DIM = 224\n",
    "MAX_N_VOXELS_3D = DEFAULT_3D_DIM ** 3\n",
    "\n",
    "volume_shape = data_volume.shape\n",
    "logger.debug(f\"{volume_shape=}\")\n",
    "\n",
    "# it has to be multiple of 16 because of the 4 cascaded 2x2-strided 2x2-downsamplings in u-net\n",
    "if model_type == ModelType.input2d:\n",
    "    dims_multiple_16 = [\n",
    "        int(16 * np.floor(dim / 16)) \n",
    "        for dim in volume_shape[:2]\n",
    "    ]\n",
    "    crop_shape = tuple(dims_multiple_16 + [1])  # x-axis, y-axis, z-axis\n",
    "\n",
    "elif model_type == ModelType.input2halfd:\n",
    "    raise NotImplemented()\n",
    "    \n",
    "elif model_type == ModelType.input3d:\n",
    "    dims_multiple_16 = [\n",
    "        int(16 * np.floor(dim / 16)) \n",
    "        for dim in volume_shape\n",
    "    ]\n",
    "    nvoxels_per_crop = dims_multiple_16[0] * dims_multiple_16[1] * dims_multiple_16[2]\n",
    "    \n",
    "    if nvoxels_per_crop > MAX_N_VOXELS_3D:\n",
    "        logger.warning(f\"If {dims_multiple_16=} ==> {nvoxels_per_crop=}, which is too big. Using default dimension {DEFAULT_3D_DIM=}.\")\n",
    "        \n",
    "        dims_multiple_16 = [\n",
    "            min(DEFAULT_3D_DIM, dim)\n",
    "            for dim in dims_multiple_16\n",
    "        ]\n",
    "        \n",
    "        logger.debug(f\"Effective computed {dims_multiple_16=}\")\n",
    "\n",
    "    crop_shape = tuple(dims_multiple_16)  # x-axis, y-axis, z-axis\n",
    "\n",
    "logger.debug(f\"{dims_multiple_16=}\")\n",
    "logger.debug(f\"{crop_shape=}\")\n",
    "\n",
    "n_steps = tuple(\n",
    "    int(np.ceil(vol_dim / crop_dim))\n",
    "    for vol_dim, crop_dim in zip(volume_shape, crop_shape)\n",
    ")\n",
    "logger.debug(f\"{n_steps=}\")\n",
    "\n",
    "def get_coordinates_iterator(n_steps_):\n",
    "    assert len(n_steps_) == 3\n",
    "    return itertools.product(*(range(n_steps_[dim]) for dim in range(3)))\n",
    "\n",
    "get_ijk_iterator = functools.partial(\n",
    "    get_coordinates_iterator, copy.copy(n_steps)\n",
    ")\n",
    "\n",
    "get_kji_iterator = functools.partial(\n",
    "    get_coordinates_iterator, tuple(reversed(n_steps))\n",
    ")\n",
    "\n",
    "# coordinates (xs, ys, and zs) of the front upper left corners of the crops\n",
    "x0s, y0s, z0s = tuple(\n",
    "    tuple(map(\n",
    "        int, \n",
    "        np.linspace(0, vol_dim - crop_dim, n)\n",
    "    ))\n",
    "    for vol_dim, crop_dim, n in zip(volume_shape, crop_shape, n_steps)\n",
    ")\n",
    "logger.debug(f\"\"\"{min(x0s)=}, {max(x0s)=}, {len(x0s)=}\n",
    "{min(y0s)=}, {max(y0s)=}, {len(y0s)=}\n",
    "{min(z0s)=}, {max(z0s)=}, {len(z0s)=}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [debug] Orthogonal slices figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-20-f89740f0514b>:<module>:011}::[2020-12-07::13:23:17.704]\n",
      "Saving figure (figname := display.title + '.png')='PA66GF30.neighbour.orthogonal-slices-display.x=1024-y=1024-z=1024.png'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if opts.debug__save_figs:\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(sz := 15, sz), dpi=120)\n",
    "    fig.set_tight_layout(True)\n",
    "    \n",
    "    display = viz.OrthogonalSlicesDisplay(\n",
    "        volume=data_volume,\n",
    "        volume_name=volume.fullname,\n",
    "    ).plot(axs=axs,)\n",
    "    \n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        dpi=200, format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crops coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-21-81c28bea32a8>:<module>:001}::[2020-12-07::13:23:22.570]\n",
      "Generating the crop coordinates.\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-21-81c28bea32a8>:<module>:015}::[2020-12-07::13:23:22.579]\n",
      "crops_coordinates.shape=(1, 1, 2048, 3, 2)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-21-81c28bea32a8>:<module>:020}::[2020-12-07::13:23:22.581]\n",
      "crops_coordinates_sequential.shape=(2048, 3, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"Generating the crop coordinates.\")\n",
    "\n",
    "crops_coordinates = np.array(\n",
    "    [\n",
    "        (\n",
    "            (x0, x0 + crop_shape[0]), \n",
    "            (y0, y0 + crop_shape[1]),\n",
    "            (z0, z0 + crop_shape[2]),\n",
    "        )\n",
    "        for x0, y0, z0 in itertools.product(x0s, y0s, z0s)\n",
    "    ], \n",
    "    dtype=tuple\n",
    ").reshape(len(x0s), len(y0s), len(z0s), 3, 2).astype(int)  # 3 = nb of dimenstions, 2 = (start, end)\n",
    "\n",
    "logger.debug(f\"{crops_coordinates.shape=}\")\n",
    "\n",
    "# 'F' reshapes with x varying fastest and z slowest\n",
    "crops_coordinates_sequential = crops_coordinates.reshape(-1, 3, 2, order='F')  \n",
    "\n",
    "logger.debug(f\"{crops_coordinates_sequential.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [debug] Crops (if `debug__materialize_crops`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if opts.debug__materialize_crops:\n",
    "    logger.info(\"Materializing crops\")\n",
    "    \n",
    "    crops_sequential = np.array([\n",
    "        data_volume[tuple(slice(*coords_) for coords_ in coords)]\n",
    "        for coords in pbar(crops_coordinates_sequential, max_value=crops_coordinates_sequential.shape[0])\n",
    "    ])\n",
    "    logger.debug(f\"{crops_sequential.shape=}\")\n",
    "\n",
    "    crops_target_shape = list(crops_coordinates.shape[:3]) + list(crop_shape)\n",
    "    logger.debug(f\"{crops_target_shape=}\")\n",
    "\n",
    "    # 'F' reshapes with x varying fastest and z slowest\n",
    "    # this option is necessary because `crops_coordinates` was reshaped with it\n",
    "    crops = crops_sequential.reshape(crops_target_shape, order=\"F\")\n",
    "    del crops_sequential\n",
    "    logger.debug(f\"{crops.shape=}\")\n",
    "    \n",
    "    if debug__save_processed_crops:\n",
    "        fname = estimation_volume.debug__crops_coordinates_path\n",
    "        logger.info(f\"Saving crops coordinates at {fname=}\")\n",
    "        np.save(fname, crops_coordinates)\n",
    "        \n",
    "        fname = estimation_volume.debug__crops_path\n",
    "        logger.info(f\"Saving materialized crops at {fname=}\")\n",
    "        np.save(fname, crops)\n",
    "        \n",
    "    if debug__save_figs:\n",
    "\n",
    "        n_crop_plots = 3\n",
    "        logger.debug(f\"Plotinng {n_crop_plots=} examples of 3d crops.\")\n",
    "\n",
    "        for n, (k, j, i) in enumerate(get_kji_iterator()):\n",
    "\n",
    "            if n >= n_crop_plots:\n",
    "                break\n",
    "\n",
    "            ijk = (i, j, k)\n",
    "            one_crop = crops[i, j, k]\n",
    "            logger.debug(f\"{ijk=} {one_crop.shape=}\")\n",
    "\n",
    "            fig, axs = plt.subplots(\n",
    "                nrows=2, ncols=2,\n",
    "                figsize=(sz := 20, sz), \n",
    "                dpi=120,\n",
    "                gridspec_kw={\"wspace\": (gridspace := .01), \"hspace\": .5 * gridspace}\n",
    "            )\n",
    "\n",
    "            display = viz.OrthogonalSlicesDisplay(\n",
    "                volume=one_crop,\n",
    "                volume_name=volume.fullname + f\".debug.crop-{ijk=}\",\n",
    "            ).plot(axs=axs, with_cuts=False)\n",
    "\n",
    "            logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "            display.fig_.savefig(\n",
    "                fname=figs_dir / figname,\n",
    "                format=\"png\",\n",
    "                metadata=display.metadata,\n",
    "            )       \n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:005}::[2020-12-07::13:56:27.424]\n",
      "Segmenting one crop for debug crop_ijk=(0, 0, 0)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:015}::[2020-12-07::13:56:27.426]\n",
      "crop_data.shape=(2048, 2048, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:023}::[2020-12-07::13:56:27.428]\n",
      "modelin_target_shape=(1, 2048, 2048, 1, 1)\n",
      "\n",
      "1/1 - 0s\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:035}::[2020-12-07::13:56:28.579]\n",
      "modelout.shape=(1, 2048, 2048, 3)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:039}::[2020-12-07::13:56:28.580]\n",
      "n_classes=3\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:044}::[2020-12-07::13:56:28.581]\n",
      "crop_probas_target_shape=[2048, 2048, 1, 3]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:048}::[2020-12-07::13:56:28.671]\n",
      "crop_probas.shape=(2048, 2048, 1, 3)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:049}::[2020-12-07::13:56:28.672]\n",
      "crop_probas.dtype=dtype('float16')\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:054}::[2020-12-07::13:56:28.787]\n",
      "crop_preds.shape=(2048, 2048, 1)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-25-e41af88ee793>:<module>:055}::[2020-12-07::13:56:28.788]\n",
      "crop_preds.dtype=dtype('int8')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crop_ijk = (0, 0, 0)\n",
    "i, j, k = crop_ijk\n",
    "crop_coords = crops_coordinates[i, j, k]\n",
    "\n",
    "logger.info(f\"Segmenting one crop for debug {crop_ijk=}\")\n",
    "\n",
    "if opts.debug__materialize_crops:\n",
    "    crop_data = crops[i, j, k]\n",
    "    \n",
    "else:\n",
    "    slice3d = tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "    crop_data = data_volume[slice3d]\n",
    "    del slice3d\n",
    "    \n",
    "logger.debug(f\"{crop_data.shape=}\")\n",
    "\n",
    "# [model] - i call it with a first crop bc if something goes wrong then the error\n",
    "# will appear here instead of in a loop\n",
    "\n",
    "# modelin\n",
    "modelin_target_shape = (1, crop_shape[0], crop_shape[1], crop_shape[2], 1)\n",
    "\n",
    "logger.debug(f\"{modelin_target_shape=}\")\n",
    "\n",
    "modelin = crop_data.reshape(modelin_target_shape) \n",
    "\n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=1,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{modelout.shape=}\")\n",
    "\n",
    "n_classes = modelout.shape[-1]\n",
    "\n",
    "logger.debug(f\"{n_classes=}\")\n",
    "\n",
    "# probas\n",
    "crop_probas_target_shape = list(crop_shape) + [n_classes]\n",
    "\n",
    "logger.debug(f\"{crop_probas_target_shape=}\")\n",
    "\n",
    "crop_probas = modelout.reshape(crop_probas_target_shape).astype(opts.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{crop_probas.shape=}\")\n",
    "logger.debug(f\"{crop_probas.dtype=}\")\n",
    "\n",
    "# preds\n",
    "crop_preds = crop_probas.argmax(axis=-1).astype(np.int8)\n",
    "\n",
    "logger.debug(f\"{crop_preds.shape=}\")\n",
    "logger.debug(f\"{crop_preds.dtype=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::tomo2seg::{<ipython-input-27-619e6a14591c>:<module>:015}::[2020-12-07::13:57:08.028]\n",
      "Saving figure (figname := display.title + '.png')='PA66GF30.neighbour.debug.crop-crop_ijk=(0, 0, 0).orthogonal-slices-display.x=1024-y=1024-z=0.png'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if opts.debug__save_figs:\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=3, ncols=2,\n",
    "        figsize=(2 * (sz := 20), sz), \n",
    "        dpi=120,\n",
    "    )\n",
    "\n",
    "    display = viz.OrthogonalSlicesPredictionDisplay(\n",
    "        volume_data=crop_data,\n",
    "        volume_prediction=crop_preds,\n",
    "        n_classes=n_classes,\n",
    "        volume_name=volume.fullname + f\".debug.crop-{crop_ijk=}\",\n",
    "    ).plot(axs=axs,)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )       \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment  (if `debug__materialize_crops`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if opts.debug__materialize_crops:\n",
    "    \n",
    "    logger.info(\"Predicting all crops in advance (materialized version).\")\n",
    "    \n",
    "    proba_crops_target_shape = list(crops.shape) + [n_classes]\n",
    "    logger.debug(f\"{proba_crops_target_shape=}\")\n",
    "\n",
    "    proba_crops = np.empty(proba_crops_target_shape, dtype=opts.probabilities_dtype)\n",
    "    logger.debug(f\"{proba_crops.shape=} {proba_crops.dtype=}\")\n",
    "\n",
    "    pred_crops = np.empty_like(crops)\n",
    "    logger.debug(f\"{pred_crops.shape=} {pred_crops.dtype=}\")\n",
    "\n",
    "    ijk_iterator = list(get_ijk_iterator())\n",
    "    n_iterations = len(ijk_iterator)\n",
    "    logger.debug(f\"{n_iterations=}\")\n",
    "\n",
    "    for i, j, k in pbar(ijk_iterator, prefix=\"crops-segmentation\", max_value=n_iterations):\n",
    "        \n",
    "        crop_data = crops[i, j, k]\n",
    "        \n",
    "        # [model]\n",
    "        model_in = crop_data.reshape(*modelin_target_shape) \n",
    "        model_out = model.predict(model_in)\n",
    "        proba_crops[i, j, k] = model_out.astype(opts.probabilities_dtype).reshape(crop_probas_target_shape)\n",
    "        pred_crops[i, j, k] = proba_crops[i, j, k].argmax(axis=-1).astype(np.int8)\n",
    "    \n",
    "    if debug__save_processed_crops:\n",
    "        fname = estimation_volume.debug__crops_probas_path\n",
    "        logger.info(f\"Saving crops probabilities at {fname=}\")\n",
    "        np.save(fname, proba_crops)\n",
    "        \n",
    "        fname = estimation_volume.debug__crops_preds_path\n",
    "        logger.info(f\"Saving crops predictions at {fname=}\")\n",
    "        np.save(fname, pred_crops)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG::tomo2seg::{<ipython-input-37-70a5766c98ad>:<module>:003}::[2020-12-07::14:04:08.130]\n",
      "proba_volume_target_shape=[2048, 2048, 2048, 3]\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-37-70a5766c98ad>:<module>:007}::[2020-12-07::14:04:08.132]\n",
      "proba_volume.shape=(2048, 2048, 2048, 3)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-37-70a5766c98ad>:<module>:011}::[2020-12-07::14:04:08.133]\n",
      "redundancies_count_target_shape=(2048, 2048, 2048)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-37-70a5766c98ad>:<module>:015}::[2020-12-07::14:04:08.135]\n",
      "redundancies_count.shape=(2048, 2048, 2048)\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-37-70a5766c98ad>:<module>:019}::[2020-12-07::14:04:08.136]\n",
      "n_iterations=2048\n",
      "\n",
      "DEBUG::tomo2seg::{<ipython-input-37-70a5766c98ad>:<module>:038}::[2020-12-07::14:04:08.137]\n",
      "Predicting and summing up the crops' probabilities.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict-and-sum-probas 43% (900 of 2048) || Elapsed Time: 0:32:23 ETA:   0:52:14"
     ]
    }
   ],
   "source": [
    "proba_volume_target_shape = list(volume_shape) + [n_classes]\n",
    "\n",
    "logger.debug(f\"{proba_volume_target_shape=}\")\n",
    "\n",
    "proba_volume = np.zeros(proba_volume_target_shape, dtype=opts.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{proba_volume.shape=}\")\n",
    "\n",
    "redundancies_count_target_shape = volume_shape\n",
    "\n",
    "logger.debug(f\"{redundancies_count_target_shape=}\")\n",
    "\n",
    "redundancies_count = np.zeros(redundancies_count_target_shape, dtype=np.int8)  # only one channel\n",
    "\n",
    "logger.debug(f\"{redundancies_count.shape=}\")\n",
    "\n",
    "n_iterations = n_steps[0] * n_steps[1] * n_steps[2]\n",
    "\n",
    "logger.debug(f\"{n_iterations=}\")\n",
    "\n",
    "if opts.debug__materialize_crops:\n",
    "    # 'F' reshapes with x varying fastest and z slowest\n",
    "    # this is necessary bcs `crops_coordinates_sequential` is \n",
    "    # also reshaped like this\n",
    "    proba_crops_sequential = proba_crops.reshape(-1, *proba_crops.shape[3:], order='F')  \n",
    "    logger.debug(f\"{proba_crops_sequential.shape=}\")\n",
    "\n",
    "    logger.debug(\"Summing up the crops' probabilities.\")\n",
    "    for coord, proba_crop in pbar(zip(\n",
    "        crops_coordinates_sequential,\n",
    "        proba_crops_sequential,\n",
    "    ), prefix=\"sum-probas\", max_value=n_iterations):\n",
    "        slice3d = tuple(slice(*coords_) for coords_ in coord)\n",
    "        proba_volume[slice3d] += proba_crop\n",
    "        redundancies_count[slice3d] += np.ones(crop_shape, dtype=np.int)\n",
    "        \n",
    "else:\n",
    "    logger.debug(\"Predicting and summing up the crops' probabilities.\")\n",
    "    for coord in pbar(crops_coordinates_sequential, prefix=\"predict-and-sum-probas\", max_value=n_iterations):\n",
    "        # [model]\n",
    "        slice3d = tuple(slice(*coords_) for coords_ in coord)\n",
    "        crop_data = data_volume[slice3d]\n",
    "        modelin = crop_data.reshape(modelin_target_shape)\n",
    "        modelout = model.predict(modelin, batch_size=1, steps=1)\n",
    "        proba_volume[slice3d] += modelout.astype(opts.probabilities_dtype).reshape(crop_probas_target_shape)\n",
    "        redundancies_count[slice3d] += np.ones(crop_shape, dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proba_volume' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c70e587bdd82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check that the min and max probas are coherent with the min/max redundancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmin_proba_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba_volume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmax_proba_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba_volume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmin_redundancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredundancies_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_redundancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredundancies_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proba_volume' is not defined"
     ]
    }
   ],
   "source": [
    "# check that the min and max probas are coherent with the min/max redundancy\n",
    "min_proba_sum = proba_volume.min(axis=0).min(axis=0).min(axis=0)\n",
    "max_proba_sum = proba_volume.max(axis=0).max(axis=0).max(axis=0)\n",
    "min_redundancy = np.min(redundancies_count)\n",
    "max_redundancy = np.max(redundancies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min_redundancy >= 1, f\"{min_redundancy=}\"\n",
    "assert np.all(min_proba_sum >= 0), f\"{min_proba_sum=}\"\n",
    "assert np.all(max_proba_sum <= max_redundancy), f\"{max_proba_sum=} {max_redundancy=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each probability channel by the number of times it was summed (avg proba)\n",
    "logger.debug(f\"Dividing probability redundancies.\")\n",
    "for klass_idx in pbar(range(n_classes), max_value=n_classes, prefix=\"redundancies-per-class\"):\n",
    "    proba_volume[:, :, :, klass_idx] = proba_volume[:, :, :, klass_idx] / redundancies_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes it more stable so that the sum is 1\n",
    "proba_volume[:, :, :] = proba_volume[:, :, :] / proba_volume[:, :, :].sum(axis=-1, keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that proba distribs sum to 1\n",
    "min_proba = proba_volume.min(axis=0).min(axis=0).min(axis=0)\n",
    "max_proba = proba_volume.max(axis=0).max(axis=0).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(min_proba >= 0), f\"{min_proba=}\"\n",
    "assert np.all(max_proba <= 1), f\"{max_proba=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distrib_proba_sum = proba_volume.sum(axis=-1).min()\n",
    "max_distrib_proba_sum = proba_volume.sum(axis=-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(min_distrib_proba_sum, 1, atol=.001), f\"{min_distrib_proba_sum=}\"\n",
    "assert np.isclose(max_distrib_proba_sum, 1, atol=.001), f\"{max_distrib_proba_sum=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_volume = proba_volume.argmax(axis=-1).astype(\"uint8\")\n",
    "\n",
    "logger.debug(f\"{pred_volume.shape=}\")\n",
    "logger.debug(f\"{pred_volume.min()=}\")\n",
    "logger.debug(f\"{pred_volume.max()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Writing probabilities on disk at `{estimation_volume.probabilities_path}`\")\n",
    "np.save(estimation_volume.probabilities_path, proba_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Writing predictions on disk at `{(str_path := str(estimation_volume.predictions_path))}`\")\n",
    "file_utils.HST_write(pred_volume, str_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opts.save_probas_by_class:\n",
    "    for klass_idx in volume.metadata.labels:\n",
    "        logger.debug(f\"Writing probabilities of class `{klass_idx}` on disk at `{(str_path := str(estimation_volume.get_class_probability_path(klass_idx)))=}`\")\n",
    "        file_utils.HST_write(proba_volume[:, :, :, klass_idx], str_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-z-slice-crops-locations.png\n",
    "\n",
    "not kept, search fro `one-z-slice-crops-locations.png` in `process-3d-crops-entire-2d-slice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debug__materialize_crops\n",
    "\n",
    "same for\n",
    "`debug__materialize_crops`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"process-volume-01.ipynb\"\n",
    "this_dir = os.getcwd()\n",
    "save_nb_dir = str(estimation_volume.dir)\n",
    "\n",
    "logger.warning(f\"{this_nb_name=}\")\n",
    "logger.warning(f\"{this_dir=}\")\n",
    "logger.warning(f\"{save_nb_dir=}\")\n",
    "\n",
    "command = f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {save_nb_dir} --to html\"\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

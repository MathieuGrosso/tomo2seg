{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import functools\n",
    "import itertools\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "import humanize\n",
    "from pymicro.file import file_utils\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import ndarray\n",
    "from matplotlib import pyplot as plt, patches, cm\n",
    "from sklearn import metrics as met\n",
    "from progressbar import progressbar as pbar\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn import model_selection\n",
    "import skimage\n",
    "from skimage import measure, io\n",
    "\n",
    "import tomo2seg.data as tomo2seg_data\n",
    "from tomo2seg.data import ModelPaths, Volume, EstimationVolume, SetPartition\n",
    "from tomo2seg.volume_img_segm import VolumeImgSegmSequence\n",
    "from tomo2seg import viz\n",
    "from tomo2seg.logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomo2seg.data import VOLUME_PRECIPITATES_V1 as VOL_NAME_VERSION\n",
    "logger.debug(f\"{VOL_NAME_VERSION=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "random_state = np.random.RandomState(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-10::16:07:26.608] tomo2seg :: DEBUG :: {data.py:with_check:201}\n",
      "vol=Volume(name='PA66GF30', version='v1', _metadata=None)\n",
      "\n",
      "[2020-11-10::16:07:26.645] tomo2seg :: ERROR :: {data.py:with_check:219}\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels.raw\n",
      "\n",
      "[2020-11-10::16:07:26.668] tomo2seg :: WARNING :: {data.py:with_check:223}\n",
      "Missing file: /home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.weights.raw\n",
      "\n",
      "[2020-11-10::16:07:26.670] tomo2seg :: DEBUG :: {data.py:metadata:158}\n",
      "Loading metadata from `/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.metadata.yml`.\n",
      "\n",
      "[2020-11-10::16:07:26.684] tomo2seg :: INFO :: {<ipython-input-6-034fde79d2fd>:<module>:008}\n",
      "volume=Volume(name='PA66GF30', version='v1', _metadata=Volume.Metadata(dimensions=[1300, 1040, 1900], dtype='uint8', labels=[0, 1, 2], labels_names={0: 'matrix', 1: 'fiber', 2: 'porosity'}, set_partitions={'train': {'x_range': [0, 1299], 'y_range': [0, 1039], 'z_range': [0, 1299], 'alias': 'train'}, 'val': {'x_range': [0, 1299], 'y_range': [0, 1039], 'z_range': [1600, 1899], 'alias': 'val'}, 'test': {'x_range': [0, 1299], 'y_range': [0, 1039], 'z_range': [1300, 1599], 'alias': 'test'}}))\n",
      "\n",
      "[2020-11-10::16:07:26.685] tomo2seg :: INFO :: {<ipython-input-6-034fde79d2fd>:<module>:020}\n",
      "Loading data from disk.\n",
      "\n",
      "[2020-11-10::16:07:26.686] tomo2seg :: INFO :: {<ipython-input-6-034fde79d2fd>:<module>:022}\n",
      "*Input* versioned labels: (labels_in_path := volume.versioned_labels_path(labels_in_version := 'refined'))=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels-refined.raw')\n",
      "\n",
      "[2020-11-10::16:07:26.688] tomo2seg :: INFO :: {<ipython-input-6-034fde79d2fd>:<module>:023}\n",
      "*Output* versioned labels: (labels_out_path := volume.versioned_labels_path(labels_out_version := 'refined2'))=PosixPath('/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels-refined2.raw')\n",
      "\n",
      "data type is uint8\n",
      "volume size is 1300 x 1040 x 1900\n",
      "reading volume... from byte 0\n",
      "[2020-11-10::16:07:29.909] tomo2seg :: DEBUG :: {<ipython-input-6-034fde79d2fd>:<module>:027}\n",
      "labels_volume.shape=(1300, 1040, 1900)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata/paths objects\n",
    "\n",
    "## Volume\n",
    "volume = Volume.with_check(\n",
    "    volume_name := VOL_NAME_VERSION[0], \n",
    "    volume_version := VOL_NAME_VERSION[1]\n",
    ")\n",
    "logger.info(f\"{volume=}\")\n",
    "\n",
    "hst_read = lambda x: functools.partial(\n",
    "    # from pymicro\n",
    "    file_utils.HST_read,\n",
    "    # pre-loaded kwargs\n",
    "    autoparse_filename=False,  # the file names are not properly formatted\n",
    "    data_type=volume.metadata.dtype,\n",
    "    dims=volume.metadata.dimensions,\n",
    "    verbose=True,\n",
    ")(str(x))  # it doesn't accept paths...\n",
    "\n",
    "logger.info(\"Loading data from disk.\")\n",
    "\n",
    "logger.info(f\"*Input* versioned labels: {(labels_in_path := volume.versioned_labels_path(labels_in_version := 'refined'))=}\")\n",
    "logger.info(f\"*Output* versioned labels: {(labels_out_path := volume.versioned_labels_path(labels_out_version := 'refined2'))=}\")\n",
    "\n",
    "## Labels\n",
    "labels_volume = hst_read(labels_in_path)\n",
    "logger.debug(f\"{labels_volume.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/users/jcasagrande/projects/tomo2seg/data/PA66GF30.v1/PA66GF30.v1.labels'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bkp4.py\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Optional\n",
    "import multiprocessing as multip\n",
    "\n",
    "props = [\n",
    "    \"label\", \n",
    "    \"area\", \"bbox\", \"bbox_area\", \"centroid\", \"eccentricity\", \"euler_number\", \"extent\",\n",
    "    \"filled_area\", \"inertia_tensor_eigvals\", \"local_centroid\", \"major_axis_length\", \"minor_axis_length\",\n",
    "    \"perimeter\", \"solidity\", \n",
    "    # todo add properties using the intensity image\n",
    "]\n",
    "\n",
    "\n",
    "_get_blob_props_func = functools.partial(\n",
    "    skimage.measure.regionprops_table,\n",
    "    cache=True,\n",
    "    separator=\"-\",\n",
    "    properties=props\n",
    ")\n",
    "\n",
    "\n",
    "def _do_instances_slice(args):\n",
    "    idx, instances = args\n",
    "    return {**_get_blob_props_func(instances), **{\"slice_idx\": idx}}\n",
    "\n",
    "\n",
    "def get_2d_blobs_from_slices(slices_array: ndarray, label_to_search: int, n_processes: Optional[int]) -> list:\n",
    "    \n",
    "    instances_slices = (n_slices := slices_array.shape[0]) * [None]\n",
    "    \n",
    "    for idx, slice_ in pbar(\n",
    "        enumerate(slices_array),\n",
    "        max_value=n_slices,\n",
    "        prefix=\"slices \",\n",
    "    ):\n",
    "        instances_slices[idx] = skimage.measure.label(\n",
    "            slice_ == label_to_search, \n",
    "            connectivity=2, background=0, return_num=False\n",
    "        )\n",
    "    \n",
    "    with multip.Pool(n_processes) as p:\n",
    "        mapresult = p.map_async(\n",
    "            _do_instances_slice,  # get the properties of all blobs in a slice\n",
    "            enumerate(instances_slices)\n",
    "        )\n",
    "        blobs_per_slice = mapresult.get()\n",
    "    \n",
    "    for blobs in pbar(\n",
    "        blobs_per_slice,\n",
    "        max_value=n_slices,\n",
    "        prefix=\"adjustments \",\n",
    "    ):\n",
    "        blobs['label'] = label_to_search * np.ones_like(blobs['label'])\n",
    "        blobs['slice_idx'] = blobs['slice_idx'] * np.ones_like(blobs['label'])\n",
    "        for k, v in blobs.items():\n",
    "            if v.dtype in (np.float, np.float64, np.float32, np.float128):\n",
    "                blobs[k] = v.astype(np.float16)  # reduce memory usage\n",
    "        \n",
    "    prop_keys = list(blobs_per_slice[0].keys())\n",
    "    return {\n",
    "        key: np.concatenate([\n",
    "            blobs[key] for blobs in blobs_per_slice\n",
    "        ])\n",
    "        for key in pbar(\n",
    "            prop_keys,\n",
    "            max_value=len(prop_keys),\n",
    "            prefix=\"concat \"\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "get_2d_blobs_from_slices_only_porosity = functools.partial(\n",
    "    get_2d_blobs_from_slices,\n",
    "    label_to_search=2,\n",
    "    n_processes=None,  # use all \n",
    ")\n",
    "\n",
    "test_slices = z_slices[:2]\n",
    "test_blobs = get_2d_blobs_from_slices_only_porosity(test_slices)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_blobs['slice_idx'].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "test_slices = z_slices[:200]\n",
    "test_blobs = get_2d_blobs_from_slices_only_porosity(test_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "slices 100% (1900 of 1900) |#############| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "instance_slices 100% (1900 of 1900) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "adjustments 100% (1900 of 1900) |########| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "concat 100% (22 of 22) |#################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 s, sys: 1min 3s, total: 1min 45s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"z-slices\")\n",
    "blobs2d_z_porosity = get_2d_blobs_from_slices_only_porosity(z_slices)\n",
    "blobs2d_z_porosity_df = pd.DataFrame(blobs2d_z_porosity)\n",
    "blobs2d_z_porosity_df.to_csv(\"z-blobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"y-slices\")\n",
    "blobs2d_y_porosity = get_2d_blobs_from_slices_only_porosity(y_slices)\n",
    "blobs2d_y_porosity_df = pd.DataFrame(blobs2d_y_porosity)\n",
    "blobs2d_y_porosity_df.to_csv(\"y-blobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"x-slices\")\n",
    "blobs2d_x_porosity = get_2d_blobs_from_slices_only_porosity(x_slices)\n",
    "blobs2d_x_porosity_df = pd.DataFrame(blobs2d_x_porosity)\n",
    "blobs2d_x_porosity_df.to_csv(\"x-blobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bkps of simpler versions of the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bkp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "def get_2d_blobs_from_slices(slices_array: ndarray, label_to_search: int, properties: List[str]) -> list:\n",
    "    \n",
    "    instances_slices = (n_slices := slices_array.shape[0]) * [None]\n",
    "    \n",
    "    for idx, slice_ in pbar(\n",
    "        enumerate(slices_array),\n",
    "        max_value=n_slices,\n",
    "        prefix=\"slices \",\n",
    "    ):\n",
    "        instances_slices[idx] = skimage.measure.label(\n",
    "            slice_ == label_to_search, \n",
    "            connectivity=2, background=0, return_num=True\n",
    "        )\n",
    "    \n",
    "    get_blob_props = functools.partial(\n",
    "        skimage.measure.regionprops_table,\n",
    "        cache=True,\n",
    "        separator=\"-\",\n",
    "        properties=properties\n",
    "    )\n",
    "    \n",
    "    blobs_per_slice = [\n",
    "        get_blob_props(instances)\n",
    "        for instances, n_instances in pbar(\n",
    "            instances_slices,\n",
    "            max_value=n_slices,\n",
    "            prefix=\"instance_slices \",\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for blobs in blobs_per_slice:\n",
    "        blobs['label'] = label_to_search * np.ones_like(blobs['label'])\n",
    "        \n",
    "    return {\n",
    "        key: np.concatenate([\n",
    "            blobs[key] for blobs in blobs_per_slice\n",
    "        ])\n",
    "        for key in blobs_per_slice[0].keys()\n",
    "    }\n",
    "\n",
    "props = [\n",
    "    \"label\", \n",
    "    \"area\", \"bbox\", \"bbox_area\", \"centroid\", \"eccentricity\", \"euler_number\", \"extent\",\n",
    "    \"filled_area\", \"inertia_tensor_eigvals\", \"local_centroid\", \"major_axis_length\", \"minor_axis_length\",\n",
    "    \"perimeter\", \"solidity\", \n",
    "    # todo add properties using the intensity image\n",
    "]\n",
    "\n",
    "get_2d_blobs_from_slices_only_porosity = functools.partial(\n",
    "    get_2d_blobs_from_slices,\n",
    "    label_to_search=2,\n",
    "    properties=props\n",
    ")\n",
    "\n",
    "test_slices = z_slices[:2]\n",
    "test_blobs = get_2d_blobs_from_slices_only_porosity(test_slices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bkp 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import Tuple, List\n",
    "import multiprocessing as multip\n",
    "\n",
    "props = [\n",
    "    \"label\", \n",
    "    \"area\", \"bbox\", \"bbox_area\", \"centroid\", \"eccentricity\", \"euler_number\", \"extent\",\n",
    "    \"filled_area\", \"inertia_tensor_eigvals\", \"local_centroid\", \"major_axis_length\", \"minor_axis_length\",\n",
    "    \"perimeter\", \"solidity\", \n",
    "    # todo add properties using the intensity image\n",
    "]\n",
    "\n",
    "\n",
    "_get_blob_props_func = functools.partial(\n",
    "    skimage.measure.regionprops_table,\n",
    "    cache=True,\n",
    "    separator=\"-\",\n",
    "    properties=props\n",
    ")\n",
    "\n",
    "\n",
    "def _do_instances_slice(args):\n",
    "    idx, instances = args\n",
    "    return {**_get_blob_props_func(instances), **{\"slice_idx\": idx}}\n",
    "\n",
    "\n",
    "def get_2d_blobs_from_slices(slices_array: ndarray, label_to_search: int, properties: List[str]) -> list:\n",
    "    \n",
    "    instances_slices = (n_slices := slices_array.shape[0]) * [None]\n",
    "    \n",
    "    for idx, slice_ in pbar(\n",
    "        enumerate(slices_array),\n",
    "        max_value=n_slices,\n",
    "        prefix=\"slices \",\n",
    "    ):\n",
    "        instances_slices[idx] = skimage.measure.label(\n",
    "            slice_ == label_to_search, \n",
    "            connectivity=2, background=0, return_num=False\n",
    "        )\n",
    "    \n",
    "    with multip.Pool(None) as p:\n",
    "        mapresult = p.map_async(\n",
    "            _do_instances_slice,\n",
    "            pbar(\n",
    "                enumerate(instances_slices),\n",
    "                max_value=n_slices,\n",
    "                prefix=\"instance_slices \",\n",
    "            )\n",
    "        )\n",
    "#         mapresult.wait()\n",
    "        blobs_per_slice = mapresult.get()\n",
    "    \n",
    "    for blobs in pbar(\n",
    "        blobs_per_slice,\n",
    "        max_value=n_slices,\n",
    "        prefix=\"adjustments \",\n",
    "    ):\n",
    "        blobs['label'] = label_to_search * np.ones_like(blobs['label'])\n",
    "        blobs['slice_idx'] = blobs['slice_idx'] * np.ones_like(blobs['label'])\n",
    "        for k, v in blobs.items():\n",
    "            if v.dtype in (np.float, np.float64, np.float32, np.float128):\n",
    "                blobs[k] = v.astype(np.float16)  # reduce memory usage\n",
    "        \n",
    "    prop_keys = list(blobs_per_slice[0].keys())\n",
    "    return {\n",
    "        key: np.concatenate([\n",
    "            blobs[key] for blobs in blobs_per_slice\n",
    "        ])\n",
    "        for key in pbar(\n",
    "            prop_keys,\n",
    "            max_value=len(prop_keys),\n",
    "            prefix=\"concat \"\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "get_2d_blobs_from_slices_only_porosity = functools.partial(\n",
    "    get_2d_blobs_from_slices,\n",
    "    label_to_search=2,\n",
    "    properties=props\n",
    ")\n",
    "\n",
    "test_slices = z_slices[:2]\n",
    "test_blobs = get_2d_blobs_from_slices_only_porosity(test_slices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bkp3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import Tuple, List, Optional\n",
    "import multiprocessing as multip\n",
    "\n",
    "props = [\n",
    "    \"label\", \n",
    "    \"area\", \"bbox\", \"bbox_area\", \"centroid\", \"eccentricity\", \"euler_number\", \"extent\",\n",
    "    \"filled_area\", \"inertia_tensor_eigvals\", \"local_centroid\", \"major_axis_length\", \"minor_axis_length\",\n",
    "    \"perimeter\", \"solidity\", \n",
    "    # todo add properties using the intensity image\n",
    "]\n",
    "\n",
    "\n",
    "_get_blob_props_func = functools.partial(\n",
    "    skimage.measure.regionprops_table,\n",
    "    cache=True,\n",
    "    separator=\"-\",\n",
    "    properties=props\n",
    ")\n",
    "\n",
    "\n",
    "def _do_instances_slice(args):\n",
    "    idx, instances = args\n",
    "    return {**_get_blob_props_func(instances), **{\"slice_idx\": idx}}\n",
    "\n",
    "\n",
    "def get_2d_blobs_from_slices(slices_array: ndarray, label_to_search: int, n_processes: Optional[int]) -> list:\n",
    "    \n",
    "    instances_slices = (n_slices := slices_array.shape[0]) * [None]\n",
    "    \n",
    "    for idx, slice_ in pbar(\n",
    "        enumerate(slices_array),\n",
    "        max_value=n_slices,\n",
    "        prefix=\"slices \",\n",
    "    ):\n",
    "        instances_slices[idx] = skimage.measure.label(\n",
    "            slice_ == label_to_search, \n",
    "            connectivity=2, background=0, return_num=False\n",
    "        )\n",
    "    \n",
    "    with multip.Pool(n_processes) as p:\n",
    "        mapresult = p.map_async(\n",
    "            _do_instances_slice,  # get the properties of all blobs in a slice\n",
    "            pbar(\n",
    "                enumerate(instances_slices),\n",
    "                max_value=n_slices,\n",
    "                prefix=\"instance_slices \",\n",
    "            )\n",
    "        )\n",
    "        blobs_per_slice = mapresult.get()\n",
    "    \n",
    "    for blobs in pbar(\n",
    "        blobs_per_slice,\n",
    "        max_value=n_slices,\n",
    "        prefix=\"adjustments \",\n",
    "    ):\n",
    "        blobs['label'] = label_to_search * np.ones_like(blobs['label'])\n",
    "        blobs['slice_idx'] = blobs['slice_idx'] * np.ones_like(blobs['label'])\n",
    "        for k, v in blobs.items():\n",
    "            if v.dtype in (np.float, np.float64, np.float32, np.float128):\n",
    "                blobs[k] = v.astype(np.float16)  # reduce memory usage\n",
    "        \n",
    "    prop_keys = list(blobs_per_slice[0].keys())\n",
    "    return {\n",
    "        key: np.concatenate([\n",
    "            blobs[key] for blobs in blobs_per_slice\n",
    "        ])\n",
    "        for key in pbar(\n",
    "            prop_keys,\n",
    "            max_value=len(prop_keys),\n",
    "            prefix=\"concat \"\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "get_2d_blobs_from_slices_only_porosity = functools.partial(\n",
    "    get_2d_blobs_from_slices,\n",
    "    label_to_search=2,\n",
    "    n_processes=None,  # use all \n",
    ")\n",
    "\n",
    "test_slices = z_slices[:2]\n",
    "test_blobs = get_2d_blobs_from_slices_only_porosity(test_slices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
